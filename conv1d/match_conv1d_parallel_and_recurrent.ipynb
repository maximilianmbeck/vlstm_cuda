{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "\n",
    "from conv1d import CausalConv1dConfig, CausalConv1d\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match parallel and recurrent impl of causal 1D convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f90963a68d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTYPE = torch.float32 \n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "S = 12\n",
    "DH = 5\n",
    "EPS = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.9247, -0.4253, -2.6438,  0.1452, -0.1209],\n",
       "          [-0.5797, -0.6229, -0.3284, -1.0745, -0.3631],\n",
       "          [-1.6711,  2.2655,  0.3117, -0.1842,  1.2866],\n",
       "          [ 1.1820, -0.1271,  1.2169,  1.4353,  1.0605],\n",
       "          [-0.4941, -1.4244, -0.7244, -1.2973,  0.0697],\n",
       "          [-0.0074,  1.8969,  0.6878, -0.0779, -0.8373],\n",
       "          [ 1.3506, -0.2879, -0.5965, -0.3283, -0.9086],\n",
       "          [-0.8059, -0.7407, -0.0504,  0.5435,  1.5150],\n",
       "          [ 0.0141,  0.4532,  1.6349,  0.7124, -0.1806],\n",
       "          [ 1.0252, -1.4622, -0.7554, -0.1836,  0.3824],\n",
       "          [ 0.3918, -0.0830,  0.8971, -1.1123,  0.1116],\n",
       "          [ 0.4863, -0.5499, -0.3231, -0.5469,  0.9049]]], device='cuda:0'),\n",
       " torch.Size([1, 12, 5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = torch.randn((B, S, DH), dtype=DTYPE, device=DEVICE)\n",
    "xs, xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d = CausalConv1d(config=CausalConv1dConfig(feature_dim=DH, kernel_size=4, causal_conv_bias=True)).to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0333,  0.4533,  1.0648, -0.2179,  0.0256],\n",
       "          [ 0.3536,  0.3336,  1.6271, -0.2148,  0.1696],\n",
       "          [ 0.1185, -0.6049,  1.2795, -0.4546, -0.3236],\n",
       "          [-0.1661,  1.5106,  0.5153, -0.4060, -1.0016],\n",
       "          [-1.4377,  0.3595, -0.0985, -0.4110, -0.3364],\n",
       "          [ 0.4205, -1.1767, -0.0652, -0.2971,  0.0118],\n",
       "          [-0.8406,  1.5220,  0.1182,  0.0782,  0.4352],\n",
       "          [-0.6601,  0.2417,  0.5137, -0.8620, -0.2299],\n",
       "          [ 0.7227, -0.3354, -0.1103, -0.1781, -0.5223],\n",
       "          [-0.8804,  1.1659, -0.0971, -0.0738,  0.2892],\n",
       "          [-0.8929, -0.2839, -0.1745,  0.0970, -0.6405],\n",
       "          [-0.1276,  0.6855, -0.1451, -0.2405, -0.3184]]], device='cuda:0',\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 12, 5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = conv1d(xs)\n",
    "y_p, y_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0333,  0.4533,  1.0648, -0.2179,  0.0256],\n",
       "        [ 0.3536,  0.3336,  1.6271, -0.2148,  0.1696],\n",
       "        [ 0.1185, -0.6049,  1.2795, -0.4546, -0.3236],\n",
       "        [-0.1661,  1.5106,  0.5153, -0.4060, -1.0016],\n",
       "        [-1.4377,  0.3595, -0.0985, -0.4110, -0.3364],\n",
       "        [ 0.4205, -1.1767, -0.0652, -0.2971,  0.0118],\n",
       "        [-0.8406,  1.5220,  0.1182,  0.0782,  0.4352],\n",
       "        [-0.6601,  0.2417,  0.5137, -0.8620, -0.2299],\n",
       "        [ 0.7227, -0.3354, -0.1103, -0.1781, -0.5223],\n",
       "        [-0.8804,  1.1659, -0.0971, -0.0738,  0.2892],\n",
       "        [-0.8929, -0.2839, -0.1745,  0.0970, -0.6405],\n",
       "        [-0.1276,  0.6855, -0.1451, -0.2405, -0.3184]], device='cuda:0',\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = []\n",
    "conv_state = None\n",
    "for x in xs.split(split_size=1, dim=1):\n",
    "    y, conv_state = conv1d.step(x, conv_state)\n",
    "    # print(conv_state)\n",
    "    ys.append(y)\n",
    "torch.cat(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1176e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  1.1921e-07,  1.4901e-08,  0.0000e+00],\n",
       "         [-1.4901e-08,  0.0000e+00,  0.0000e+00, -2.9802e-08, -2.9802e-08],\n",
       "         [ 4.4703e-08, -1.1921e-07,  0.0000e+00,  2.9802e-08,  0.0000e+00],\n",
       "         [-1.1921e-07,  2.9802e-08,  4.4703e-08,  0.0000e+00, -2.9802e-08],\n",
       "         [ 8.9407e-08, -1.1921e-07,  3.7253e-08, -2.9802e-08,  2.7008e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  2.9802e-08,  0.0000e+00],\n",
       "         [-5.9605e-08,  2.9802e-08,  5.9605e-08,  0.0000e+00,  0.0000e+00],\n",
       "         [-5.9605e-08,  0.0000e+00, -1.4901e-08, -1.4901e-08,  5.9605e-08],\n",
       "         [-5.9605e-08,  1.1921e-07,  5.2154e-08,  2.9802e-08,  0.0000e+00],\n",
       "         [ 0.0000e+00,  2.9802e-08, -1.4901e-08,  7.4506e-09, -5.9605e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00, -2.9802e-08,  0.0000e+00,  0.0000e+00]]],\n",
       "       device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(ys) - y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1, 4]), torch.Size([5]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1d.conv.weight.shape, conv1d.conv.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0141,  0.4532,  1.6349,  0.7124, -0.1806],\n",
       "         [ 1.0252, -1.4622, -0.7554, -0.1836,  0.3824],\n",
       "         [ 0.3918, -0.0830,  0.8971, -1.1123,  0.1116],\n",
       "         [ 0.4863, -0.5499, -0.3231, -0.5469,  0.9049]]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the conv state are the kernel_size last input elements\n",
    "# take the first 4\n",
    "conv_state = xs[:, -4:].clone()\n",
    "conv_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0252, -1.4622, -0.7554, -0.1836,  0.3824],\n",
       "         [ 0.3918, -0.0830,  0.8971, -1.1123,  0.1116],\n",
       "         [ 0.4863, -0.5499, -0.3231, -0.5469,  0.9049],\n",
       "         [ 0.0141,  0.4532,  1.6349,  0.7124, -0.1806]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.roll(conv_state, shifts=-1, dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.9247, -0.4253, -2.6438,  0.1452, -0.1209]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 5]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = xs[:, :1, :]\n",
    "x_new, x_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_state_new = torch.roll(conv_state, shifts=-1, dims=1)\n",
    "conv_state_new[:, -1, :] = x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.0252, -1.4622, -0.7554, -0.1836,  0.3824],\n",
       "          [ 0.3918, -0.0830,  0.8971, -1.1123,  0.1116],\n",
       "          [ 0.4863, -0.5499, -0.3231, -0.5469,  0.9049],\n",
       "          [-0.9247, -0.4253, -2.6438,  0.1452, -0.1209]]], device='cuda:0'),\n",
       " torch.Size([1, 4, 5]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_state_new, conv_state_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2971,  0.1015,  0.7834, -0.4558, -0.4674]], device='cuda:0',\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(conv_state_new * rearrange(conv1d.conv.weight, 'D 1 KS -> KS D'), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d_step(x: torch.Tensor, conv_state: torch.Tensor, conv1d_weight: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    B: batch size\n",
    "    S: sequence length\n",
    "    D: feature dimension\n",
    "    KS: kernel size\n",
    "    Args:\n",
    "        x (torch.Tensor): (B, S, D)\n",
    "        conv_state (torch.Tensor): (B, KS, D)\n",
    "        conv1d_weight (torch.Tensor): (KS, D)\n",
    "    \"\"\"\n",
    "    assert x.shape[0] == conv_state.shape[0], f\"x has batch size {x.shape[0]} but conv_state has batch size {conv_state.shape[0]}\"\n",
    "    assert x.shape[2] == conv_state.shape[2], f\"x has feature dimension {x.shape[2]} but conv_state has feature dimension {conv_state.shape[2]}\"\n",
    "    assert x.shape[1] == 1, f\"x has sequence length {x.shape[1]} but it should be 1\"\n",
    "    conv_state_new = torch.roll(conv_state, shifts=-1, dims=1)\n",
    "    conv_state_new[:, -1, :] = x\n",
    "    return torch.sum(conv_state_new * conv1d_weight, dim=1), conv_state_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(xs[:, :4, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9247, -0.4253, -2.6438,  0.1452, -0.1209],\n",
       "         [-0.5797, -0.6229, -0.3284, -1.0745, -0.3631],\n",
       "         [-1.6711,  2.2655,  0.3117, -0.1842,  1.2866],\n",
       "         [ 1.1820, -0.1271,  1.2169,  1.4353,  1.0605],\n",
       "         [-0.4941, -1.4244, -0.7244, -1.2973,  0.0697],\n",
       "         [-0.0074,  1.8969,  0.6878, -0.0779, -0.8373],\n",
       "         [ 1.3506, -0.2879, -0.5965, -0.3283, -0.9086],\n",
       "         [-0.8059, -0.7407, -0.0504,  0.5435,  1.5150],\n",
       "         [ 0.0141,  0.4532,  1.6349,  0.7124, -0.1806],\n",
       "         [ 1.0252, -1.4622, -0.7554, -0.1836,  0.3824],\n",
       "         [ 0.3918, -0.0830,  0.8971, -1.1123,  0.1116],\n",
       "         [ 0.4863, -0.5499, -0.3231, -0.5469,  0.9049]]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt220cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
