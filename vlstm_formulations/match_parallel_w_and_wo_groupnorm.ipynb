{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch vLSTM forward with group norm (headwise layernorm)\n",
    "\n",
    "Shows what happens if we fuse the multihead layernorm with the vlstm kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from vlstm_parallel_tiled import vlstm_parallel_tiled\n",
    "from vlstm_parallel import vlstm_parallel_fw_torch\n",
    "from vlstm_parallel_w_groupnorm import vlstm_parallel_fw_torch_w_groupnorm, vlstm_parallel_fwbw_torch_w_groupnorm\n",
    "from ln import MultiHeadLayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "S = 8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 4 # dim per head\n",
    "DTYPE = torch.float64\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "EPS = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 8, 4]), torch.Size([1, 1, 8, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(0)\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "igs = torch.rand((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "igs2 = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1)\n",
    "fgs = torch.rand((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "qs.shape, fgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0., 0., 0., 0.], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_layernorm = MultiHeadLayerNorm(NH*DH, eps=1e-6).to(device=DEVICE, dtype=DTYPE)\n",
    "mh_layernorm.weight, mh_layernorm.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_pt = fgs.clone().detach().requires_grad_(True)\n",
    "igs_pt = igs.clone().detach().requires_grad_(True)\n",
    "qs_pt = qs.clone().detach().requires_grad_(True)\n",
    "ks_pt = ks.clone().detach().requires_grad_(True)\n",
    "vs_pt = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = vlstm_fw_torch(\n",
    "#     queries=qs,\n",
    "#     keys=ks,\n",
    "#     values=vs,\n",
    "#     igate_preact=igs,\n",
    "#     fgate_preact=fgs,\n",
    "#     stabilize_rowwise=True,\n",
    "# )\n",
    "# rs, rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.2508, -1.1810, -0.7554,  0.6856],\n",
       "           [-1.4225, -0.2860,  1.3208,  0.3877],\n",
       "           [ 1.1236,  0.4122, -1.6011,  0.0653],\n",
       "           [ 0.9885, -0.1728, -1.5612,  0.7455],\n",
       "           [ 0.8213, -1.0949, -0.8853,  1.1589],\n",
       "           [-0.8941,  0.1563,  1.5739, -0.8361],\n",
       "           [-1.4935,  0.9028,  0.9198, -0.3292],\n",
       "           [-1.6608,  0.7769,  0.0900,  0.7939]]]], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = vlstm_parallel_fw_torch(\n",
    "    queries=qs_pt,\n",
    "    keys=ks_pt,\n",
    "    values=vs_pt,\n",
    "    igate_preact=igs_pt,\n",
    "    fgate_preact=fgs_pt,\n",
    "    eps=EPS,\n",
    ")\n",
    "rs_scaled = mh_layernorm(rs)\n",
    "rs_scaled, rs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "((rs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.shape # (B, NH, S, DH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3274e-05,  1.0109e-05,  3.6511e-05, -1.6533e-05],\n",
       "          [ 5.3569e-01,  2.4857e+00,  3.0122e+00, -1.4810e+00],\n",
       "          [-6.8308e+00,  7.2907e+00,  2.5978e+00,  2.0262e-01],\n",
       "          [ 8.0473e-02, -3.9897e-01,  8.5354e-02,  2.3112e-02],\n",
       "          [ 2.6339e+00,  1.2841e+00,  7.9257e-01, -3.0563e+00],\n",
       "          [ 3.3218e+00, -5.3795e+00,  3.3445e+00,  3.0653e+00],\n",
       "          [ 1.2528e+00, -9.5476e-01,  2.2962e+00, -2.4906e-01],\n",
       "          [ 1.1260e+00, -8.5640e-01,  1.0127e-01, -4.8459e-01]]]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs2 = rs#.transpose(1, 2)\n",
    "rs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.2508, -1.1810, -0.7554,  0.6856],\n",
       "           [-1.4225, -0.2860,  1.3208,  0.3877],\n",
       "           [ 1.1236,  0.4122, -1.6011,  0.0653],\n",
       "           [ 0.9885, -0.1728, -1.5612,  0.7455],\n",
       "           [ 0.8213, -1.0949, -0.8853,  1.1589],\n",
       "           [-0.8941,  0.1563,  1.5739, -0.8361],\n",
       "           [-1.4935,  0.9028,  0.9198, -0.3292],\n",
       "           [-1.6608,  0.7769,  0.0900,  0.7939]]]], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<DivBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 = (rs2 - rs2.mean(-1, keepdim=True)) / rs2.std(-1, keepdim=True, unbiased=False)\n",
    "# rs4 = rs3.transpose(1, 2)\n",
    "rs3, rs3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.4372e-06, -1.3570e-06, -8.6796e-07,  7.8776e-07],\n",
       "          [-1.8984e-06, -3.8173e-07,  1.7627e-06,  5.1739e-07],\n",
       "          [ 1.8660e-06,  6.8450e-07, -2.6590e-06,  1.0852e-07],\n",
       "          [ 2.5576e-08, -4.4698e-09, -4.0394e-08,  1.9289e-08],\n",
       "          [ 1.5123e-06, -2.0160e-06, -1.6302e-06,  2.1339e-06],\n",
       "          [-7.6744e-07,  1.3418e-07,  1.3509e-06, -7.1761e-07],\n",
       "          [-1.6035e-06,  9.6934e-07,  9.8759e-07, -3.5345e-07],\n",
       "          [-1.0968e-06,  5.1307e-07,  5.9439e-08,  5.2432e-07]]]],\n",
       "       device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 - rs_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_obw = fgs.clone().detach().requires_grad_(True)\n",
    "igs_obw = igs.clone().detach().requires_grad_(True)\n",
    "qs_obw = qs.clone().detach().requires_grad_(True)\n",
    "ks_obw = ks.clone().detach().requires_grad_(True)\n",
    "vs_obw = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.2508, -1.1810, -0.7554,  0.6856],\n",
       "           [-1.4225, -0.2860,  1.3208,  0.3877],\n",
       "           [ 1.1236,  0.4122, -1.6011,  0.0653],\n",
       "           [ 0.9885, -0.1728, -1.5612,  0.7455],\n",
       "           [ 0.8213, -1.0949, -0.8853,  1.1589],\n",
       "           [-0.8941,  0.1563,  1.5739, -0.8361],\n",
       "           [-1.4935,  0.9028,  0.9198, -0.3292],\n",
       "           [-1.6608,  0.7769,  0.0900,  0.7939]]]], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs, var_b, var_m = vlstm_parallel_fwbw_torch_w_groupnorm(\n",
    "    queries=qs_obw,\n",
    "    keys=ks_obw,\n",
    "    values=vs_obw,\n",
    "    igate_preact=igs_obw,\n",
    "    fgate_preact=fgs_obw,\n",
    "    eps=EPS,\n",
    ")\n",
    "hs, hs.shape\n",
    "hs_scaled = mh_layernorm(hs)\n",
    "hs_scaled, hs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_scaled - rs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 1.9281e-05],\n",
      "          [ 0.0000e+00],\n",
      "          [-5.1218e-06],\n",
      "          [-2.0799e-06]]]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "((hs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.3274e-05,  1.0109e-05,  3.6511e-05, -1.6533e-05],\n",
       "           [ 5.3569e-01,  2.4857e+00,  3.0122e+00, -1.4810e+00],\n",
       "           [-6.8308e+00,  7.2907e+00,  2.5978e+00,  2.0262e-01],\n",
       "           [ 8.0473e-02, -3.9897e-01,  8.5354e-02,  2.3112e-02],\n",
       "           [ 2.6339e+00,  1.2841e+00,  7.9257e-01, -3.0563e+00],\n",
       "           [ 3.3218e+00, -5.3795e+00,  3.3445e+00,  3.0653e+00],\n",
       "           [ 1.2528e+00, -9.5476e-01,  2.2962e+00, -2.4906e-01],\n",
       "           [ 1.1260e+00, -8.5641e-01,  1.0126e-01, -4.8459e-01]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 1.3274e-05,  1.0109e-05,  3.6511e-05, -1.6533e-05],\n",
       "           [ 5.3569e-01,  2.4857e+00,  3.0122e+00, -1.4810e+00],\n",
       "           [-6.8308e+00,  7.2907e+00,  2.5978e+00,  2.0262e-01],\n",
       "           [ 8.0473e-02, -3.9897e-01,  8.5354e-02,  2.3112e-02],\n",
       "           [ 2.6339e+00,  1.2841e+00,  7.9257e-01, -3.0563e+00],\n",
       "           [ 3.3218e+00, -5.3795e+00,  3.3445e+00,  3.0653e+00],\n",
       "           [ 1.2528e+00, -9.5476e-01,  2.2962e+00, -2.4906e-01],\n",
       "           [ 1.1260e+00, -8.5640e-01,  1.0127e-01, -4.8459e-01]]]],\n",
       "        device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad, qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.4916],\n",
       "           [0.3684],\n",
       "           [0.1097],\n",
       "           [0.2194],\n",
       "           [0.9885],\n",
       "           [0.0628],\n",
       "           [1.3290],\n",
       "           [2.0126]]]], device='cuda:0', dtype=torch.float64,\n",
       "        grad_fn=<AbsBackward0>),\n",
       " tensor([[[[0.6603],\n",
       "           [0.5352],\n",
       "           [0.3983],\n",
       "           [0.6340],\n",
       "           [0.4514],\n",
       "           [0.6290],\n",
       "           [0.3836],\n",
       "           [0.7017]]]], device='cuda:0', dtype=torch.float64,\n",
       "        grad_fn=<ExpBackward0>),\n",
       " tensor([[[[ True],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [False],\n",
       "           [ True],\n",
       "           [False],\n",
       "           [False]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_b.abs(), torch.exp(-var_m), var_b.abs() < torch.exp(-var_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.8937e-06, -1.0558e-05, -2.7356e-06,  1.5993e-05],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-6.0601e-07, -9.2155e-07,  4.0914e-06, -5.0413e-07],\n",
       "          [-1.2725e-06,  1.7485e-06,  5.4959e-06,  8.2998e-07]]]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad - qs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.6995e-17],\n",
       "          [-2.3993e-07],\n",
       "          [ 9.2670e-07],\n",
       "          [ 1.9190e-06],\n",
       "          [-3.1642e-06],\n",
       "          [-1.1329e-06],\n",
       "          [-1.9609e-06],\n",
       "          [-1.3309e-06]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_pt.grad - fgs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(qs_pt.grad, qs_obw.grad, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusion: \n",
    "# dividing we get the same gradients, the error -1e-5 is due to numerical precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([[[[-3.7828e-17, -2.8809e-17, -1.0405e-16,  4.7115e-17],\n",
    "#           [-1.1102e-16, -4.4409e-16, -8.8818e-16,  4.4409e-16],\n",
    "#           [ 8.8818e-16, -8.8818e-16,  0.0000e+00, -8.3267e-17],\n",
    "#           [ 1.2490e-16, -5.5511e-17,  1.3878e-17, -1.7347e-17],\n",
    "#           [ 1.8937e-06, -1.0558e-05, -2.7356e-06,  1.5993e-05],\n",
    "#           [ 4.4409e-16,  0.0000e+00,  1.3323e-15,  0.0000e+00],\n",
    "#           [-6.0601e-07, -9.2155e-07,  4.0914e-06, -5.0413e-07],\n",
    "#           [-1.2725e-06,  1.7485e-06,  5.4959e-06,  8.2998e-07]]]],\n",
    "#        device='cuda:0', dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt220cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
