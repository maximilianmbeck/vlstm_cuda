{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch vLSTM forward with group norm (headwise layernorm)\n",
    "\n",
    "Shows what happens if we fuse the multihead layernorm with the vlstm kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from vlstm_parallel_tiled import vlstm_parallel_tiled\n",
    "from vlstm_parallel import vlstm_parallel_fw_torch\n",
    "from vlstm_parallel_w_groupnorm import vlstm_parallel_fw_torch_w_groupnorm, vlstm_parallel_fwbw_torch_w_groupnorm\n",
    "from ln import MultiHeadLayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "S = 8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 4 # dim per head\n",
    "DTYPE = torch.float64\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "EPS = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 8, 4]), torch.Size([1, 1, 8, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(1)\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "igs = torch.rand((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "igs2 = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1)\n",
    "fgs = torch.rand((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "qs.shape, fgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 3.* torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0., 0., 0., 0.], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_layernorm = MultiHeadLayerNorm(NH*DH, eps=1e-6).to(device=DEVICE, dtype=DTYPE)\n",
    "mh_layernorm.weight, mh_layernorm.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_pt = fgs.clone().detach().requires_grad_(True)\n",
    "igs_pt = igs.clone().detach().requires_grad_(True)\n",
    "qs_pt = qs.clone().detach().requires_grad_(True)\n",
    "ks_pt = ks.clone().detach().requires_grad_(True)\n",
    "vs_pt = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = vlstm_fw_torch(\n",
    "#     queries=qs,\n",
    "#     keys=ks,\n",
    "#     values=vs,\n",
    "#     igate_preact=igs,\n",
    "#     fgate_preact=fgs,\n",
    "#     stabilize_rowwise=True,\n",
    "# )\n",
    "# rs, rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4225],\n",
       "           [ 0.7400,  1.0432, -0.2694, -1.5138],\n",
       "           [ 0.4508,  1.3221, -1.3749, -0.3980],\n",
       "           [ 1.3565, -0.7354, -1.1550,  0.5340],\n",
       "           [ 1.5541, -0.6481, -1.0672,  0.1612],\n",
       "           [ 1.1217, -1.5834,  0.4839, -0.0223],\n",
       "           [ 0.5463, -1.4683,  1.2095, -0.2875],\n",
       "           [ 1.6076, -0.0882, -1.1156, -0.4038]]]], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = vlstm_parallel_fw_torch(\n",
    "    queries=qs_pt,\n",
    "    keys=ks_pt,\n",
    "    values=vs_pt,\n",
    "    igate_preact=igs_pt,\n",
    "    fgate_preact=fgs_pt,\n",
    "    eps=EPS,\n",
    ")\n",
    "rs_scaled = mh_layernorm(rs)\n",
    "rs_scaled, rs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "((rs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.shape # (B, NH, S, DH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.6576e-04,  5.0582e-04,  3.3532e-04, -6.0494e-04],\n",
       "          [-7.7297e-01,  9.4263e-01, -6.7030e-01, -1.0986e+00],\n",
       "          [ 4.6686e-01, -1.0144e-01, -7.7629e-01, -7.6172e-02],\n",
       "          [ 3.4602e+00, -8.3292e+00, -8.0756e+00, -8.4937e+00],\n",
       "          [ 1.3444e+00, -4.4481e-01,  1.1625e+00, -1.3412e+00],\n",
       "          [-1.9742e+01, -6.0909e+00, -1.7204e+01, -8.8154e+00],\n",
       "          [-7.0999e+00,  1.6160e+00,  7.0835e+00, -5.7153e-02],\n",
       "          [ 5.5990e+00, -2.8259e-01, -1.5718e+01, -2.6351e+00]]]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs2 = rs#.transpose(1, 2)\n",
    "rs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.7400,  1.0432, -0.2694, -1.5138],\n",
       "           [ 0.4508,  1.3221, -1.3749, -0.3980],\n",
       "           [ 1.3565, -0.7354, -1.1550,  0.5340],\n",
       "           [ 1.5541, -0.6481, -1.0672,  0.1612],\n",
       "           [ 1.1217, -1.5834,  0.4839, -0.0223],\n",
       "           [ 0.5463, -1.4683,  1.2095, -0.2875],\n",
       "           [ 1.6076, -0.0882, -1.1156, -0.4038]]]], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<DivBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 = (rs2 - rs2.mean(-1, keepdim=True)) / rs2.std(-1, keepdim=True, unbiased=False)\n",
    "# rs4 = rs3.transpose(1, 2)\n",
    "rs3, rs3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-3.8469e-06,  1.7901e-05,  5.2088e-06, -1.9262e-05],\n",
       "          [ 1.0619e-06,  1.4970e-06, -3.8655e-07, -2.1723e-06],\n",
       "          [ 2.6418e-07,  7.7482e-07, -8.0577e-07, -2.3323e-07],\n",
       "          [ 5.2545e-06, -2.8487e-06, -4.4742e-06,  2.0684e-06],\n",
       "          [ 9.5230e-07, -3.9714e-07, -6.5392e-07,  9.8760e-08],\n",
       "          [ 8.9679e-07, -1.2658e-06,  3.8687e-07, -1.7821e-08],\n",
       "          [ 2.1787e-07, -5.8553e-07,  4.8230e-07, -1.1463e-07],\n",
       "          [ 6.1161e-06, -3.3540e-07, -4.2443e-06, -1.5364e-06]]]],\n",
       "       device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 - rs_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_obw = fgs.clone().detach().requires_grad_(True)\n",
    "igs_obw = igs.clone().detach().requires_grad_(True)\n",
    "qs_obw = qs.clone().detach().requires_grad_(True)\n",
    "ks_obw = ks.clone().detach().requires_grad_(True)\n",
    "vs_obw = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4225],\n",
       "           [ 0.7400,  1.0432, -0.2694, -1.5138],\n",
       "           [ 0.4508,  1.3221, -1.3749, -0.3980],\n",
       "           [ 1.3565, -0.7354, -1.1550,  0.5340],\n",
       "           [ 1.5541, -0.6481, -1.0672,  0.1612],\n",
       "           [ 1.1217, -1.5834,  0.4839, -0.0223],\n",
       "           [ 0.5463, -1.4683,  1.2095, -0.2875],\n",
       "           [ 1.6076, -0.0882, -1.1156, -0.4038]]]], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs, var_b, var_m = vlstm_parallel_fwbw_torch_w_groupnorm(\n",
    "    queries=qs_obw,\n",
    "    keys=ks_obw,\n",
    "    values=vs_obw,\n",
    "    igate_preact=igs_obw,\n",
    "    fgate_preact=fgs_obw,\n",
    "    eps=EPS,\n",
    ")\n",
    "hs, hs.shape\n",
    "hs_scaled = mh_layernorm(hs)\n",
    "hs_scaled, hs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_scaled - rs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000e+00],\n",
      "          [0.0000e+00],\n",
      "          [7.1797e-06],\n",
      "          [0.0000e+00],\n",
      "          [1.2116e-05],\n",
      "          [3.1064e-05],\n",
      "          [1.6215e-05],\n",
      "          [0.0000e+00]]]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "((hs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-7.6576e-04,  5.0582e-04,  3.3532e-04, -6.0494e-04],\n",
       "           [-7.7297e-01,  9.4263e-01, -6.7030e-01, -1.0986e+00],\n",
       "           [ 4.6686e-01, -1.0144e-01, -7.7628e-01, -7.6160e-02],\n",
       "           [ 3.4602e+00, -8.3292e+00, -8.0756e+00, -8.4937e+00],\n",
       "           [ 1.3444e+00, -4.4479e-01,  1.1625e+00, -1.3412e+00],\n",
       "           [-1.9742e+01, -6.0909e+00, -1.7204e+01, -8.8154e+00],\n",
       "           [-7.0999e+00,  1.6160e+00,  7.0835e+00, -5.7152e-02],\n",
       "           [ 5.5990e+00, -2.8259e-01, -1.5718e+01, -2.6351e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-7.6576e-04,  5.0582e-04,  3.3532e-04, -6.0494e-04],\n",
       "           [-7.7297e-01,  9.4263e-01, -6.7030e-01, -1.0986e+00],\n",
       "           [ 4.6686e-01, -1.0144e-01, -7.7629e-01, -7.6172e-02],\n",
       "           [ 3.4602e+00, -8.3292e+00, -8.0756e+00, -8.4937e+00],\n",
       "           [ 1.3444e+00, -4.4481e-01,  1.1625e+00, -1.3412e+00],\n",
       "           [-1.9742e+01, -6.0909e+00, -1.7204e+01, -8.8154e+00],\n",
       "           [-7.0999e+00,  1.6160e+00,  7.0835e+00, -5.7153e-02],\n",
       "           [ 5.5990e+00, -2.8259e-01, -1.5718e+01, -2.6351e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad, qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.2209],\n",
       "           [0.2700],\n",
       "           [1.5735],\n",
       "           [0.5737],\n",
       "           [1.5030],\n",
       "           [0.8177],\n",
       "           [0.9032],\n",
       "           [0.1300]]]], device='cuda:0', dtype=torch.float64,\n",
       "        grad_fn=<AbsBackward0>),\n",
       " tensor([[[[0.9641],\n",
       "           [0.4819],\n",
       "           [0.6707],\n",
       "           [0.6399],\n",
       "           [0.5793],\n",
       "           [0.4735],\n",
       "           [0.3951],\n",
       "           [0.6694]]]], device='cuda:0', dtype=torch.float64,\n",
       "        grad_fn=<ExpBackward0>),\n",
       " tensor([[[[False],\n",
       "           [False],\n",
       "           [ True],\n",
       "           [False],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [False]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_b.abs(), torch.exp(-var_m), var_b.abs() > torch.exp(-var_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [-1.5314e-06,  1.1898e-06, -4.0425e-06, -1.1652e-05],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 6.4882e-06, -1.3727e-05,  6.1535e-06, -1.6513e-05],\n",
       "           [ 3.1307e-05, -1.2041e-05,  1.1293e-05,  1.6676e-06],\n",
       "           [ 2.7021e-06, -1.6586e-06,  1.1334e-05, -1.3535e-06],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 1.6914e-06,  8.2518e-07,  1.4939e-06,  1.6078e-06],\n",
       "           [ 5.2692e-06,  2.5707e-06,  4.6539e-06,  5.0088e-06],\n",
       "           [ 6.8855e-06,  3.3593e-06,  6.0815e-06,  6.5453e-06],\n",
       "           [ 5.3227e-07,  1.3101e-05,  4.5358e-06,  8.8716e-07],\n",
       "           [ 8.7948e-07,  2.1647e-05,  7.4946e-06,  1.4659e-06],\n",
       "           [-1.2351e-05,  9.8664e-06,  5.1246e-06, -8.8750e-06],\n",
       "           [-6.2944e-06,  5.1208e-06, -7.5627e-06, -1.0601e-05],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-1.7764e-15,  0.0000e+00, -7.9797e-17,  8.8818e-16],\n",
       "           [ 2.2204e-16,  0.0000e+00, -4.4409e-16,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -8.8818e-16],\n",
       "           [ 0.0000e+00,  4.4409e-16,  8.8818e-16, -8.8818e-16],\n",
       "           [ 0.0000e+00,  0.0000e+00, -4.4409e-16,  0.0000e+00],\n",
       "           [ 8.8818e-16,  0.0000e+00,  0.0000e+00,  1.7764e-15],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.2204e-16],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad - qs_obw.grad, ks_pt.grad - ks_obw.grad, vs_pt.grad - vs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-6.0397e-16],\n",
       "           [-2.7182e-07],\n",
       "           [ 7.4923e-07],\n",
       "           [-5.8534e-07],\n",
       "           [-1.2563e-05],\n",
       "           [-7.5149e-07],\n",
       "           [-5.3494e-06],\n",
       "           [ 2.0817e-16]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-7.5963e-07],\n",
       "           [ 2.4240e-06],\n",
       "           [-2.0677e-05],\n",
       "           [-3.6671e-05],\n",
       "           [ 8.3042e-06],\n",
       "           [-3.4175e-05],\n",
       "           [ 2.4098e-06],\n",
       "           [ 0.0000e+00]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_pt.grad - fgs_obw.grad, igs_pt.grad - igs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(qs_pt.grad, qs_obw.grad, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusion: \n",
    "# dividing we get the same gradients, the error -1e-5 is due to numerical precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([[[[-3.7828e-17, -2.8809e-17, -1.0405e-16,  4.7115e-17],\n",
    "#           [-1.1102e-16, -4.4409e-16, -8.8818e-16,  4.4409e-16],\n",
    "#           [ 8.8818e-16, -8.8818e-16,  0.0000e+00, -8.3267e-17],\n",
    "#           [ 1.2490e-16, -5.5511e-17,  1.3878e-17, -1.7347e-17],\n",
    "#           [ 1.8937e-06, -1.0558e-05, -2.7356e-06,  1.5993e-05],\n",
    "#           [ 4.4409e-16,  0.0000e+00,  1.3323e-15,  0.0000e+00],\n",
    "#           [-6.0601e-07, -9.2155e-07,  4.0914e-06, -5.0413e-07],\n",
    "#           [-1.2725e-06,  1.7485e-06,  5.4959e-06,  8.2998e-07]]]],\n",
    "#        device='cuda:0', dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt220cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
