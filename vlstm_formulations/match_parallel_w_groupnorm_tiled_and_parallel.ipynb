{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_printoptions(linewidth=200, threshold=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch vLSTM backward with group norm tiled (headwise layernorm)\n",
    "\n",
    "Shows what happens if we fuse the multihead layernorm with the vlstm kernel.\n",
    "Here we compare the tiled impl (template for triton&cuda kernels) with the parallel impl and check for numerical correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from vlstm_parallel_tiled import vlstm_parallel_tiled\n",
    "from vlstm_parallel_w_groupnorm import vlstm_parallel_bw_torch_w_groupnorm, vlstm_parallel_fwbw_torch_w_groupnorm, vlstm_parallel_fwbw_torch_w_groupnorm_full\n",
    "from vlstm_parallel import vlstm_parallel_fw_torch\n",
    "\n",
    "from vlstm_parallel_w_groupnorm_tiled_bw import mlstm_parallel_w_groupnorm_torch_tiled_bw, vlstm_parallel_w_groupnorm_torch_bw, construct_log_gate_matrix_tiled\n",
    "\n",
    "from ln import MultiHeadLayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BW parallel with groupnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "S = 8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 4 # dim per head\n",
    "DTYPE = torch.float64\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "EPS = 0.0\n",
    "\n",
    "BLOCK_Q = 16\n",
    "BLOCK_KV = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 8, 4]), torch.Size([1, 1, 8, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# forward inputs\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "# igs2 = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# backward inputs\n",
    "dH = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vecN = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "vecM = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "qs.shape, fgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 3.* torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0., 0., 0., 0.], device='cuda:0', dtype=torch.float64, requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_layernorm = MultiHeadLayerNorm(NH*DH, eps=1e-6).to(device=DEVICE, dtype=DTYPE)\n",
    "mh_layernorm.weight, mh_layernorm.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_pt = fgs.clone().detach().requires_grad_(True)\n",
    "igs_pt = igs.clone().detach().requires_grad_(True)\n",
    "qs_pt = qs.clone().detach().requires_grad_(True)\n",
    "ks_pt = ks.clone().detach().requires_grad_(True)\n",
    "vs_pt = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = vlstm_fw_torch(\n",
    "#     queries=qs,\n",
    "#     keys=ks,\n",
    "#     values=vs,\n",
    "#     igate_preact=igs,\n",
    "#     fgate_preact=fgs,\n",
    "#     stabilize_rowwise=True,\n",
    "# )\n",
    "# rs, rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = vlstm_parallel_fw_torch(\n",
    "    queries=qs_pt,\n",
    "    keys=ks_pt,\n",
    "    values=vs_pt,\n",
    "    igate_preact=igs_pt,\n",
    "    fgate_preact=fgs_pt,\n",
    "    eps=EPS,\n",
    ")\n",
    "rs_scaled = mh_layernorm(rs)\n",
    "rs_scaled, rs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "((rs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.shape # (B, NH, S, DH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "          [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "          [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "          [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "          [ 9.8784e-01, -4.8033e-01,  1.2925e+00, -9.1624e-01],\n",
       "          [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "          [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "          [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs2 = rs#.transpose(1, 2)\n",
    "rs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5336],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 = (rs2 - rs2.mean(-1, keepdim=True)) / rs2.std(-1, keepdim=True, unbiased=False)\n",
    "# rs4 = rs3.transpose(1, 2)\n",
    "rs3, rs3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.4993e-07,  3.4896e-06,  1.0154e-06, -3.7551e-06],\n",
       "          [ 3.4323e-06,  5.8879e-06, -1.0780e-06, -8.2422e-06],\n",
       "          [ 2.2965e-06,  3.4939e-06, -4.9360e-06, -8.5439e-07],\n",
       "          [ 2.5082e-06, -1.6520e-06, -8.3956e-07, -1.6605e-08],\n",
       "          [ 1.5938e-06, -9.8798e-07, -5.6463e-07, -4.1209e-08],\n",
       "          [ 1.0009e-06, -1.6121e-06,  6.8374e-07, -7.2535e-08],\n",
       "          [ 5.5659e-07, -1.1214e-06,  7.5538e-07, -1.9061e-07],\n",
       "          [ 3.9179e-06, -4.7970e-06,  2.4964e-05, -2.4085e-05]]]], device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 - rs_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_obw = fgs.clone().detach().requires_grad_(True)\n",
    "igs_obw = igs.clone().detach().requires_grad_(True)\n",
    "qs_obw = qs.clone().detach().requires_grad_(True)\n",
    "ks_obw = ks.clone().detach().requires_grad_(True)\n",
    "vs_obw = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs, var_b, var_m = vlstm_parallel_fwbw_torch_w_groupnorm_full(\n",
    "    queries=qs_obw,\n",
    "    keys=ks_obw,\n",
    "    values=vs_obw,\n",
    "    igate_preact=igs_obw,\n",
    "    fgate_preact=fgs_obw,\n",
    "    eps=EPS,\n",
    ")\n",
    "hs, hs.shape\n",
    "hs_scaled = mh_layernorm(hs)\n",
    "hs_scaled, hs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_scaled - rs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [-4.0645e-06],\n",
      "          [ 6.1824e-06],\n",
      "          [ 1.0703e-05],\n",
      "          [ 0.0000e+00]]]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "((hs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8033e-01,  1.2925e+00, -9.1624e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad, qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.2209],\n",
       "           [0.3124],\n",
       "           [0.8088],\n",
       "           [0.3172],\n",
       "           [2.6139],\n",
       "           [1.0345],\n",
       "           [1.5021],\n",
       "           [0.4596]]]], device='cuda:0', dtype=torch.float64, grad_fn=<AbsBackward0>),\n",
       " tensor([[[[0.4257],\n",
       "           [1.0288],\n",
       "           [1.6999],\n",
       "           [0.3699],\n",
       "           [0.5299],\n",
       "           [0.7055],\n",
       "           [1.1781],\n",
       "           [0.5167]]]], device='cuda:0', dtype=torch.float64, grad_fn=<ExpBackward0>),\n",
       " tensor([[[[False],\n",
       "           [False],\n",
       "           [False],\n",
       "           [False],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [False]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_b.abs(), torch.exp(-var_m), var_b.abs() > torch.exp(-var_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [-2.5606e-06,  1.4259e-05, -3.7683e-07,  6.6377e-06],\n",
       "           [ 7.3301e-06, -4.2211e-06,  1.7718e-06,  1.7949e-06],\n",
       "           [ 6.4459e-06, -5.9048e-06,  1.1989e-05,  1.4505e-06],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-1.3196e-07, -1.1467e-07, -7.7522e-08, -1.3573e-07],\n",
       "           [-2.0452e-07, -1.7772e-07, -1.2015e-07, -2.1036e-07],\n",
       "           [-8.9864e-08, -7.8086e-08, -5.2791e-08, -9.2430e-08],\n",
       "           [-7.8008e-06, -6.7784e-06, -4.5826e-06, -8.0236e-06],\n",
       "           [-1.4118e-06, -1.2267e-06, -8.2935e-07, -1.4521e-06],\n",
       "           [-7.6242e-06,  6.1568e-06, -4.1334e-06, -9.8372e-06],\n",
       "           [-6.9098e-06,  5.6214e-06, -8.3021e-06, -1.1637e-05],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 0.0000e+00,  0.0000e+00, -2.2204e-16,  4.4409e-16],\n",
       "           [ 0.0000e+00,  0.0000e+00,  5.5511e-17,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00, -4.4409e-16,  0.0000e+00],\n",
       "           [-1.1102e-16,  0.0000e+00,  0.0000e+00, -2.2204e-16],\n",
       "           [-4.4409e-16,  0.0000e+00,  0.0000e+00,  8.8818e-16],\n",
       "           [-8.8818e-16,  0.0000e+00, -5.0307e-17,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad - qs_obw.grad, ks_pt.grad - ks_obw.grad, vs_pt.grad - vs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 6.0959e-16],\n",
       "           [ 4.0919e-08],\n",
       "           [ 5.5045e-09],\n",
       "           [ 2.2432e-07],\n",
       "           [ 7.5696e-06],\n",
       "           [-2.4253e-06],\n",
       "           [-1.4291e-05],\n",
       "           [-1.1102e-16]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 5.5821e-08],\n",
       "           [-4.1876e-08],\n",
       "           [ 2.4110e-07],\n",
       "           [ 2.4811e-05],\n",
       "           [-9.3009e-07],\n",
       "           [-2.9778e-05],\n",
       "           [ 2.6454e-06],\n",
       "           [-3.5527e-15]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_pt.grad - fgs_obw.grad, igs_pt.grad - igs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(qs_pt.grad, qs_obw.grad, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward match: True\n",
      "qs match: True\n",
      "ks match: True\n",
      "vs match: True\n",
      "fgate_preacts match: True\n",
      "igate_preacts match: True\n"
     ]
    }
   ],
   "source": [
    "atol = 1e-5\n",
    "rtol = 1e-5\n",
    "print(f\"Forward match: {torch.allclose(hs_scaled, rs_scaled)}\")\n",
    "print(f\"qs match: {torch.allclose(qs_pt.grad, qs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"ks match: {torch.allclose(ks_pt.grad, ks_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"vs match: {torch.allclose(vs_pt.grad, vs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"fgate_preacts match: {torch.allclose(fgs_pt.grad, fgs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"igate_preacts match: {torch.allclose(igs_pt.grad, igs_obw.grad, atol=atol, rtol=rtol)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusion: \n",
    "# dividing we get the same gradients, the error -1e-5 is due to numerical precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([[[[-3.7828e-17, -2.8809e-17, -1.0405e-16,  4.7115e-17],\n",
    "#           [-1.1102e-16, -4.4409e-16, -8.8818e-16,  4.4409e-16],\n",
    "#           [ 8.8818e-16, -8.8818e-16,  0.0000e+00, -8.3267e-17],\n",
    "#           [ 1.2490e-16, -5.5511e-17,  1.3878e-17, -1.7347e-17],\n",
    "#           [ 1.8937e-06, -1.0558e-05, -2.7356e-06,  1.5993e-05],\n",
    "#           [ 4.4409e-16,  0.0000e+00,  1.3323e-15,  0.0000e+00],\n",
    "#           [-6.0601e-07, -9.2155e-07,  4.0914e-06, -5.0413e-07],\n",
    "#           [-1.2725e-06,  1.7485e-06,  5.4959e-06,  8.2998e-07]]]],\n",
    "#        device='cuda:0', dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own backward2\n",
    "\n",
    "Reimplementation by using separate function for fw and bw which serve as ground truth for kernel impl.\n",
    "They should match exactly own backward(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_obw2 = fgs.clone().detach().requires_grad_(True)\n",
    "igs_obw2 = igs.clone().detach().requires_grad_(True)\n",
    "qs_obw2 = qs.clone().detach().requires_grad_(True)\n",
    "ks_obw2 = ks.clone().detach().requires_grad_(True)\n",
    "vs_obw2 = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs2, var_b2, var_m2 = vlstm_parallel_fwbw_torch_w_groupnorm(\n",
    "    queries=qs_obw2,\n",
    "    keys=ks_obw2,\n",
    "    values=vs_obw2,\n",
    "    igate_preact=igs_obw2,\n",
    "    fgate_preact=fgs_obw2,\n",
    "    eps=EPS,\n",
    ")\n",
    "hs2, hs2.shape\n",
    "hs_scaled2 = mh_layernorm(hs2)\n",
    "hs_scaled2, hs_scaled2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_scaled - hs_scaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "((hs_scaled2+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-1.3020e-10,  8.6005e-11,  5.7015e-11, -1.0286e-10],\n",
       "           [ 5.3706e-07, -6.5505e-07,  4.6599e-07,  7.6344e-07],\n",
       "           [-2.5350e-06,  3.9298e-07,  4.4202e-06,  2.0236e-07],\n",
       "           [-7.5124e-07,  3.8170e-06, -5.5758e-07, -1.4132e-07],\n",
       "           [ 3.7791e-07, -1.8376e-07,  4.9448e-07, -3.5052e-07],\n",
       "           [-4.0115e-06, -4.4232e-06, -1.8519e-06, -4.1562e-06],\n",
       "           [ 9.0684e-07,  2.0908e-07, -1.0949e-06,  3.4366e-07],\n",
       "           [-4.9801e-05,  2.0900e-05, -4.6278e-05, -1.7950e-05]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 6.1895e-06, -2.2341e-06,  1.7210e-06,  2.6788e-06],\n",
       "           [ 3.8116e-06, -2.7216e-06,  2.7156e-06,  6.0842e-06],\n",
       "           [ 8.4303e-08,  4.1735e-07, -5.1106e-07, -2.3957e-07],\n",
       "           [-8.9174e-06, -1.0295e-05, -3.8709e-06,  2.0779e-05],\n",
       "           [ 1.4558e-06,  2.0089e-06,  4.3810e-07, -1.9617e-06],\n",
       "           [-1.6445e-05, -2.9992e-05, -1.6734e-05,  5.6504e-05],\n",
       "           [-1.6525e-05, -2.8659e-05, -1.3668e-05,  5.5794e-05],\n",
       "           [ 3.1712e-06,  5.0606e-06,  2.6874e-06, -9.8349e-06]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-3.8741e-06, -3.8724e-06,  5.7541e-06,  1.9924e-06],\n",
       "           [ 7.1809e-07,  4.7887e-07, -9.5332e-07, -2.4364e-07],\n",
       "           [ 1.2931e-06, -2.6308e-06, -2.0233e-06,  3.3611e-06],\n",
       "           [ 9.3499e-07,  1.3951e-05, -2.2263e-05,  7.3768e-06],\n",
       "           [ 1.5885e-06, -2.7415e-06,  7.5294e-08,  1.0777e-06],\n",
       "           [-4.5426e-06,  1.5047e-05, -3.0964e-06, -7.4076e-06],\n",
       "           [ 1.0900e-05, -1.7300e-05,  3.5894e-07,  6.0407e-06],\n",
       "           [-4.9925e-05,  7.8684e-05, -2.4389e-06, -2.6320e-05]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad - qs_obw2.grad, ks_obw.grad - ks_obw2.grad, vs_obw.grad - vs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00],\n",
       "           [-2.8527e-06],\n",
       "           [-7.4537e-07],\n",
       "           [-5.4030e-07],\n",
       "           [ 1.7050e-07],\n",
       "           [ 1.9369e-06],\n",
       "           [ 1.4342e-05],\n",
       "           [ 1.2706e-06]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-3.8915e-06],\n",
       "           [ 2.0035e-06],\n",
       "           [ 1.2739e-06],\n",
       "           [ 1.1791e-06],\n",
       "           [ 2.3387e-06],\n",
       "           [ 2.3987e-05],\n",
       "           [-2.0978e-05],\n",
       "           [-5.9123e-06]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_obw.grad - fgs_obw2.grad, igs_obw.grad - igs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7786e-01,  1.4118e+00, -2.0623e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-1.3020e-10,  8.6005e-11,  5.7015e-11, -1.0286e-10],\n",
       "           [ 5.3706e-07, -6.5505e-07,  4.6599e-07,  7.6344e-07],\n",
       "           [-2.5350e-06,  3.9298e-07,  4.4202e-06,  2.0236e-07],\n",
       "           [-7.5124e-07,  3.8170e-06, -5.5758e-07, -1.4132e-07],\n",
       "           [ 3.7791e-07, -1.8376e-07,  4.9448e-07, -3.5052e-07],\n",
       "           [-4.0115e-06, -4.4232e-06, -1.8519e-06, -4.1562e-06],\n",
       "           [ 9.0684e-07,  2.0908e-07, -1.0949e-06,  3.4366e-07],\n",
       "           [-4.9801e-05,  2.0900e-05, -4.6278e-05, -1.7950e-05]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad, qs_obw2.grad, qs_obw.grad - qs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: the impls match, the error is max 1e-5 is due to numerical precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BW parallel TILED with groupnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "S = 32 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 4 # dim per head\n",
    "DTYPE = torch.float64\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "EPS = 0.0\n",
    "\n",
    "BLOCK_Q = 16\n",
    "BLOCK_KV = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 32, 4]), torch.Size([1, 1, 32, 1]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# forward inputs\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "# igs2 = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# backward inputs\n",
    "dH = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vecN = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "vecM = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "qs.shape, fgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dQ_pt_p, dK_pt_p, dV_pt_p, dI_pt_p, dF_pt_p = vlstm_parallel_w_groupnorm_torch_bw(matDeltaHtilde=dH, matQ=qs, matK=ks, matV=vs, vecN=vecN, vecM=vecM, vecI=igs, vecF=fgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 7.5400e-01, -4.9806e-01, -3.3017e-01,  5.9565e-01],\n",
       "           [-6.7514e-02,  4.3178e-02,  3.2875e-02, -5.1733e-02],\n",
       "           [ 1.1512e-02, -3.2063e-02,  8.4872e-02,  1.1490e-01],\n",
       "           [ 7.4273e+00, -5.7824e+01, -7.5553e-01, -2.4850e+01],\n",
       "           [-2.6519e-01,  3.6867e+00,  5.8413e-01,  1.3191e+00],\n",
       "           [-2.7861e+00, -1.4612e-01, -8.6080e-01, -1.5563e+00],\n",
       "           [ 1.9155e+01, -6.8366e+00, -7.8849e+00,  5.2391e+00],\n",
       "           [-1.4842e+00, -3.2384e+00,  1.4640e+00, -4.3700e-01],\n",
       "           [ 5.3037e-01,  1.1785e+00, -3.6594e-01,  2.6766e-01],\n",
       "           [-4.5050e-01,  6.4523e+00, -2.3888e+00,  6.8275e-01],\n",
       "           [ 4.8508e-02,  1.4290e-02, -1.7072e-03,  4.6091e-02],\n",
       "           [-1.4577e+01,  7.8521e-02,  1.3548e+01,  4.6773e+00],\n",
       "           [ 7.2648e+00,  9.2629e+00, -4.1493e+00, -5.6710e+00],\n",
       "           [-1.1986e+00, -3.2646e+00,  1.5351e-01,  1.7021e+00],\n",
       "           [ 4.3460e-01,  1.2499e-01, -1.3076e+00,  1.1921e+00],\n",
       "           [-2.4046e+00, -6.6040e-01, -1.1694e+00, -2.9227e+00],\n",
       "           [-2.2959e+00, -7.5322e-01,  1.8458e+01, -1.0527e+01],\n",
       "           [ 4.7477e-01,  3.5569e-01,  7.9919e-01,  1.2811e-01],\n",
       "           [-6.9372e-01, -5.3056e-01,  2.8078e-01, -1.5153e+00],\n",
       "           [ 4.7713e-01,  4.1836e-01, -8.2331e-01,  1.5518e+00],\n",
       "           [ 1.8608e-01, -3.9467e-01,  5.5482e-01, -3.3411e-01],\n",
       "           [ 5.5745e-02,  2.0860e-01, -7.2182e-02, -8.3620e-01],\n",
       "           [ 6.1640e-01,  9.6800e-02, -7.6782e-01, -4.4058e-01],\n",
       "           [ 1.7413e+01,  8.3361e+00, -2.0309e+01,  9.0535e+00],\n",
       "           [-2.2563e+00,  2.3765e+00, -3.6486e+01,  1.1932e+01],\n",
       "           [-1.3222e-03,  8.9794e-03, -9.5058e-03,  1.3309e-02],\n",
       "           [-2.0408e-02, -2.4860e-01, -3.4227e-01, -1.5009e-01],\n",
       "           [-1.6291e-01,  2.7033e-01,  2.7424e-01,  2.3129e-01],\n",
       "           [ 1.8898e+00, -2.1737e+00,  8.9676e+00,  6.8500e+00],\n",
       "           [-4.5521e-01,  2.9128e-01,  1.3927e+00,  1.4497e+00],\n",
       "           [-1.1235e-01,  1.7477e-01, -5.3547e+00, -4.0281e+00],\n",
       "           [-4.4049e-01,  1.6150e+01,  2.3098e+01, -1.5658e+01]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 1.4209e+00, -1.1789e+00, -9.0115e-01,  7.5405e-01],\n",
       "           [ 1.7881e+00,  6.3361e-02, -6.5737e-01,  1.5685e+00],\n",
       "           [ 8.5479e-02,  4.0702e-02, -8.5684e-02,  7.2798e-02],\n",
       "           [ 1.3225e+01,  8.6571e-01, -1.0734e+01,  9.5395e+00],\n",
       "           [-9.0924e-02,  1.2602e+00, -5.6127e-01, -8.3958e-01],\n",
       "           [-2.0953e+00,  2.0837e+00, -4.4945e+00, -6.1851e+00],\n",
       "           [ 8.4761e+00, -7.0617e+00,  1.0504e+01,  1.4343e+01],\n",
       "           [ 1.7988e+00,  7.0789e-01,  1.8770e+00, -3.3341e+00],\n",
       "           [-3.0630e+00,  2.3399e+00, -4.7668e+00,  7.1049e-01],\n",
       "           [-1.2250e+00,  7.3245e-01, -1.9632e+00,  7.1375e-01],\n",
       "           [ 1.5809e+00, -1.0108e+00,  2.3200e+00,  1.1255e+00],\n",
       "           [ 1.7582e+01, -1.1632e+01,  1.9237e+01,  7.8500e+00],\n",
       "           [ 4.2450e-01, -9.0352e-01, -5.4162e+00, -4.9957e+00],\n",
       "           [-3.3871e-02, -6.5294e-02, -5.9487e-02, -6.0125e-02],\n",
       "           [ 4.8422e+00,  3.6624e+00, -9.6914e+00,  1.4946e+00],\n",
       "           [ 2.2225e+00,  3.5274e+00,  2.3352e+00,  1.4554e+00],\n",
       "           [ 7.6658e-02,  4.2608e-01,  4.8235e-02, -1.8359e-01],\n",
       "           [ 4.1445e-03, -4.3295e-01,  4.7676e-01,  5.4382e-01],\n",
       "           [-6.2729e-01,  7.6401e-01,  3.7706e-01, -6.6470e-01],\n",
       "           [-1.9239e-02, -1.6600e-01,  4.6737e-02,  8.4367e-02],\n",
       "           [ 3.6781e-01,  1.6332e+00, -2.9099e+00, -1.5729e+00],\n",
       "           [ 6.4322e-01, -3.0567e-02,  2.8990e-01, -5.1895e-02],\n",
       "           [-2.3112e+00, -1.2235e+01,  4.4676e+00,  1.6729e+01],\n",
       "           [-2.1884e+00, -7.4559e+00,  2.6604e+00,  1.1582e+01],\n",
       "           [ 6.7254e+00, -1.0460e+01,  2.4768e+01, -7.6402e+00],\n",
       "           [-2.0152e-01, -1.1981e-02,  2.8332e-01,  2.9125e-01],\n",
       "           [-1.2679e-02, -1.4086e+00, -5.4428e-01, -9.1187e-01],\n",
       "           [ 4.8701e+00, -7.6113e-01, -1.1948e+01, -6.4467e+00],\n",
       "           [-9.1580e+00,  5.3204e+00,  3.0385e+01,  1.6007e+01],\n",
       "           [ 3.8407e+00,  1.0529e+00, -8.3076e+00, -5.1794e+00],\n",
       "           [-3.0737e+00, -1.2711e+00,  8.2603e-01,  1.2754e+00],\n",
       "           [-9.1790e+00, -2.3757e+00,  3.0713e+01,  1.9358e+01]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-5.4668e-01, -5.7119e-01, -4.4057e-01,  7.8830e-01],\n",
       "           [ 5.9528e-03, -3.2812e-01, -3.0225e-01,  2.3520e-01],\n",
       "           [-1.9878e-01, -2.3832e-01, -2.5050e-01,  2.7650e-01],\n",
       "           [-1.8906e+00, -1.8854e+01, -2.1038e+01,  1.0591e+01],\n",
       "           [ 3.0928e-01,  1.2140e-01,  2.7045e-01, -2.1390e-01],\n",
       "           [ 1.5126e+01,  6.3961e+00,  1.6854e+01, -2.5019e+01],\n",
       "           [-1.4887e+00, -3.4322e-01, -2.1153e+00,  2.9281e+00],\n",
       "           [ 1.8517e-01, -7.9503e-01, -2.4028e+00,  5.4896e-01],\n",
       "           [-1.9366e-01, -6.9749e-01,  2.5666e-01, -8.0708e-01],\n",
       "           [-4.7281e-01,  2.2342e-02,  1.9283e+00, -2.0704e+00],\n",
       "           [ 4.3729e-01, -2.1400e+00, -2.1100e-01,  1.2883e+00],\n",
       "           [ 7.2413e-01, -4.7037e+00, -6.7549e-01, -2.8948e+00],\n",
       "           [-4.4632e-02, -6.0885e-01,  4.8634e-02,  7.5744e-02],\n",
       "           [ 1.1623e+00,  4.9391e-01,  2.0603e-01, -2.8740e-01],\n",
       "           [ 1.7216e+01,  8.8175e+00, -1.6707e+00, -4.1869e+00],\n",
       "           [ 4.7349e+00,  2.9431e+00, -6.6694e+00, -3.8783e+00],\n",
       "           [-3.3982e-01, -4.7809e-01, -7.4531e-01, -1.9747e-01],\n",
       "           [ 8.6751e-01,  5.3356e-01, -2.9791e-02, -2.6536e-01],\n",
       "           [-2.3802e+00, -1.4024e+00, -7.2875e-01,  1.4712e+00],\n",
       "           [ 1.3065e-01,  1.0451e-01, -1.6953e-01, -5.2811e-02],\n",
       "           [ 1.0177e+00,  8.7391e-01, -3.6849e-01, -2.5131e+00],\n",
       "           [-3.8444e-01, -2.1812e-01,  1.8265e-01,  6.8892e-01],\n",
       "           [-3.9151e+00,  7.5759e+00,  1.2800e-01, -1.4211e+01],\n",
       "           [-6.3681e+00, -1.0418e+00,  1.0265e+00,  7.6240e+00],\n",
       "           [-3.5554e+00,  1.3417e+01, -2.8002e+01,  3.1427e+01],\n",
       "           [-4.1373e-01,  9.8666e-02, -1.0478e-01,  2.4386e-01],\n",
       "           [ 2.1120e+00, -3.1047e-01,  1.4099e+00, -8.9111e-01],\n",
       "           [ 6.6467e+00, -1.7560e+00,  5.0801e+00, -7.9314e+00],\n",
       "           [ 2.8238e+01, -3.5662e+00,  4.3246e+01, -5.2226e+01],\n",
       "           [ 5.5652e-01, -1.0772e-01,  1.2920e+00, -1.5222e+00],\n",
       "           [ 1.6925e+00, -3.6982e-01,  4.9334e+00, -6.8212e+00],\n",
       "           [-7.6175e+00,  1.3238e+00, -1.8280e+01,  2.2934e+01]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-1.3750e+00],\n",
       "           [-7.9864e-01],\n",
       "           [-2.3363e-02],\n",
       "           [-6.7269e+00],\n",
       "           [-8.9934e-02],\n",
       "           [-1.3872e+01],\n",
       "           [-2.9720e+00],\n",
       "           [-5.1041e-01],\n",
       "           [ 2.1011e+00],\n",
       "           [ 2.1108e+00],\n",
       "           [ 3.3276e+00],\n",
       "           [ 2.7788e+00],\n",
       "           [-1.0435e+00],\n",
       "           [ 7.9929e-02],\n",
       "           [ 2.5149e+01],\n",
       "           [-6.4929e+00],\n",
       "           [-7.5794e-01],\n",
       "           [ 9.5857e-01],\n",
       "           [ 1.6447e-01],\n",
       "           [-1.0524e-01],\n",
       "           [ 2.2886e+00],\n",
       "           [ 2.1161e-01],\n",
       "           [-6.0387e+00],\n",
       "           [ 8.5916e+00],\n",
       "           [-2.8992e+01],\n",
       "           [-2.7213e-01],\n",
       "           [-2.1400e+00],\n",
       "           [-1.0708e+01],\n",
       "           [ 7.9003e+01],\n",
       "           [-3.4510e+00],\n",
       "           [ 1.4714e+00],\n",
       "           [-4.2965e+01]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 0.0000],\n",
       "           [-0.4415],\n",
       "           [-0.5698],\n",
       "           [-1.4774],\n",
       "           [ 1.9131],\n",
       "           [-0.8970],\n",
       "           [-8.9773],\n",
       "           [ 0.1895],\n",
       "           [ 0.4586],\n",
       "           [ 2.7207],\n",
       "           [-0.8600],\n",
       "           [ 0.4763],\n",
       "           [ 3.6947],\n",
       "           [ 0.0924],\n",
       "           [ 0.2316],\n",
       "           [11.8905],\n",
       "           [ 6.1789],\n",
       "           [-0.0955],\n",
       "           [ 0.5313],\n",
       "           [ 0.1795],\n",
       "           [ 0.2913],\n",
       "           [ 0.4898],\n",
       "           [ 2.4192],\n",
       "           [-0.9509],\n",
       "           [-6.7381],\n",
       "           [-0.0823],\n",
       "           [-0.2107],\n",
       "           [-1.6829],\n",
       "           [-3.0899],\n",
       "           [16.9208],\n",
       "           [34.8912],\n",
       "           [31.1490]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dQ_pt_p, dK_pt_p, dV_pt_p, dI_pt_p, dF_pt_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.8541,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-0.1560, -0.0284,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [ 0.2714,  0.3990, -1.3529,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-1.7164, -1.5888, -3.3407,  0.9946,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-0.8786, -0.7510, -2.5028,  1.8324, -1.0743,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-1.5739, -1.4463, -3.1982,  1.1371, -1.7696,  0.3488,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-1.7074, -1.5798, -3.3317,  1.0036, -1.9031,  0.2153, -0.1639,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-0.4118, -0.2842, -2.0361,  2.2992, -0.6075,  1.5109,  1.1317,  0.6603,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [ 1.0827,  1.2104, -0.5415,  3.7938,  0.8870,  3.0054,  2.6263,  2.1549,  0.6156,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [ 0.0078,  0.1354, -1.6165,  2.7188, -0.1880,  1.9304,  1.5513,  1.0799, -0.4594, -1.0923,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [ 0.5316,  0.6592, -1.0927,  3.2426,  0.3358,  2.4543,  2.0751,  1.6037,  0.0644, -0.5684, -0.8476,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [ 0.6539,  0.7815, -0.9704,  3.3649,  0.4582,  2.5766,  2.1974,  1.7260,  0.1867, -0.4461, -0.7253,  0.4137,    -inf,    -inf,    -inf,    -inf],\n",
       "          [ 1.4176,  1.5452, -0.2067,  4.1286,  1.2219,  3.3403,  2.9611,  2.4897,  0.9504,  0.3176,  0.0384,  1.1774, -0.1818,    -inf,    -inf,    -inf],\n",
       "          [ 1.5534,  1.6810, -0.0709,  4.2644,  1.3577,  3.4761,  3.0970,  2.6255,  1.0863,  0.4534,  0.1742,  1.3132, -0.0459,  0.0641,    -inf,    -inf],\n",
       "          [-0.0366,  0.0910, -1.6609,  2.6744, -0.2323,  1.8861,  1.5070,  1.0355, -0.5037, -1.1366, -1.4158, -0.2768, -1.6359, -1.5259,  1.5092,    -inf],\n",
       "          [ 0.1224,  0.2500, -1.5018,  2.8334, -0.0733,  2.0451,  1.6660,  1.1945, -0.3447, -0.9776, -1.2568, -0.1178, -1.4769, -1.3669,  1.6682,  0.6495]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logD_tile = construct_log_gate_matrix_tiled(vecI=igs.squeeze(-1), vecF=fgs.squeeze(-1), BQ=BLOCK_Q, BKV=BLOCK_KV, idx_BQ=0, idx_BKV=0)\n",
    "logD_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt220cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
