{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_printoptions(linewidth=600, threshold=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch vLSTM backward with group norm tiled (headwise layernorm)\n",
    "\n",
    "Shows what happens if we fuse the multihead layernorm with the vlstm kernel.\n",
    "Here we compare the tiled impl (template for triton&cuda kernels) with the parallel impl and check for numerical correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from vlstm_parallel_tiled import vlstm_parallel_tiled\n",
    "from vlstm_parallel_w_groupnorm import vlstm_parallel_bw_torch_w_groupnorm, vlstm_parallel_fwbw_torch_w_groupnorm, vlstm_parallel_fwbw_torch_w_groupnorm_full\n",
    "from vlstm_parallel import vlstm_parallel_fw_torch\n",
    "\n",
    "from vlstm_parallel_w_groupnorm_tiled_bw import mlstm_parallel_w_groupnorm_torch_tiled_bw, vlstm_parallel_w_groupnorm_torch_bw, construct_log_gate_matrix_tiled, construct_log_gate_matrix_paper\n",
    "\n",
    "from ln import MultiHeadLayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BW parallel with groupnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "S = 8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 4 # dim per head\n",
    "DTYPE = torch.float64\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "EPS = 0.0\n",
    "\n",
    "BLOCK_Q = 16\n",
    "BLOCK_KV = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 8, 4]), torch.Size([1, 1, 8, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# forward inputs\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "# igs2 = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# backward inputs\n",
    "dH = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vecN = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "vecM = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "qs.shape, fgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 3.* torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0., 0., 0., 0.], device='cuda:0', dtype=torch.float64, requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_layernorm = MultiHeadLayerNorm(NH*DH, eps=1e-6).to(device=DEVICE, dtype=DTYPE)\n",
    "mh_layernorm.weight, mh_layernorm.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_pt = fgs.clone().detach().requires_grad_(True)\n",
    "igs_pt = igs.clone().detach().requires_grad_(True)\n",
    "qs_pt = qs.clone().detach().requires_grad_(True)\n",
    "ks_pt = ks.clone().detach().requires_grad_(True)\n",
    "vs_pt = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = vlstm_fw_torch(\n",
    "#     queries=qs,\n",
    "#     keys=ks,\n",
    "#     values=vs,\n",
    "#     igate_preact=igs,\n",
    "#     fgate_preact=fgs,\n",
    "#     stabilize_rowwise=True,\n",
    "# )\n",
    "# rs, rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = vlstm_parallel_fw_torch(\n",
    "    queries=qs_pt,\n",
    "    keys=ks_pt,\n",
    "    values=vs_pt,\n",
    "    igate_preact=igs_pt,\n",
    "    fgate_preact=fgs_pt,\n",
    "    eps=EPS,\n",
    ")\n",
    "rs_scaled = mh_layernorm(rs)\n",
    "rs_scaled, rs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "((rs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.shape # (B, NH, S, DH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "          [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "          [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "          [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "          [ 9.8784e-01, -4.8033e-01,  1.2925e+00, -9.1624e-01],\n",
       "          [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "          [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "          [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs2 = rs#.transpose(1, 2)\n",
    "rs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5336],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 = (rs2 - rs2.mean(-1, keepdim=True)) / rs2.std(-1, keepdim=True, unbiased=False)\n",
    "# rs4 = rs3.transpose(1, 2)\n",
    "rs3, rs3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.4993e-07,  3.4896e-06,  1.0154e-06, -3.7551e-06],\n",
       "          [ 3.4323e-06,  5.8879e-06, -1.0780e-06, -8.2422e-06],\n",
       "          [ 2.2965e-06,  3.4939e-06, -4.9360e-06, -8.5439e-07],\n",
       "          [ 2.5082e-06, -1.6520e-06, -8.3956e-07, -1.6605e-08],\n",
       "          [ 1.5938e-06, -9.8798e-07, -5.6463e-07, -4.1209e-08],\n",
       "          [ 1.0009e-06, -1.6121e-06,  6.8374e-07, -7.2535e-08],\n",
       "          [ 5.5659e-07, -1.1214e-06,  7.5538e-07, -1.9061e-07],\n",
       "          [ 3.9179e-06, -4.7970e-06,  2.4964e-05, -2.4085e-05]]]], device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 - rs_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_obw = fgs.clone().detach().requires_grad_(True)\n",
    "igs_obw = igs.clone().detach().requires_grad_(True)\n",
    "qs_obw = qs.clone().detach().requires_grad_(True)\n",
    "ks_obw = ks.clone().detach().requires_grad_(True)\n",
    "vs_obw = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs, var_b, var_m = vlstm_parallel_fwbw_torch_w_groupnorm_full(\n",
    "    queries=qs_obw,\n",
    "    keys=ks_obw,\n",
    "    values=vs_obw,\n",
    "    igate_preact=igs_obw,\n",
    "    fgate_preact=fgs_obw,\n",
    "    eps=EPS,\n",
    ")\n",
    "hs, hs.shape\n",
    "hs_scaled = mh_layernorm(hs)\n",
    "hs_scaled, hs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_scaled - rs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [-4.0645e-06],\n",
      "          [ 6.1824e-06],\n",
      "          [ 1.0703e-05],\n",
      "          [ 0.0000e+00]]]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "((hs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8033e-01,  1.2925e+00, -9.1624e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad, qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.2209],\n",
       "           [0.3124],\n",
       "           [0.8088],\n",
       "           [0.3172],\n",
       "           [2.6139],\n",
       "           [1.0345],\n",
       "           [1.5021],\n",
       "           [0.4596]]]], device='cuda:0', dtype=torch.float64, grad_fn=<AbsBackward0>),\n",
       " tensor([[[[0.4257],\n",
       "           [1.0288],\n",
       "           [1.6999],\n",
       "           [0.3699],\n",
       "           [0.5299],\n",
       "           [0.7055],\n",
       "           [1.1781],\n",
       "           [0.5167]]]], device='cuda:0', dtype=torch.float64, grad_fn=<ExpBackward0>),\n",
       " tensor([[[[False],\n",
       "           [False],\n",
       "           [False],\n",
       "           [False],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [False]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_b.abs(), torch.exp(-var_m), var_b.abs() > torch.exp(-var_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [-2.5606e-06,  1.4259e-05, -3.7683e-07,  6.6377e-06],\n",
       "           [ 7.3301e-06, -4.2211e-06,  1.7718e-06,  1.7949e-06],\n",
       "           [ 6.4459e-06, -5.9048e-06,  1.1989e-05,  1.4505e-06],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-1.3196e-07, -1.1467e-07, -7.7522e-08, -1.3573e-07],\n",
       "           [-2.0452e-07, -1.7772e-07, -1.2015e-07, -2.1036e-07],\n",
       "           [-8.9864e-08, -7.8086e-08, -5.2791e-08, -9.2430e-08],\n",
       "           [-7.8008e-06, -6.7784e-06, -4.5826e-06, -8.0236e-06],\n",
       "           [-1.4118e-06, -1.2267e-06, -8.2935e-07, -1.4521e-06],\n",
       "           [-7.6242e-06,  6.1568e-06, -4.1334e-06, -9.8372e-06],\n",
       "           [-6.9098e-06,  5.6214e-06, -8.3021e-06, -1.1637e-05],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 0.0000e+00,  0.0000e+00, -2.2204e-16,  4.4409e-16],\n",
       "           [ 0.0000e+00,  0.0000e+00,  5.5511e-17,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00, -4.4409e-16,  0.0000e+00],\n",
       "           [-1.1102e-16,  0.0000e+00,  0.0000e+00, -2.2204e-16],\n",
       "           [-4.4409e-16,  0.0000e+00,  0.0000e+00,  8.8818e-16],\n",
       "           [-8.8818e-16,  0.0000e+00, -5.0307e-17,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad - qs_obw.grad, ks_pt.grad - ks_obw.grad, vs_pt.grad - vs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 6.0959e-16],\n",
       "           [ 4.0919e-08],\n",
       "           [ 5.5045e-09],\n",
       "           [ 2.2432e-07],\n",
       "           [ 7.5696e-06],\n",
       "           [-2.4253e-06],\n",
       "           [-1.4291e-05],\n",
       "           [-1.1102e-16]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 5.5821e-08],\n",
       "           [-4.1876e-08],\n",
       "           [ 2.4110e-07],\n",
       "           [ 2.4811e-05],\n",
       "           [-9.3009e-07],\n",
       "           [-2.9778e-05],\n",
       "           [ 2.6454e-06],\n",
       "           [-3.5527e-15]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_pt.grad - fgs_obw.grad, igs_pt.grad - igs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(qs_pt.grad, qs_obw.grad, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward match: True\n",
      "qs match: True\n",
      "ks match: True\n",
      "vs match: True\n",
      "fgate_preacts match: True\n",
      "igate_preacts match: True\n"
     ]
    }
   ],
   "source": [
    "atol = 1e-5\n",
    "rtol = 1e-5\n",
    "print(f\"Forward match: {torch.allclose(hs_scaled, rs_scaled)}\")\n",
    "print(f\"qs match: {torch.allclose(qs_pt.grad, qs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"ks match: {torch.allclose(ks_pt.grad, ks_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"vs match: {torch.allclose(vs_pt.grad, vs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"fgate_preacts match: {torch.allclose(fgs_pt.grad, fgs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"igate_preacts match: {torch.allclose(igs_pt.grad, igs_obw.grad, atol=atol, rtol=rtol)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusion: \n",
    "# dividing we get the same gradients, the error -1e-5 is due to numerical precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([[[[-3.7828e-17, -2.8809e-17, -1.0405e-16,  4.7115e-17],\n",
    "#           [-1.1102e-16, -4.4409e-16, -8.8818e-16,  4.4409e-16],\n",
    "#           [ 8.8818e-16, -8.8818e-16,  0.0000e+00, -8.3267e-17],\n",
    "#           [ 1.2490e-16, -5.5511e-17,  1.3878e-17, -1.7347e-17],\n",
    "#           [ 1.8937e-06, -1.0558e-05, -2.7356e-06,  1.5993e-05],\n",
    "#           [ 4.4409e-16,  0.0000e+00,  1.3323e-15,  0.0000e+00],\n",
    "#           [-6.0601e-07, -9.2155e-07,  4.0914e-06, -5.0413e-07],\n",
    "#           [-1.2725e-06,  1.7485e-06,  5.4959e-06,  8.2998e-07]]]],\n",
    "#        device='cuda:0', dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own backward2\n",
    "\n",
    "Reimplementation by using separate function for fw and bw which serve as ground truth for kernel impl.\n",
    "They should match exactly own backward(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_obw2 = fgs.clone().detach().requires_grad_(True)\n",
    "igs_obw2 = igs.clone().detach().requires_grad_(True)\n",
    "qs_obw2 = qs.clone().detach().requires_grad_(True)\n",
    "ks_obw2 = ks.clone().detach().requires_grad_(True)\n",
    "vs_obw2 = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs2, var_b2, var_m2 = vlstm_parallel_fwbw_torch_w_groupnorm(\n",
    "    queries=qs_obw2,\n",
    "    keys=ks_obw2,\n",
    "    values=vs_obw2,\n",
    "    igate_preact=igs_obw2,\n",
    "    fgate_preact=fgs_obw2,\n",
    "    eps=EPS,\n",
    ")\n",
    "hs2, hs2.shape\n",
    "hs_scaled2 = mh_layernorm(hs2)\n",
    "hs_scaled2, hs_scaled2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_scaled - hs_scaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "((hs_scaled2+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-1.3020e-10,  8.6005e-11,  5.7015e-11, -1.0286e-10],\n",
       "           [ 5.3706e-07, -6.5505e-07,  4.6599e-07,  7.6344e-07],\n",
       "           [-2.5350e-06,  3.9298e-07,  4.4202e-06,  2.0236e-07],\n",
       "           [-7.5124e-07,  3.8170e-06, -5.5758e-07, -1.4132e-07],\n",
       "           [ 3.7791e-07, -1.8376e-07,  4.9448e-07, -3.5052e-07],\n",
       "           [-4.0115e-06, -4.4232e-06, -1.8519e-06, -4.1562e-06],\n",
       "           [ 9.0684e-07,  2.0908e-07, -1.0949e-06,  3.4366e-07],\n",
       "           [-4.9801e-05,  2.0900e-05, -4.6278e-05, -1.7950e-05]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 6.1895e-06, -2.2341e-06,  1.7210e-06,  2.6788e-06],\n",
       "           [ 3.8116e-06, -2.7216e-06,  2.7156e-06,  6.0842e-06],\n",
       "           [ 8.4303e-08,  4.1735e-07, -5.1106e-07, -2.3957e-07],\n",
       "           [-8.9174e-06, -1.0295e-05, -3.8709e-06,  2.0779e-05],\n",
       "           [ 1.4558e-06,  2.0089e-06,  4.3810e-07, -1.9617e-06],\n",
       "           [-1.6445e-05, -2.9992e-05, -1.6734e-05,  5.6504e-05],\n",
       "           [-1.6525e-05, -2.8659e-05, -1.3668e-05,  5.5794e-05],\n",
       "           [ 3.1712e-06,  5.0606e-06,  2.6874e-06, -9.8349e-06]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-3.8741e-06, -3.8724e-06,  5.7541e-06,  1.9924e-06],\n",
       "           [ 7.1809e-07,  4.7887e-07, -9.5332e-07, -2.4364e-07],\n",
       "           [ 1.2931e-06, -2.6308e-06, -2.0233e-06,  3.3611e-06],\n",
       "           [ 9.3499e-07,  1.3951e-05, -2.2263e-05,  7.3768e-06],\n",
       "           [ 1.5885e-06, -2.7415e-06,  7.5294e-08,  1.0777e-06],\n",
       "           [-4.5426e-06,  1.5047e-05, -3.0964e-06, -7.4076e-06],\n",
       "           [ 1.0900e-05, -1.7300e-05,  3.5894e-07,  6.0407e-06],\n",
       "           [-4.9925e-05,  7.8684e-05, -2.4389e-06, -2.6320e-05]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad - qs_obw2.grad, ks_obw.grad - ks_obw2.grad, vs_obw.grad - vs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00],\n",
       "           [-2.8527e-06],\n",
       "           [-7.4537e-07],\n",
       "           [-5.4030e-07],\n",
       "           [ 1.7050e-07],\n",
       "           [ 1.9369e-06],\n",
       "           [ 1.4342e-05],\n",
       "           [ 1.2706e-06]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-3.8915e-06],\n",
       "           [ 2.0035e-06],\n",
       "           [ 1.2739e-06],\n",
       "           [ 1.1791e-06],\n",
       "           [ 2.3387e-06],\n",
       "           [ 2.3987e-05],\n",
       "           [-2.0978e-05],\n",
       "           [-5.9123e-06]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_obw.grad - fgs_obw2.grad, igs_obw.grad - igs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7786e-01,  1.4118e+00, -2.0623e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-1.3020e-10,  8.6005e-11,  5.7015e-11, -1.0286e-10],\n",
       "           [ 5.3706e-07, -6.5505e-07,  4.6599e-07,  7.6344e-07],\n",
       "           [-2.5350e-06,  3.9298e-07,  4.4202e-06,  2.0236e-07],\n",
       "           [-7.5124e-07,  3.8170e-06, -5.5758e-07, -1.4132e-07],\n",
       "           [ 3.7791e-07, -1.8376e-07,  4.9448e-07, -3.5052e-07],\n",
       "           [-4.0115e-06, -4.4232e-06, -1.8519e-06, -4.1562e-06],\n",
       "           [ 9.0684e-07,  2.0908e-07, -1.0949e-06,  3.4366e-07],\n",
       "           [-4.9801e-05,  2.0900e-05, -4.6278e-05, -1.7950e-05]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad, qs_obw2.grad, qs_obw.grad - qs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: the impls match, the error is max 1e-5 is due to numerical precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BW parallel TILED with groupnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# params\n",
    "S = 8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 4 # dim per head\n",
    "DTYPE = torch.float64\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "EPS = 0.0\n",
    "\n",
    "BLOCK_Q = 8\n",
    "BLOCK_KV = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 8, 4]), torch.Size([1, 1, 8, 1]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# forward inputs\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "# igs2 = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# fgs = torch.zeros((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "# igs = torch.zeros_like(fgs) #torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# backward inputs\n",
    "dH = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vecN = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "vecM = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "qs.shape, fgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dQ_pt_p, dK_pt_p, dV_pt_p, dI_pt_p, dF_pt_p, matDtilde_p = vlstm_parallel_w_groupnorm_torch_bw(matDeltaHtilde=dH, matQ=qs, matK=ks, matV=vs, vecN=vecN, vecM=vecM, vecI=igs, vecF=fgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dQ_pt_p, dK_pt_p, dV_pt_p, dI_pt_p, dF_pt_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.7831,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-0.8115, -1.0101,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-2.1644, -2.3630,  0.4274,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-1.1698, -1.3684,  1.4220, -1.9878,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-2.2441, -2.4427,  0.3477, -3.0621,  0.8379,    -inf,    -inf,    -inf],\n",
       "          [-1.8953, -2.0940,  0.6965, -2.7133,  1.1866, -0.6953,    -inf,    -inf],\n",
       "          [-2.0592, -2.2578,  0.5326, -2.8772,  1.0228, -0.8592, -0.1335,    -inf],\n",
       "          [-1.3989, -1.5975,  1.1929, -2.2168,  1.6831, -0.1989,  0.5268,  1.2956]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logD_tile = construct_log_gate_matrix_tiled(vecI=igs.squeeze(-1), vecF=fgs.squeeze(-1), BQ=BLOCK_Q, BKV=BLOCK_KV, idx_BQ=0, idx_BKV=0)\n",
    "logD_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logD_tile_paper = construct_log_gate_matrix_paper(vecI=igs, vecF=fgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5339,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.2427,  0.1990,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0397,  0.0325,  0.5298,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.9599,  0.7870, 12.8189,  0.4236,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0948,  0.0777,  1.2658,  0.0418,  2.0665,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.1289,  0.1057,  1.7213,  0.0569,  2.8101,  0.4280,  0.0000,  0.0000],\n",
       "          [ 0.1446,  0.1185,  1.9305,  0.0638,  3.1517,  0.4800,  0.9917,  0.0000],\n",
       "          [ 0.3091,  0.2534,  4.1275,  0.1364,  6.7384,  1.0262,  2.1203,  4.5739]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(logD_tile_paper-vecM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logD_tile_paper - logD_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matQ_tiles: 1, torch.Size([1, 1, 8, 4]) | matK_tiles: 1, torch.Size([1, 1, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "# tiled version\n",
    "dQ_pt_t, dK_pt_t, dV_pt_t, dI_pt_t, dF_pt_t, matDtilde_t = mlstm_parallel_w_groupnorm_torch_tiled_bw(\n",
    "    matDeltaHtilde=dH,\n",
    "    matQ=qs,\n",
    "    matK=ks,\n",
    "    matV=vs,\n",
    "    vecN=vecN,\n",
    "    vecM=vecM,\n",
    "    vecI=igs.squeeze(-1),\n",
    "    vecF=fgs.squeeze(-1),\n",
    "    BLOCK_Q=BLOCK_Q,\n",
    "    BLOCK_KV=BLOCK_KV,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6298, -0.6688, -4.4727, -0.5512, -4.5151, -5.0400, -3.4385, -3.6111]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dI_pt_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dQ_pt_t, dQ_pt_p, \n",
    "dQ_pt_t - dQ_pt_p, dQ_pt_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dK_pt_t - dK_pt_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dV_pt_t - dV_pt_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dI_pt_t - dI_pt_p.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000e+00, -2.7756e-17, -1.1102e-16,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dF_pt_t - dF_pt_p.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000, -0.2432, -0.9247, -1.7464, -0.8082, -3.3331, -6.9210,  0.1670]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[ 0.0000, -0.2432, -0.9247, -1.7464, -0.8082, -3.3331, -6.9210,  0.1670]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[ 0.0000e+00, -2.7756e-17, -1.1102e-16,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dF_pt_t, dF_pt_p.squeeze(-1), dF_pt_t - dF_pt_p.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 6, 5, 4, 3, 2, 1, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(8).flip(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5032e-01, -0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
       "          [ 1.4427e-02,  8.7954e-04, -0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
       "          [ 6.6945e-03,  2.4660e-03,  8.2255e-01, -0.0000e+00,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
       "          [-4.7378e-01, -7.4472e-01, -4.0568e+00, -6.5979e-01,  0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
       "          [-1.0351e-04, -1.6686e-04,  5.5249e-02,  1.3401e-01,  2.2691e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00],\n",
       "          [ 1.4763e-03,  1.5872e-03, -1.1645e-01, -5.9713e-03, -8.3991e-01,  6.5777e-01, -0.0000e+00,  0.0000e+00],\n",
       "          [-2.8362e-02,  7.1250e-02, -1.2926e+00, -1.9432e-02, -6.4556e+00, -5.6466e+00, -3.3532e+00,  0.0000e+00],\n",
       "          [ 1.3704e-04, -1.4171e-04,  1.1541e-01, -5.1184e-05,  5.1134e-01, -5.1118e-02, -8.5253e-02, -3.6111e+00]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matDtilde_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matDtilde_p, matDtilde_p.shape, matDtilde_p - matDtilde_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "qIdx = 0\n",
    "kvIdx = 0\n",
    "\n",
    "bq_idxes = torch.arange(\n",
    "    qIdx * BLOCK_Q, (qIdx + 1) * BLOCK_Q, device=DEVICE\n",
    ")\n",
    "kv_idxes = torch.arange(\n",
    "    kvIdx * BLOCK_KV, (kvIdx + 1) * BLOCK_KV, device=DEVICE\n",
    ")\n",
    "idx_mask = bq_idxes[:, None] - kv_idxes[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -1, -2, -3, -4, -5, -6, -7],\n",
       "        [ 1,  0, -1, -2, -3, -4, -5, -6],\n",
       "        [ 2,  1,  0, -1, -2, -3, -4, -5],\n",
       "        [ 3,  2,  1,  0, -1, -2, -3, -4],\n",
       "        [ 4,  3,  2,  1,  0, -1, -2, -3],\n",
       "        [ 5,  4,  3,  2,  1,  0, -1, -2],\n",
       "        [ 6,  5,  4,  3,  2,  1,  0, -1],\n",
       "        [ 7,  6,  5,  4,  3,  2,  1,  0]], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1, -2, -3, -4, -5, -6, -7, -8],\n",
       "        [ 0, -1, -2, -3, -4, -5, -6, -7],\n",
       "        [ 1,  0, -1, -2, -3, -4, -5, -6],\n",
       "        [ 2,  1,  0, -1, -2, -3, -4, -5],\n",
       "        [ 3,  2,  1,  0, -1, -2, -3, -4],\n",
       "        [ 4,  3,  2,  1,  0, -1, -2, -3],\n",
       "        [ 5,  4,  3,  2,  1,  0, -1, -2],\n",
       "        [ 6,  5,  4,  3,  2,  1,  0, -1]], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qIdx = 1\n",
    "kvIdx = 1\n",
    "\n",
    "bq_idxes = torch.arange(\n",
    "    qIdx * BLOCK_Q, (qIdx + 1) * BLOCK_Q, device=DEVICE\n",
    ")\n",
    "kv_idxes = torch.arange(\n",
    "    kvIdx * BLOCK_KV, (kvIdx + 1) * BLOCK_KV, device=DEVICE\n",
    ") + 1\n",
    "idx_mask = bq_idxes[:, None] - kv_idxes[None, :]\n",
    "idx_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt220cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
