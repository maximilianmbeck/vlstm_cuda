{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch vLSTM backward with group norm tiled (headwise layernorm)\n",
    "\n",
    "Shows what happens if we fuse the multihead layernorm with the vlstm kernel.\n",
    "Here we compare the tiled impl (template for triton&cuda kernels) with the parallel impl and check for numerical correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from vlstm_parallel_tiled import vlstm_parallel_tiled\n",
    "from vlstm_parallel_w_groupnorm import vlstm_parallel_bw_torch_w_groupnorm, vlstm_parallel_fwbw_torch_w_groupnorm, vlstm_parallel_fwbw_torch_w_groupnorm_full\n",
    "from vlstm_parallel import vlstm_parallel_fw_torch\n",
    "\n",
    "from vlstm_parallel_w_groupnorm_tiled_bw import mlstm_parallel_w_groupnorm_torch_tiled_bw, vlstm_parallel_w_groupnorm_torch_bw\n",
    "\n",
    "from ln import MultiHeadLayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "S = 8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 4 # dim per head\n",
    "DTYPE = torch.float64\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "EPS = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 8, 4]), torch.Size([1, 1, 8, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# forward inputs\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "# igs2 = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# backward inputs\n",
    "dH = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vecN = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "vecM = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "qs.shape, fgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 3.* torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0., 0., 0., 0.], device='cuda:0', dtype=torch.float64,\n",
       "        requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_layernorm = MultiHeadLayerNorm(NH*DH, eps=1e-6).to(device=DEVICE, dtype=DTYPE)\n",
    "mh_layernorm.weight, mh_layernorm.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BW parallel with groupnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_pt = fgs.clone().detach().requires_grad_(True)\n",
    "igs_pt = igs.clone().detach().requires_grad_(True)\n",
    "qs_pt = qs.clone().detach().requires_grad_(True)\n",
    "ks_pt = ks.clone().detach().requires_grad_(True)\n",
    "vs_pt = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = vlstm_fw_torch(\n",
    "#     queries=qs,\n",
    "#     keys=ks,\n",
    "#     values=vs,\n",
    "#     igate_preact=igs,\n",
    "#     fgate_preact=fgs,\n",
    "#     stabilize_rowwise=True,\n",
    "# )\n",
    "# rs, rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = vlstm_parallel_fw_torch(\n",
    "    queries=qs_pt,\n",
    "    keys=ks_pt,\n",
    "    values=vs_pt,\n",
    "    igate_preact=igs_pt,\n",
    "    fgate_preact=fgs_pt,\n",
    "    eps=EPS,\n",
    ")\n",
    "rs_scaled = mh_layernorm(rs)\n",
    "rs_scaled, rs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "((rs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.shape # (B, NH, S, DH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "          [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "          [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "          [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "          [ 9.8784e-01, -4.8033e-01,  1.2925e+00, -9.1624e-01],\n",
       "          [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "          [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "          [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs2 = rs#.transpose(1, 2)\n",
    "rs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5336],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<DivBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 = (rs2 - rs2.mean(-1, keepdim=True)) / rs2.std(-1, keepdim=True, unbiased=False)\n",
    "# rs4 = rs3.transpose(1, 2)\n",
    "rs3, rs3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.4993e-07,  3.4896e-06,  1.0154e-06, -3.7551e-06],\n",
       "          [ 3.4323e-06,  5.8879e-06, -1.0780e-06, -8.2422e-06],\n",
       "          [ 2.2965e-06,  3.4939e-06, -4.9360e-06, -8.5439e-07],\n",
       "          [ 2.5082e-06, -1.6520e-06, -8.3956e-07, -1.6605e-08],\n",
       "          [ 1.5938e-06, -9.8798e-07, -5.6463e-07, -4.1209e-08],\n",
       "          [ 1.0009e-06, -1.6121e-06,  6.8374e-07, -7.2535e-08],\n",
       "          [ 5.5659e-07, -1.1214e-06,  7.5538e-07, -1.9061e-07],\n",
       "          [ 3.9179e-06, -4.7970e-06,  2.4964e-05, -2.4085e-05]]]],\n",
       "       device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 - rs_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_obw = fgs.clone().detach().requires_grad_(True)\n",
    "igs_obw = igs.clone().detach().requires_grad_(True)\n",
    "qs_obw = qs.clone().detach().requires_grad_(True)\n",
    "ks_obw = ks.clone().detach().requires_grad_(True)\n",
    "vs_obw = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs, var_b, var_m = vlstm_parallel_fwbw_torch_w_groupnorm_full(\n",
    "    queries=qs_obw,\n",
    "    keys=ks_obw,\n",
    "    values=vs_obw,\n",
    "    igate_preact=igs_obw,\n",
    "    fgate_preact=fgs_obw,\n",
    "    eps=EPS,\n",
    ")\n",
    "hs, hs.shape\n",
    "hs_scaled = mh_layernorm(hs)\n",
    "hs_scaled, hs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_scaled - rs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [-4.0645e-06],\n",
      "          [ 6.1824e-06],\n",
      "          [ 1.0703e-05],\n",
      "          [ 0.0000e+00]]]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "((hs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8033e-01,  1.2925e+00, -9.1624e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad, qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.2209],\n",
       "           [0.3124],\n",
       "           [0.8088],\n",
       "           [0.3172],\n",
       "           [2.6139],\n",
       "           [1.0345],\n",
       "           [1.5021],\n",
       "           [0.4596]]]], device='cuda:0', dtype=torch.float64,\n",
       "        grad_fn=<AbsBackward0>),\n",
       " tensor([[[[0.4257],\n",
       "           [1.0288],\n",
       "           [1.6999],\n",
       "           [0.3699],\n",
       "           [0.5299],\n",
       "           [0.7055],\n",
       "           [1.1781],\n",
       "           [0.5167]]]], device='cuda:0', dtype=torch.float64,\n",
       "        grad_fn=<ExpBackward0>),\n",
       " tensor([[[[False],\n",
       "           [False],\n",
       "           [False],\n",
       "           [False],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [False]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_b.abs(), torch.exp(-var_m), var_b.abs() > torch.exp(-var_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [-2.5606e-06,  1.4259e-05, -3.7683e-07,  6.6377e-06],\n",
       "           [ 7.3301e-06, -4.2211e-06,  1.7718e-06,  1.7949e-06],\n",
       "           [ 6.4459e-06, -5.9048e-06,  1.1989e-05,  1.4505e-06],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-1.3196e-07, -1.1467e-07, -7.7522e-08, -1.3573e-07],\n",
       "           [-2.0452e-07, -1.7772e-07, -1.2015e-07, -2.1036e-07],\n",
       "           [-8.9864e-08, -7.8086e-08, -5.2791e-08, -9.2430e-08],\n",
       "           [-7.8008e-06, -6.7784e-06, -4.5826e-06, -8.0236e-06],\n",
       "           [-1.4118e-06, -1.2267e-06, -8.2935e-07, -1.4521e-06],\n",
       "           [-7.6242e-06,  6.1568e-06, -4.1334e-06, -9.8372e-06],\n",
       "           [-6.9098e-06,  5.6214e-06, -8.3021e-06, -1.1637e-05],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 0.0000e+00,  0.0000e+00, -2.2204e-16,  4.4409e-16],\n",
       "           [ 0.0000e+00,  0.0000e+00,  5.5511e-17,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00, -4.4409e-16,  0.0000e+00],\n",
       "           [-1.1102e-16,  0.0000e+00,  0.0000e+00, -2.2204e-16],\n",
       "           [-4.4409e-16,  0.0000e+00,  0.0000e+00,  8.8818e-16],\n",
       "           [-8.8818e-16,  0.0000e+00, -5.0307e-17,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad - qs_obw.grad, ks_pt.grad - ks_obw.grad, vs_pt.grad - vs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 6.0959e-16],\n",
       "           [ 4.0919e-08],\n",
       "           [ 5.5045e-09],\n",
       "           [ 2.2432e-07],\n",
       "           [ 7.5696e-06],\n",
       "           [-2.4253e-06],\n",
       "           [-1.4291e-05],\n",
       "           [-1.1102e-16]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 5.5821e-08],\n",
       "           [-4.1876e-08],\n",
       "           [ 2.4110e-07],\n",
       "           [ 2.4811e-05],\n",
       "           [-9.3009e-07],\n",
       "           [-2.9778e-05],\n",
       "           [ 2.6454e-06],\n",
       "           [-3.5527e-15]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_pt.grad - fgs_obw.grad, igs_pt.grad - igs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(qs_pt.grad, qs_obw.grad, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward match: True\n",
      "qs match: True\n",
      "ks match: True\n",
      "vs match: True\n",
      "fgate_preacts match: True\n",
      "igate_preacts match: True\n"
     ]
    }
   ],
   "source": [
    "atol = 1e-5\n",
    "rtol = 1e-5\n",
    "print(f\"Forward match: {torch.allclose(hs_scaled, rs_scaled)}\")\n",
    "print(f\"qs match: {torch.allclose(qs_pt.grad, qs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"ks match: {torch.allclose(ks_pt.grad, ks_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"vs match: {torch.allclose(vs_pt.grad, vs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"fgate_preacts match: {torch.allclose(fgs_pt.grad, fgs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"igate_preacts match: {torch.allclose(igs_pt.grad, igs_obw.grad, atol=atol, rtol=rtol)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusion: \n",
    "# dividing we get the same gradients, the error -1e-5 is due to numerical precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([[[[-3.7828e-17, -2.8809e-17, -1.0405e-16,  4.7115e-17],\n",
    "#           [-1.1102e-16, -4.4409e-16, -8.8818e-16,  4.4409e-16],\n",
    "#           [ 8.8818e-16, -8.8818e-16,  0.0000e+00, -8.3267e-17],\n",
    "#           [ 1.2490e-16, -5.5511e-17,  1.3878e-17, -1.7347e-17],\n",
    "#           [ 1.8937e-06, -1.0558e-05, -2.7356e-06,  1.5993e-05],\n",
    "#           [ 4.4409e-16,  0.0000e+00,  1.3323e-15,  0.0000e+00],\n",
    "#           [-6.0601e-07, -9.2155e-07,  4.0914e-06, -5.0413e-07],\n",
    "#           [-1.2725e-06,  1.7485e-06,  5.4959e-06,  8.2998e-07]]]],\n",
    "#        device='cuda:0', dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own backward2\n",
    "\n",
    "Reimplementation by using separate function for fw and bw which serve as ground truth for kernel impl.\n",
    "They should match exactly own backward(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_obw2 = fgs.clone().detach().requires_grad_(True)\n",
    "igs_obw2 = igs.clone().detach().requires_grad_(True)\n",
    "qs_obw2 = qs.clone().detach().requires_grad_(True)\n",
    "ks_obw2 = ks.clone().detach().requires_grad_(True)\n",
    "vs_obw2 = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0',\n",
       "        dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs2, var_b2, var_m2 = vlstm_parallel_fwbw_torch_w_groupnorm(\n",
    "    queries=qs_obw2,\n",
    "    keys=ks_obw2,\n",
    "    values=vs_obw2,\n",
    "    igate_preact=igs_obw2,\n",
    "    fgate_preact=fgs_obw2,\n",
    "    eps=EPS,\n",
    ")\n",
    "hs2, hs2.shape\n",
    "hs_scaled2 = mh_layernorm(hs2)\n",
    "hs_scaled2, hs_scaled2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_scaled - hs_scaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "((hs_scaled2+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-1.3020e-10,  8.6005e-11,  5.7015e-11, -1.0286e-10],\n",
       "           [ 5.3706e-07, -6.5505e-07,  4.6599e-07,  7.6344e-07],\n",
       "           [-2.5350e-06,  3.9298e-07,  4.4202e-06,  2.0236e-07],\n",
       "           [-7.5124e-07,  3.8170e-06, -5.5758e-07, -1.4132e-07],\n",
       "           [ 3.7791e-07, -1.8376e-07,  4.9448e-07, -3.5052e-07],\n",
       "           [-4.0115e-06, -4.4232e-06, -1.8519e-06, -4.1562e-06],\n",
       "           [ 9.0684e-07,  2.0908e-07, -1.0949e-06,  3.4366e-07],\n",
       "           [-4.9801e-05,  2.0900e-05, -4.6278e-05, -1.7950e-05]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 6.1895e-06, -2.2341e-06,  1.7210e-06,  2.6788e-06],\n",
       "           [ 3.8116e-06, -2.7216e-06,  2.7156e-06,  6.0842e-06],\n",
       "           [ 8.4303e-08,  4.1735e-07, -5.1106e-07, -2.3957e-07],\n",
       "           [-8.9174e-06, -1.0295e-05, -3.8709e-06,  2.0779e-05],\n",
       "           [ 1.4558e-06,  2.0089e-06,  4.3810e-07, -1.9617e-06],\n",
       "           [-1.6445e-05, -2.9992e-05, -1.6734e-05,  5.6504e-05],\n",
       "           [-1.6525e-05, -2.8659e-05, -1.3668e-05,  5.5794e-05],\n",
       "           [ 3.1712e-06,  5.0606e-06,  2.6874e-06, -9.8349e-06]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-3.8741e-06, -3.8724e-06,  5.7541e-06,  1.9924e-06],\n",
       "           [ 7.1809e-07,  4.7887e-07, -9.5332e-07, -2.4364e-07],\n",
       "           [ 1.2931e-06, -2.6308e-06, -2.0233e-06,  3.3611e-06],\n",
       "           [ 9.3499e-07,  1.3951e-05, -2.2263e-05,  7.3768e-06],\n",
       "           [ 1.5885e-06, -2.7415e-06,  7.5294e-08,  1.0777e-06],\n",
       "           [-4.5426e-06,  1.5047e-05, -3.0964e-06, -7.4076e-06],\n",
       "           [ 1.0900e-05, -1.7300e-05,  3.5894e-07,  6.0407e-06],\n",
       "           [-4.9925e-05,  7.8684e-05, -2.4389e-06, -2.6320e-05]]]],\n",
       "        device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad - qs_obw2.grad, ks_obw.grad - ks_obw2.grad, vs_obw.grad - vs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00],\n",
       "           [-2.8527e-06],\n",
       "           [-7.4537e-07],\n",
       "           [-5.4030e-07],\n",
       "           [ 1.7050e-07],\n",
       "           [ 1.9369e-06],\n",
       "           [ 1.4342e-05],\n",
       "           [ 1.2706e-06]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-3.8915e-06],\n",
       "           [ 2.0035e-06],\n",
       "           [ 1.2739e-06],\n",
       "           [ 1.1791e-06],\n",
       "           [ 2.3387e-06],\n",
       "           [ 2.3987e-05],\n",
       "           [-2.0978e-05],\n",
       "           [-5.9123e-06]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_obw.grad - fgs_obw2.grad, igs_obw.grad - igs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7786e-01,  1.4118e+00, -2.0623e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-1.3020e-10,  8.6005e-11,  5.7015e-11, -1.0286e-10],\n",
       "           [ 5.3706e-07, -6.5505e-07,  4.6599e-07,  7.6344e-07],\n",
       "           [-2.5350e-06,  3.9298e-07,  4.4202e-06,  2.0236e-07],\n",
       "           [-7.5124e-07,  3.8170e-06, -5.5758e-07, -1.4132e-07],\n",
       "           [ 3.7791e-07, -1.8376e-07,  4.9448e-07, -3.5052e-07],\n",
       "           [-4.0115e-06, -4.4232e-06, -1.8519e-06, -4.1562e-06],\n",
       "           [ 9.0684e-07,  2.0908e-07, -1.0949e-06,  3.4366e-07],\n",
       "           [-4.9801e-05,  2.0900e-05, -4.6278e-05, -1.7950e-05]]]],\n",
       "        device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad, qs_obw2.grad, qs_obw.grad - qs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: the impls match, the error is max 1e-5 is due to numerical precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BW parallel TILED with groupnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dQ_pt_p, dK_pt_p, dV_pt_p, dI_pt_p, dF_pt_p = vlstm_parallel_w_groupnorm_torch_bw(matDeltaHtilde=dH, matQ=qs, matK=ks, matV=vs, vecN=vecN, vecM=vecM, vecI=igs, vecF=fgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 7.5400e-01, -4.9806e-01, -3.3017e-01,  5.9565e-01],\n",
       "           [-6.7514e-02,  4.3178e-02,  3.2875e-02, -5.1733e-02],\n",
       "           [ 1.1512e-02, -3.2063e-02,  8.4872e-02,  1.1490e-01],\n",
       "           [ 7.4273e+00, -5.7824e+01, -7.5553e-01, -2.4850e+01],\n",
       "           [-2.6519e-01,  3.6867e+00,  5.8413e-01,  1.3191e+00],\n",
       "           [-2.7861e+00, -1.4612e-01, -8.6080e-01, -1.5563e+00],\n",
       "           [ 1.9155e+01, -6.8366e+00, -7.8849e+00,  5.2391e+00],\n",
       "           [-1.4842e+00, -3.2384e+00,  1.4640e+00, -4.3700e-01]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[  1.4249,  -1.1815,  -0.8963,   0.7549],\n",
       "           [  1.7919,   0.0621,  -0.6536,   1.5702],\n",
       "           [  0.0869,   0.0401,  -0.0827,   0.0721],\n",
       "           [ 13.3159,   0.8007, -10.6145,   9.5685],\n",
       "           [ -0.1685,   1.3196,  -0.6682,  -0.8364],\n",
       "           [ -2.3977,   2.3395,  -5.0113,  -6.0130],\n",
       "           [  8.4134,  -7.0458,  10.1382,  14.5689],\n",
       "           [  1.0261,   1.6375,   0.8696,  -3.1824]]]], device='cuda:0',\n",
       "        dtype=torch.float64),\n",
       " tensor([[[[-5.4642e-01, -5.7131e-01, -4.4108e-01,  7.8939e-01],\n",
       "           [ 5.1412e-03, -3.2840e-01, -2.9842e-01,  2.3227e-01],\n",
       "           [-1.9781e-01, -2.3904e-01, -2.5391e-01,  2.7970e-01],\n",
       "           [-1.9638e+00, -1.9003e+01, -2.0825e+01,  1.0247e+01],\n",
       "           [ 2.9915e-01,  1.1493e-01,  3.2656e-01, -2.5846e-01],\n",
       "           [ 1.4899e+01,  6.4732e+00,  1.7791e+01, -2.5976e+01],\n",
       "           [-1.5142e+00, -3.8946e-01, -1.8435e+00,  2.8958e+00],\n",
       "           [-1.5429e-01, -1.5258e+00, -1.4606e+00, -6.8513e-01]]]],\n",
       "        device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ -1.3769],\n",
       "           [ -0.7964],\n",
       "           [ -0.0259],\n",
       "           [ -6.5615],\n",
       "           [ -0.2337],\n",
       "           [-14.6119],\n",
       "           [ -3.3515],\n",
       "           [ -1.9131]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 0.0000],\n",
       "           [-0.4429],\n",
       "           [-0.5697],\n",
       "           [-1.4793],\n",
       "           [ 1.9624],\n",
       "           [-0.8839],\n",
       "           [-9.3615],\n",
       "           [-0.0469]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dQ_pt_p, dK_pt_p, dV_pt_p, dI_pt_p, dF_pt_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt220cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
