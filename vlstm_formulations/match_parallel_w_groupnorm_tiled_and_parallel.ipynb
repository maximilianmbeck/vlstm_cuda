{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_printoptions(linewidth=600, threshold=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch vLSTM backward with group norm tiled (headwise layernorm)\n",
    "\n",
    "Shows what happens if we fuse the multihead layernorm with the vlstm kernel.\n",
    "Here we compare the tiled impl (template for triton&cuda kernels) with the parallel impl and check for numerical correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# from vlstm_parallel_tiled import vlstm_parallel_tiled\n",
    "from vlstm_parallel_w_groupnorm import vlstm_parallel_bw_torch_w_groupnorm, vlstm_parallel_fwbw_torch_w_groupnorm, vlstm_parallel_fwbw_torch_w_groupnorm_full\n",
    "from vlstm_parallel import vlstm_parallel_fw_torch\n",
    "\n",
    "from vlstm_parallel_w_groupnorm_tiled_bw import mlstm_parallel_w_groupnorm_torch_tiled_bw, vlstm_parallel_w_groupnorm_torch_bw, construct_log_gate_matrix_tiled, construct_log_gate_matrix_paper\n",
    "\n",
    "from ln import MultiHeadLayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BW parallel with groupnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "S = 8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 4 # dim per head\n",
    "DTYPE = torch.float64\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "EPS = 0.0\n",
    "\n",
    "BLOCK_Q = 16\n",
    "BLOCK_KV = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 8, 4]), torch.Size([1, 1, 8, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# forward inputs\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "# igs2 = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# backward inputs\n",
    "dH = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vecN = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "vecM = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "qs.shape, fgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 3.* torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0., 0., 0., 0.], device='cuda:0', dtype=torch.float64, requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mh_layernorm = MultiHeadLayerNorm(NH*DH, eps=1e-6).to(device=DEVICE, dtype=DTYPE)\n",
    "mh_layernorm.weight, mh_layernorm.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_pt = fgs.clone().detach().requires_grad_(True)\n",
    "igs_pt = igs.clone().detach().requires_grad_(True)\n",
    "qs_pt = qs.clone().detach().requires_grad_(True)\n",
    "ks_pt = ks.clone().detach().requires_grad_(True)\n",
    "vs_pt = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs = vlstm_fw_torch(\n",
    "#     queries=qs,\n",
    "#     keys=ks,\n",
    "#     values=vs,\n",
    "#     igate_preact=igs,\n",
    "#     fgate_preact=fgs,\n",
    "#     stabilize_rowwise=True,\n",
    "# )\n",
    "# rs, rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = vlstm_parallel_fw_torch(\n",
    "    queries=qs_pt,\n",
    "    keys=ks_pt,\n",
    "    values=vs_pt,\n",
    "    igate_preact=igs_pt,\n",
    "    fgate_preact=fgs_pt,\n",
    "    eps=EPS,\n",
    ")\n",
    "rs_scaled = mh_layernorm(rs)\n",
    "rs_scaled, rs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "((rs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.shape # (B, NH, S, DH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "          [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "          [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "          [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "          [ 9.8784e-01, -4.8033e-01,  1.2925e+00, -9.1624e-01],\n",
       "          [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "          [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "          [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs2 = rs#.transpose(1, 2)\n",
    "rs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5336],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 = (rs2 - rs2.mean(-1, keepdim=True)) / rs2.std(-1, keepdim=True, unbiased=False)\n",
    "# rs4 = rs3.transpose(1, 2)\n",
    "rs3, rs3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.4993e-07,  3.4896e-06,  1.0154e-06, -3.7551e-06],\n",
       "          [ 3.4323e-06,  5.8879e-06, -1.0780e-06, -8.2422e-06],\n",
       "          [ 2.2965e-06,  3.4939e-06, -4.9360e-06, -8.5439e-07],\n",
       "          [ 2.5082e-06, -1.6520e-06, -8.3956e-07, -1.6605e-08],\n",
       "          [ 1.5938e-06, -9.8798e-07, -5.6463e-07, -4.1209e-08],\n",
       "          [ 1.0009e-06, -1.6121e-06,  6.8374e-07, -7.2535e-08],\n",
       "          [ 5.5659e-07, -1.1214e-06,  7.5538e-07, -1.9061e-07],\n",
       "          [ 3.9179e-06, -4.7970e-06,  2.4964e-05, -2.4085e-05]]]], device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs3 - rs_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_obw = fgs.clone().detach().requires_grad_(True)\n",
    "igs_obw = igs.clone().detach().requires_grad_(True)\n",
    "qs_obw = qs.clone().detach().requires_grad_(True)\n",
    "ks_obw = ks.clone().detach().requires_grad_(True)\n",
    "vs_obw = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs, var_b, var_m = vlstm_parallel_fwbw_torch_w_groupnorm_full(\n",
    "    queries=qs_obw,\n",
    "    keys=ks_obw,\n",
    "    values=vs_obw,\n",
    "    igate_preact=igs_obw,\n",
    "    fgate_preact=fgs_obw,\n",
    "    eps=EPS,\n",
    ")\n",
    "hs, hs.shape\n",
    "hs_scaled = mh_layernorm(hs)\n",
    "hs_scaled, hs_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_scaled - rs_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [ 0.0000e+00],\n",
      "          [-4.0645e-06],\n",
      "          [ 6.1824e-06],\n",
      "          [ 1.0703e-05],\n",
      "          [ 0.0000e+00]]]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "((hs_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8033e-01,  1.2925e+00, -9.1624e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad, qs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.2209],\n",
       "           [0.3124],\n",
       "           [0.8088],\n",
       "           [0.3172],\n",
       "           [2.6139],\n",
       "           [1.0345],\n",
       "           [1.5021],\n",
       "           [0.4596]]]], device='cuda:0', dtype=torch.float64, grad_fn=<AbsBackward0>),\n",
       " tensor([[[[0.4257],\n",
       "           [1.0288],\n",
       "           [1.6999],\n",
       "           [0.3699],\n",
       "           [0.5299],\n",
       "           [0.7055],\n",
       "           [1.1781],\n",
       "           [0.5167]]]], device='cuda:0', dtype=torch.float64, grad_fn=<ExpBackward0>),\n",
       " tensor([[[[False],\n",
       "           [False],\n",
       "           [False],\n",
       "           [False],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [ True],\n",
       "           [False]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_b.abs(), torch.exp(-var_m), var_b.abs() > torch.exp(-var_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [-2.5606e-06,  1.4259e-05, -3.7683e-07,  6.6377e-06],\n",
       "           [ 7.3301e-06, -4.2211e-06,  1.7718e-06,  1.7949e-06],\n",
       "           [ 6.4459e-06, -5.9048e-06,  1.1989e-05,  1.4505e-06],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-1.3196e-07, -1.1467e-07, -7.7522e-08, -1.3573e-07],\n",
       "           [-2.0452e-07, -1.7772e-07, -1.2015e-07, -2.1036e-07],\n",
       "           [-8.9864e-08, -7.8086e-08, -5.2791e-08, -9.2430e-08],\n",
       "           [-7.8008e-06, -6.7784e-06, -4.5826e-06, -8.0236e-06],\n",
       "           [-1.4118e-06, -1.2267e-06, -8.2935e-07, -1.4521e-06],\n",
       "           [-7.6242e-06,  6.1568e-06, -4.1334e-06, -9.8372e-06],\n",
       "           [-6.9098e-06,  5.6214e-06, -8.3021e-06, -1.1637e-05],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 0.0000e+00,  0.0000e+00, -2.2204e-16,  4.4409e-16],\n",
       "           [ 0.0000e+00,  0.0000e+00,  5.5511e-17,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00, -4.4409e-16,  0.0000e+00],\n",
       "           [-1.1102e-16,  0.0000e+00,  0.0000e+00, -2.2204e-16],\n",
       "           [-4.4409e-16,  0.0000e+00,  0.0000e+00,  8.8818e-16],\n",
       "           [-8.8818e-16,  0.0000e+00, -5.0307e-17,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad - qs_obw.grad, ks_pt.grad - ks_obw.grad, vs_pt.grad - vs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 6.0959e-16],\n",
       "           [ 4.0919e-08],\n",
       "           [ 5.5045e-09],\n",
       "           [ 2.2432e-07],\n",
       "           [ 7.5696e-06],\n",
       "           [-2.4253e-06],\n",
       "           [-1.4291e-05],\n",
       "           [-1.1102e-16]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 5.5821e-08],\n",
       "           [-4.1876e-08],\n",
       "           [ 2.4110e-07],\n",
       "           [ 2.4811e-05],\n",
       "           [-9.3009e-07],\n",
       "           [-2.9778e-05],\n",
       "           [ 2.6454e-06],\n",
       "           [-3.5527e-15]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_pt.grad - fgs_obw.grad, igs_pt.grad - igs_obw.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(qs_pt.grad, qs_obw.grad, atol=1e-5, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward match: True\n",
      "qs match: True\n",
      "ks match: True\n",
      "vs match: True\n",
      "fgate_preacts match: True\n",
      "igate_preacts match: True\n"
     ]
    }
   ],
   "source": [
    "atol = 1e-5\n",
    "rtol = 1e-5\n",
    "print(f\"Forward match: {torch.allclose(hs_scaled, rs_scaled)}\")\n",
    "print(f\"qs match: {torch.allclose(qs_pt.grad, qs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"ks match: {torch.allclose(ks_pt.grad, ks_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"vs match: {torch.allclose(vs_pt.grad, vs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"fgate_preacts match: {torch.allclose(fgs_pt.grad, fgs_obw.grad, atol=atol, rtol=rtol)}\")\n",
    "print(f\"igate_preacts match: {torch.allclose(igs_pt.grad, igs_obw.grad, atol=atol, rtol=rtol)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conclusion: \n",
    "# dividing we get the same gradients, the error -1e-5 is due to numerical precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([[[[-3.7828e-17, -2.8809e-17, -1.0405e-16,  4.7115e-17],\n",
    "#           [-1.1102e-16, -4.4409e-16, -8.8818e-16,  4.4409e-16],\n",
    "#           [ 8.8818e-16, -8.8818e-16,  0.0000e+00, -8.3267e-17],\n",
    "#           [ 1.2490e-16, -5.5511e-17,  1.3878e-17, -1.7347e-17],\n",
    "#           [ 1.8937e-06, -1.0558e-05, -2.7356e-06,  1.5993e-05],\n",
    "#           [ 4.4409e-16,  0.0000e+00,  1.3323e-15,  0.0000e+00],\n",
    "#           [-6.0601e-07, -9.2155e-07,  4.0914e-06, -5.0413e-07],\n",
    "#           [-1.2725e-06,  1.7485e-06,  5.4959e-06,  8.2998e-07]]]],\n",
    "#        device='cuda:0', dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### own backward2\n",
    "\n",
    "Reimplementation by using separate function for fw and bw which serve as ground truth for kernel impl.\n",
    "They should match exactly own backward(1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_obw2 = fgs.clone().detach().requires_grad_(True)\n",
    "igs_obw2 = igs.clone().detach().requires_grad_(True)\n",
    "qs_obw2 = qs.clone().detach().requires_grad_(True)\n",
    "ks_obw2 = ks.clone().detach().requires_grad_(True)\n",
    "vs_obw2 = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2841,  1.3220,  0.3847, -1.4226],\n",
       "           [ 0.6386,  1.0955, -0.2006, -1.5335],\n",
       "           [ 0.7039,  1.0709, -1.5130, -0.2619],\n",
       "           [ 1.6086, -1.0595, -0.5384, -0.0106],\n",
       "           [ 1.6273, -1.0088, -0.5765, -0.0421],\n",
       "           [ 0.9918, -1.5975,  0.6775, -0.0719],\n",
       "           [ 0.7550, -1.5210,  1.0246, -0.2585],\n",
       "           [ 0.2224, -0.2723,  1.4169, -1.3670]]]], device='cuda:0', dtype=torch.float64, grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs2, var_b2, var_m2 = vlstm_parallel_fwbw_torch_w_groupnorm(\n",
    "    queries=qs_obw2,\n",
    "    keys=ks_obw2,\n",
    "    values=vs_obw2,\n",
    "    igate_preact=igs_obw2,\n",
    "    fgate_preact=fgs_obw2,\n",
    "    eps=EPS,\n",
    ")\n",
    "hs2, hs2.shape\n",
    "hs_scaled2 = mh_layernorm(hs2)\n",
    "hs_scaled2, hs_scaled2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0.]]]], device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_scaled - hs_scaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "((hs_scaled2+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-1.3020e-10,  8.6005e-11,  5.7015e-11, -1.0286e-10],\n",
       "           [ 5.3706e-07, -6.5505e-07,  4.6599e-07,  7.6344e-07],\n",
       "           [-2.5350e-06,  3.9298e-07,  4.4202e-06,  2.0236e-07],\n",
       "           [-7.5124e-07,  3.8170e-06, -5.5758e-07, -1.4132e-07],\n",
       "           [ 3.7791e-07, -1.8376e-07,  4.9448e-07, -3.5052e-07],\n",
       "           [-4.0115e-06, -4.4232e-06, -1.8519e-06, -4.1562e-06],\n",
       "           [ 9.0684e-07,  2.0908e-07, -1.0949e-06,  3.4366e-07],\n",
       "           [-4.9801e-05,  2.0900e-05, -4.6278e-05, -1.7950e-05]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[ 6.1895e-06, -2.2341e-06,  1.7210e-06,  2.6788e-06],\n",
       "           [ 3.8116e-06, -2.7216e-06,  2.7156e-06,  6.0842e-06],\n",
       "           [ 8.4303e-08,  4.1735e-07, -5.1106e-07, -2.3957e-07],\n",
       "           [-8.9174e-06, -1.0295e-05, -3.8709e-06,  2.0779e-05],\n",
       "           [ 1.4558e-06,  2.0089e-06,  4.3810e-07, -1.9617e-06],\n",
       "           [-1.6445e-05, -2.9992e-05, -1.6734e-05,  5.6504e-05],\n",
       "           [-1.6525e-05, -2.8659e-05, -1.3668e-05,  5.5794e-05],\n",
       "           [ 3.1712e-06,  5.0606e-06,  2.6874e-06, -9.8349e-06]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-3.8741e-06, -3.8724e-06,  5.7541e-06,  1.9924e-06],\n",
       "           [ 7.1809e-07,  4.7887e-07, -9.5332e-07, -2.4364e-07],\n",
       "           [ 1.2931e-06, -2.6308e-06, -2.0233e-06,  3.3611e-06],\n",
       "           [ 9.3499e-07,  1.3951e-05, -2.2263e-05,  7.3768e-06],\n",
       "           [ 1.5885e-06, -2.7415e-06,  7.5294e-08,  1.0777e-06],\n",
       "           [-4.5426e-06,  1.5047e-05, -3.0964e-06, -7.4076e-06],\n",
       "           [ 1.0900e-05, -1.7300e-05,  3.5894e-07,  6.0407e-06],\n",
       "           [-4.9925e-05,  7.8684e-05, -2.4389e-06, -2.6320e-05]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad - qs_obw2.grad, ks_obw.grad - ks_obw2.grad, vs_obw.grad - vs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00],\n",
       "           [-2.8527e-06],\n",
       "           [-7.4537e-07],\n",
       "           [-5.4030e-07],\n",
       "           [ 1.7050e-07],\n",
       "           [ 1.9369e-06],\n",
       "           [ 1.4342e-05],\n",
       "           [ 1.2706e-06]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-3.8915e-06],\n",
       "           [ 2.0035e-06],\n",
       "           [ 1.2739e-06],\n",
       "           [ 1.1791e-06],\n",
       "           [ 2.3387e-06],\n",
       "           [ 2.3987e-05],\n",
       "           [-2.0978e-05],\n",
       "           [-5.9123e-06]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_obw.grad - fgs_obw2.grad, igs_obw.grad - igs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7787e-01,  1.4118e+00, -2.0624e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-5.5424e-05,  3.6611e-05,  2.4270e-05, -4.3784e-05],\n",
       "           [ 5.5255e-01, -6.7394e-01,  4.7943e-01,  7.8546e-01],\n",
       "           [-4.3091e+00,  6.6800e-01,  7.5137e+00,  3.4398e-01],\n",
       "           [-2.7786e-01,  1.4118e+00, -2.0623e-01, -5.2272e-02],\n",
       "           [ 9.8784e-01, -4.8034e-01,  1.2925e+00, -9.1625e-01],\n",
       "           [-4.1501e+00, -4.5760e+00, -1.9159e+00, -4.2997e+00],\n",
       "           [ 1.3622e+00,  3.1406e-01, -1.6447e+00,  5.1623e-01],\n",
       "           [-2.5732e+01,  1.0798e+01, -2.3911e+01, -9.2743e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " tensor([[[[-1.3020e-10,  8.6005e-11,  5.7015e-11, -1.0286e-10],\n",
       "           [ 5.3706e-07, -6.5505e-07,  4.6599e-07,  7.6344e-07],\n",
       "           [-2.5350e-06,  3.9298e-07,  4.4202e-06,  2.0236e-07],\n",
       "           [-7.5124e-07,  3.8170e-06, -5.5758e-07, -1.4132e-07],\n",
       "           [ 3.7791e-07, -1.8376e-07,  4.9448e-07, -3.5052e-07],\n",
       "           [-4.0115e-06, -4.4232e-06, -1.8519e-06, -4.1562e-06],\n",
       "           [ 9.0684e-07,  2.0908e-07, -1.0949e-06,  3.4366e-07],\n",
       "           [-4.9801e-05,  2.0900e-05, -4.6278e-05, -1.7950e-05]]]], device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_obw.grad, qs_obw2.grad, qs_obw.grad - qs_obw2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion: the impls match, the error is max 1e-5 is due to numerical precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BW parallel TILED with groupnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# params\n",
    "S = 32 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 4 # dim per head\n",
    "DTYPE = torch.float64\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "EPS = 0.0\n",
    "\n",
    "BLOCK_Q = 8\n",
    "BLOCK_KV = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 32, 4]), torch.Size([1, 1, 32, 1]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(1)\n",
    "\n",
    "# forward inputs\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "# igs2 = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# fgs = torch.zeros((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "# igs = torch.zeros_like(fgs) #torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# backward inputs\n",
    "dH = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vecN = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "vecM = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "qs.shape, fgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dQ_pt_p, dK_pt_p, dV_pt_p, dI_pt_p, dF_pt_p, matDtilde_p = vlstm_parallel_w_groupnorm_torch_bw(matDeltaHtilde=dH, matQ=qs, matK=ks, matV=vs, vecN=vecN, vecM=vecM, vecI=igs, vecF=fgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dQ_pt_p, dK_pt_p, dV_pt_p, dI_pt_p, dF_pt_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.7831,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-0.8115, -1.0101,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-2.1644, -2.3630,  0.4274,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-1.1698, -1.3684,  1.4220, -1.9878,    -inf,    -inf,    -inf,    -inf],\n",
       "          [-2.2441, -2.4427,  0.3477, -3.0621,  0.8379,    -inf,    -inf,    -inf],\n",
       "          [-1.8953, -2.0940,  0.6965, -2.7133,  1.1866, -0.6953,    -inf,    -inf],\n",
       "          [-2.0592, -2.2578,  0.5326, -2.8772,  1.0228, -0.8592, -0.1335,    -inf],\n",
       "          [-1.3989, -1.5975,  1.1929, -2.2168,  1.6831, -0.1989,  0.5268,  1.2956]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logD_tile = construct_log_gate_matrix_tiled(vecI=igs.squeeze(-1), vecF=fgs.squeeze(-1), BQ=BLOCK_Q, BKV=BLOCK_KV, idx_BQ=0, idx_BKV=0)\n",
    "logD_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logD_tile_paper = construct_log_gate_matrix_paper(vecI=igs, vecF=fgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5.3393e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.4270e-01, 1.9898e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [3.9675e-02, 3.2527e-02, 5.2982e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [9.5992e-01, 7.8700e-01, 1.2819e+01, 4.2365e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [9.4786e-02, 7.7711e-02, 1.2658e+00, 4.1832e-02, 2.0665e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.2889e-01, 1.0567e-01, 1.7213e+00, 5.6886e-02, 2.8101e+00, 4.2795e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.4457e-01, 1.1852e-01, 1.9305e+00, 6.3802e-02, 3.1517e+00, 4.7999e-01, 9.9170e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [3.0908e-01, 2.5340e-01, 4.1275e+00, 1.3641e-01, 6.7384e+00, 1.0262e+00, 2.1203e+00, 4.5739e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.9588e-01, 1.6059e-01, 2.6157e+00, 8.6447e-02, 4.2704e+00, 6.5034e-01, 1.3437e+00, 2.8986e+00, 1.9109e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [6.2476e-01, 5.1221e-01, 8.3430e+00, 2.7573e-01, 1.3621e+01, 2.0743e+00, 4.2857e+00, 9.2453e+00, 6.0950e+00, 1.3912e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [2.0545e-02, 1.6844e-02, 2.7436e-01, 9.0673e-03, 4.4791e-01, 6.8214e-02, 1.4094e-01, 3.0403e-01, 2.0043e-01, 4.5751e-02, 5.2830e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [9.2887e-02, 7.6154e-02, 1.2404e+00, 4.0994e-02, 2.0251e+00, 3.0840e-01, 6.3719e-01, 1.3746e+00, 9.0619e-01, 2.0685e-01, 2.3885e+00, 1.0571e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [9.1968e-02, 7.5401e-02, 1.2281e+00, 4.0589e-02, 2.0050e+00, 3.0535e-01, 6.3088e-01, 1.3610e+00, 8.9722e-01, 2.0480e-01, 2.3649e+00, 1.0466e+00, 2.3837e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [4.7761e-02, 3.9157e-02, 6.3780e-01, 2.1079e-02, 1.0412e+00, 1.5857e-01, 3.2763e-01, 7.0677e-01, 4.6594e-01, 1.0636e-01, 1.2281e+00, 5.4352e-01, 1.2379e+00, 6.1970e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.8850e-01, 1.5455e-01, 2.5173e+00, 8.3194e-02, 4.1097e+00, 6.2587e-01, 1.2931e+00, 2.7895e+00, 1.8390e+00, 4.1977e-01, 4.8472e+00, 2.1452e+00, 4.8859e+00, 2.4459e+00, 9.6274e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [3.6376e+00, 2.9823e+00, 4.8577e+01, 1.6054e+00, 7.9305e+01, 1.2078e+01, 2.4953e+01, 5.3830e+01, 3.5487e+01, 8.1004e+00, 9.3537e+01, 4.1396e+01, 9.4284e+01, 4.7199e+01, 1.8578e+00, 5.5785e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [5.4414e-01, 4.4612e-01, 7.2665e+00, 2.4015e-01, 1.1863e+01, 1.8067e+00, 3.7327e+00, 8.0523e+00, 5.3085e+00, 1.2117e+00, 1.3992e+01, 6.1924e+00, 1.4104e+01, 7.0603e+00, 2.7791e-01, 8.3447e-01, 3.1684e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.2134e-01, 5.9140e-01, 9.6329e+00, 3.1835e-01, 1.5726e+01, 2.3950e+00, 4.9483e+00, 1.0675e+01, 7.0372e+00, 1.6063e+00, 1.8549e+01, 8.2090e+00, 1.8697e+01, 9.3596e+00, 3.6841e-01, 1.1062e+00, 4.2002e+00, 1.4496e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [4.7437e+00, 3.8892e+00, 6.3348e+01, 2.0936e+00, 1.0342e+02, 1.5750e+01, 3.2541e+01, 7.0199e+01, 4.6279e+01, 1.0564e+01, 1.2198e+02, 5.3984e+01, 1.2295e+02, 6.1551e+01, 2.4227e+00, 7.2748e+00, 2.7622e+01, 9.5329e+00, 6.5101e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [3.1996e-01, 2.6232e-01, 4.2728e+00, 1.4121e-01, 6.9756e+00, 1.0623e+00, 2.1949e+00, 4.7349e+00, 3.1215e+00, 7.1251e-01, 8.2275e+00, 3.6412e+00, 8.2932e+00, 4.1516e+00, 1.6341e-01, 4.9068e-01, 1.8631e+00, 6.4299e-01, 4.3910e-01, 3.1603e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [7.3792e-01, 6.0499e-01, 9.8543e+00, 3.2567e-01, 1.6088e+01, 2.4500e+00, 5.0620e+00, 1.0920e+01, 7.1990e+00, 1.6432e+00, 1.8975e+01, 8.3977e+00, 1.9126e+01, 9.5747e+00, 3.7688e-01, 1.1317e+00, 4.2968e+00, 1.4829e+00, 1.0127e+00, 7.2887e+00, 8.3755e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.5951e-01, 1.3077e-01, 2.1301e+00, 7.0396e-02, 3.4775e+00, 5.2959e-01, 1.0942e+00, 2.3604e+00, 1.5561e+00, 3.5520e-01, 4.1016e+00, 1.8152e+00, 4.1343e+00, 2.0696e+00, 8.1464e-02, 2.4461e-01, 9.2878e-01, 3.2054e-01, 2.1890e-01, 1.5755e+00, 1.8104e-01, 8.6167e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.2779e+00, 1.0477e+00, 1.7065e+01, 5.6398e-01, 2.7860e+01, 4.2429e+00, 8.7662e+00, 1.8911e+01, 1.2467e+01, 2.8457e+00, 3.2860e+01, 1.4543e+01, 3.3122e+01, 1.6581e+01, 6.5265e-01, 1.9597e+00, 7.4409e+00, 2.5680e+00, 1.7537e+00, 1.2622e+01, 1.4504e+00, 6.9033e+00, 1.9704e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [3.8014e+00, 3.1166e+00, 5.0764e+01, 1.6777e+00, 8.2876e+01, 1.2621e+01, 2.6077e+01, 5.6254e+01, 3.7086e+01, 8.4652e+00, 9.7749e+01, 4.3260e+01, 9.8530e+01, 4.9324e+01, 1.9415e+00, 5.8297e+00, 2.2135e+01, 7.6392e+00, 5.2169e+00, 3.7547e+01, 4.3146e+00, 2.0535e+01, 5.8615e-01, 7.0974e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.6684e+01, 1.3678e+01, 2.2279e+02, 7.3631e+00, 3.6373e+02, 5.5393e+01, 1.1445e+02, 2.4689e+02, 1.6276e+02, 3.7152e+01, 4.2900e+02, 1.8986e+02, 4.3243e+02, 2.1647e+02, 8.5207e+00, 2.5585e+01, 9.7145e+01, 3.3527e+01, 2.2896e+01, 1.6479e+02, 1.8936e+01, 9.0126e+01, 2.5725e+00, 3.1149e+01, 3.4242e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [1.5550e-01, 1.2749e-01, 2.0765e+00, 6.8626e-02, 3.3900e+00, 5.1628e-01, 1.0667e+00, 2.3011e+00, 1.5170e+00, 3.4627e-01, 3.9984e+00, 1.7696e+00, 4.0304e+00, 2.0176e+00, 7.9416e-02, 2.3846e-01, 9.0542e-01, 3.1248e-01, 2.1340e-01, 1.5359e+00, 1.7649e-01, 8.4000e-01, 2.3977e-02, 2.9032e-01, 3.1914e-02, 5.5462e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [5.6046e-01, 4.5950e-01, 7.4844e+00, 2.4735e-01, 1.2219e+01, 1.8608e+00, 3.8447e+00, 8.2938e+00, 5.4677e+00, 1.2481e+00, 1.4412e+01, 6.3781e+00, 1.4527e+01, 7.2721e+00, 2.8624e-01, 8.5950e-01, 3.2634e+00, 1.1263e+00, 7.6915e-01, 5.5358e+00, 6.3613e-01, 3.0276e+00, 8.6420e-02, 1.0464e+00, 1.1503e-01, 1.9990e-02, 3.6539e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [8.5440e-01, 7.0049e-01, 1.1410e+01, 3.7708e-01, 1.8627e+01, 2.8368e+00, 5.8610e+00, 1.2644e+01, 8.3353e+00, 1.9026e+00, 2.1970e+01, 9.7232e+00, 2.2145e+01, 1.1086e+01, 4.3636e-01, 1.3103e+00, 4.9750e+00, 1.7170e+00, 1.1725e+00, 8.4391e+00, 9.6975e-01, 4.6155e+00, 1.3174e-01, 1.5952e+00, 1.7536e-01, 3.0475e-02, 5.5703e-01, 2.1062e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [8.9630e+00, 7.3484e+00, 1.1969e+02, 3.9557e+00, 1.9540e+02, 2.9759e+01, 6.1484e+01, 1.3264e+02, 8.7440e+01, 1.9959e+01, 2.3047e+02, 1.0200e+02, 2.3231e+02, 1.1630e+02, 4.5776e+00, 1.3745e+01, 5.2189e+01, 1.8012e+01, 1.2300e+01, 8.8529e+01, 1.0173e+01, 4.8418e+01, 1.3820e+00, 1.6734e+01, 1.8396e+00, 3.1969e-01, 5.8434e+00, 2.2094e+00, 3.1854e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [4.6268e+00, 3.7933e+00, 6.1787e+01, 2.0420e+00, 1.0087e+02, 1.5362e+01, 3.1739e+01, 6.8469e+01, 4.5138e+01, 1.0303e+01, 1.1897e+02, 5.2654e+01, 1.1992e+02, 6.0034e+01, 2.3630e+00, 7.0955e+00, 2.6941e+01, 9.2980e+00, 6.3497e+00, 4.5700e+01, 5.2515e+00, 2.4994e+01, 7.1343e-01, 8.6385e+00, 9.4961e-01, 1.6503e-01, 3.0165e+00, 1.1406e+00, 1.6444e+00, 2.7982e+00, 0.0000e+00, 0.0000e+00],\n",
       "          [4.7436e+00, 3.8891e+00, 6.3347e+01, 2.0935e+00, 1.0342e+02, 1.5750e+01, 3.2541e+01, 7.0197e+01, 4.6278e+01, 1.0563e+01, 1.2198e+02, 5.3983e+01, 1.2295e+02, 6.1550e+01, 2.4227e+00, 7.2747e+00, 2.7621e+01, 9.5328e+00, 6.5100e+00, 4.6854e+01, 5.3841e+00, 2.5625e+01, 7.3144e-01, 8.8566e+00, 9.7359e-01, 1.6920e-01, 3.0926e+00, 1.1693e+00, 1.6859e+00, 2.8688e+00, 1.3876e+00, 0.0000e+00],\n",
       "          [2.3196e+00, 1.9017e+00, 3.0976e+01, 1.0237e+00, 5.0570e+01, 7.7014e+00, 1.5912e+01, 3.4325e+01, 2.2629e+01, 5.1653e+00, 5.9645e+01, 2.6397e+01, 6.0122e+01, 3.0097e+01, 1.1847e+00, 3.5572e+00, 1.3506e+01, 4.6614e+00, 3.1833e+00, 2.2911e+01, 2.6327e+00, 1.2530e+01, 3.5766e-01, 4.3307e+00, 4.7607e-01, 8.2734e-02, 1.5122e+00, 5.7179e-01, 8.2437e-01, 1.4028e+00, 6.7850e-01, 2.1705e+00]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(logD_tile_paper-vecM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logD_tile_paper - logD_tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matQ_tiles: 4, torch.Size([1, 1, 8, 4]) | matK_tiles: 4, torch.Size([1, 1, 8, 4])\n"
     ]
    }
   ],
   "source": [
    "# tiled version\n",
    "dQ_pt_t, dK_pt_t, dV_pt_t, dI_pt_t, dF_pt_t, matDtilde_t = mlstm_parallel_w_groupnorm_torch_tiled_bw(\n",
    "    matDeltaHtilde=dH,\n",
    "    matQ=qs,\n",
    "    matK=ks,\n",
    "    matV=vs,\n",
    "    vecN=vecN,\n",
    "    vecM=vecM,\n",
    "    vecI=igs.squeeze(-1),\n",
    "    vecF=fgs.squeeze(-1),\n",
    "    BLOCK_Q=BLOCK_Q,\n",
    "    BLOCK_KV=BLOCK_KV,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dI_pt_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [-4.4409e-16,  0.0000e+00,  0.0000e+00, -4.4409e-16],\n",
       "           [-2.7756e-17, -2.7756e-17,  0.0000e+00,  0.0000e+00],\n",
       "           [-8.8818e-16,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  3.5527e-15,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.3878e-17],\n",
       "           [ 5.5511e-17,  0.0000e+00,  0.0000e+00, -5.5511e-17],\n",
       "           [-2.7756e-17,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.0817e-17],\n",
       "           [ 0.0000e+00,  0.0000e+00, -2.2204e-16, -2.7756e-17],\n",
       "           [ 0.0000e+00,  0.0000e+00,  8.3267e-17,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -2.2204e-16],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  3.5527e-15,  1.7764e-15,  0.0000e+00],\n",
       "           [-1.7347e-18,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [-1.7347e-18, -2.7756e-17,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  5.5511e-17, -5.5511e-17,  0.0000e+00],\n",
       "           [ 0.0000e+00, -2.2204e-16,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.5511e-17],\n",
       "           [-5.5511e-17, -2.4286e-17,  0.0000e+00,  2.2204e-16],\n",
       "           [ 0.0000e+00,  0.0000e+00, -3.5527e-15,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64),\n",
       " torch.Size([1, 1, 32, 4]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dQ_pt_t, dQ_pt_p, \n",
    "dQ_pt_t - dQ_pt_p, dQ_pt_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.2204e-16,  2.7756e-17,  0.0000e+00, -2.2204e-16],\n",
       "          [ 4.4409e-16,  1.3878e-17,  1.1102e-16,  0.0000e+00],\n",
       "          [ 0.0000e+00, -2.2204e-16,  0.0000e+00, -4.4409e-16],\n",
       "          [ 0.0000e+00,  1.3878e-17, -5.5511e-17,  1.1102e-16],\n",
       "          [ 8.8818e-16, -1.7764e-15,  0.0000e+00,  1.7764e-15],\n",
       "          [-3.3307e-16,  2.2204e-16, -2.2204e-16,  4.4409e-16],\n",
       "          [-1.7764e-15, -2.6645e-15, -3.5527e-15,  1.7764e-15],\n",
       "          [ 8.8818e-16, -2.2204e-16,  4.4409e-16,  1.7764e-15],\n",
       "          [ 8.8818e-16,  1.7764e-15, -1.7764e-15,  2.2204e-16],\n",
       "          [ 2.2204e-16,  1.1102e-16, -4.4409e-16,  5.5511e-17],\n",
       "          [ 2.6645e-15,  8.8818e-16,  1.7764e-15, -4.4409e-16],\n",
       "          [ 3.5527e-15,  0.0000e+00, -3.5527e-15,  0.0000e+00],\n",
       "          [ 2.2204e-16, -2.2204e-16,  1.7764e-15,  3.5527e-15],\n",
       "          [-1.3878e-17,  0.0000e+00, -5.5511e-17,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.1102e-16, -6.9389e-18],\n",
       "          [-1.1102e-16,  4.4409e-16, -1.7764e-15,  0.0000e+00],\n",
       "          [-1.1102e-16,  0.0000e+00, -5.5511e-17,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -5.5511e-17],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  5.5511e-17],\n",
       "          [ 0.0000e+00, -8.8818e-16,  0.0000e+00,  5.5511e-17],\n",
       "          [ 3.4694e-18,  0.0000e+00,  0.0000e+00, -2.2204e-16],\n",
       "          [ 0.0000e+00, -3.5527e-15, -8.8818e-16, -1.1102e-16],\n",
       "          [ 0.0000e+00,  0.0000e+00,  1.6653e-16, -4.4409e-16],\n",
       "          [ 1.7764e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dK_pt_t - dK_pt_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00, -1.1102e-16,  0.0000e+00],\n",
       "          [ 8.6736e-19, -5.5511e-17, -5.5511e-17, -2.7756e-17],\n",
       "          [ 4.4409e-16, -1.7764e-15,  3.5527e-15,  1.7764e-15],\n",
       "          [ 0.0000e+00, -2.2204e-16, -2.2204e-16,  2.2204e-16],\n",
       "          [ 4.4409e-16, -2.2204e-16,  4.4409e-16,  4.4409e-16],\n",
       "          [ 8.8818e-16, -4.4409e-16,  8.8818e-16,  1.7764e-15],\n",
       "          [-2.2204e-16, -2.2204e-16,  4.4409e-16, -4.4409e-16],\n",
       "          [ 2.7756e-17,  2.2204e-16,  0.0000e+00, -1.1102e-16],\n",
       "          [ 1.1102e-16,  6.6613e-16,  1.1102e-16,  2.2204e-16],\n",
       "          [ 5.5511e-17,  0.0000e+00,  2.2204e-16,  0.0000e+00],\n",
       "          [ 2.2204e-16, -1.7764e-15,  1.1102e-16, -8.8818e-16],\n",
       "          [-2.7756e-17, -4.4409e-16, -6.9389e-18,  6.6613e-16],\n",
       "          [ 0.0000e+00,  2.2204e-16, -2.2204e-16,  0.0000e+00],\n",
       "          [ 0.0000e+00, -5.5511e-17,  5.5511e-17,  3.4694e-18],\n",
       "          [ 0.0000e+00,  5.5511e-17,  0.0000e+00, -1.1102e-16],\n",
       "          [ 4.4409e-16, -2.2204e-16,  0.0000e+00,  8.8818e-16],\n",
       "          [ 2.2204e-16,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  1.1102e-16, -2.7756e-17,  5.5511e-17],\n",
       "          [ 0.0000e+00,  1.1102e-16,  3.4694e-18,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00, -5.5511e-17,  2.2204e-16],\n",
       "          [ 8.8818e-16,  8.8818e-16,  0.0000e+00,  0.0000e+00],\n",
       "          [ 5.5511e-17, -1.1102e-16,  2.7756e-17,  0.0000e+00],\n",
       "          [-3.5527e-15,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dV_pt_t - dV_pt_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt220cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
