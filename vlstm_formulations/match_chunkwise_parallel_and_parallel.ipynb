{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch \n",
    "\n",
    "from vlstm_parallel import vlstm_fw_torch\n",
    "from vlstm_recurrent import vlstm_recurrent_sequence_stabilized\n",
    "from vlstm_chunkwise_parallel import vlstm_chunkwise_parallel\n",
    "from einops import rearrange\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match vLSTM chunkwise parallel to parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "S = 12\n",
    "NH = 1\n",
    "DH = 2\n",
    "EPS = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(5)\n",
    "igate_preacts = torch.randn((B, NH, S, 1), dtype=DTYPE, device=DEVICE)\n",
    "fgate_preacts = torch.randn((B, NH, S, 1), dtype=DTYPE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "igate_preacts = 5 * torch.arange(B * NH * S, dtype=DTYPE, device=DEVICE).reshape(B, NH, S, 1) / 10000\n",
    "fgate_preacts = torch.arange(B * NH * S, dtype=DTYPE, device=DEVICE).reshape(B, NH, S, 1) +1 # / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# igate_preacts = 5 * torch.arange(B * NH * S, dtype=DTYPE, device=DEVICE).reshape(B, NH, S, 1) / 10000\n",
    "# fgate_preacts = torch.arange(B * NH * S, dtype=DTYPE, device=DEVICE).reshape(B, NH, S, 1) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgate_preacts, igate_preacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 12, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = torch.randn((B, NH, S, DH), dtype=DTYPE, device=DEVICE)\n",
    "ks = torch.randn((B, NH, S, DH), dtype=DTYPE, device=DEVICE)\n",
    "vs = torch.randn((B, NH, S, DH), dtype=DTYPE, device=DEVICE)\n",
    "vs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = vlstm_fw_torch(qs, ks, vs, igate_preacts, fgate_preacts, eps=EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_r = vlstm_recurrent_sequence_stabilized(qs, ks, vs, igate_preacts, fgate_preacts, normalization_mode=\"max_abs_sum_C_1\", eps=EPS)\n",
    "# y_r, torch.allclose(y_p, y_r, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1036, -0.1770],\n",
       "          [ 0.3631, -0.0846],\n",
       "          [ 0.0722,  0.5899],\n",
       "          [ 0.2939, -0.5616],\n",
       "          [-0.9256, -0.9527],\n",
       "          [-0.1738,  2.1624],\n",
       "          [ 0.0913,  1.3176],\n",
       "          [-0.4555, -0.8872],\n",
       "          [ 0.9848,  1.8037],\n",
       "          [ 0.5587,  2.6535],\n",
       "          [ 0.2654, -1.3075],\n",
       "          [ 0.2538,  4.0591]]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_fgates: torch.Size([1, 1, 3, 4])\n",
      "tensor([[[[-3.1326e-01, -1.2693e-01, -4.8587e-02, -1.8150e-02],\n",
      "          [-6.7153e-03, -2.4757e-03, -9.1147e-04, -3.3541e-04],\n",
      "          [-1.2340e-04, -4.5399e-05, -1.6702e-05, -6.1442e-06]]]],\n",
      "       device='cuda:0')\n",
      "p_vec_f: torch.Size([1, 1, 3, 4])\n",
      "tensor([[[[-3.1326e-01, -4.4019e-01, -4.8878e-01, -5.0693e-01],\n",
      "          [-6.7153e-03, -9.1910e-03, -1.0103e-02, -1.0438e-02],\n",
      "          [-1.2340e-04, -1.6880e-04, -1.8550e-04, -1.9165e-04]]]],\n",
      "       device='cuda:0')\n",
      "q_vec_f: torch.Size([1, 1, 3, 4])\n",
      "tensor([[[[-1.9367e-01, -6.6737e-02, -1.8150e-02,  0.0000e+00],\n",
      "          [-3.7226e-03, -1.2469e-03, -3.3541e-04,  0.0000e+00],\n",
      "          [-6.8245e-05, -2.2846e-05, -6.1442e-06,  0.0000e+00]]]],\n",
      "       device='cuda:0')\n",
      "g_vec: torch.Size([1, 1, 3])\n",
      "tensor([[[-5.0693e-01, -1.0438e-02, -1.9165e-04]]], device='cuda:0')\n",
      "log_fg_k_matrix: torch.Size([1, 1, 4, 4])\n",
      "tensor([[[[ 0.0000,    -inf,    -inf,    -inf],\n",
      "          [-0.1269,  0.0000,    -inf,    -inf],\n",
      "          [-0.1755, -0.0486,  0.0000,    -inf],\n",
      "          [-0.1937, -0.0667, -0.0181,  0.0000]]]], device='cuda:0')\n",
      "log_fg_k_matrix: torch.Size([1, 1, 4, 4])\n",
      "tensor([[[[ 0.0000,    -inf,    -inf,    -inf],\n",
      "          [-0.0025,  0.0000,    -inf,    -inf],\n",
      "          [-0.0034, -0.0009,  0.0000,    -inf],\n",
      "          [-0.0037, -0.0012, -0.0003,  0.0000]]]], device='cuda:0')\n",
      "log_fg_k_matrix: torch.Size([1, 1, 4, 4])\n",
      "tensor([[[[ 0.0000e+00,        -inf,        -inf,        -inf],\n",
      "          [-4.5399e-05,  0.0000e+00,        -inf,        -inf],\n",
      "          [-6.2100e-05, -1.6702e-05,  0.0000e+00,        -inf],\n",
      "          [-6.8245e-05, -2.2846e-05, -6.1442e-06,  0.0000e+00]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-0.1036, -0.1770],\n",
       "           [ 0.3631, -0.0846],\n",
       "           [ 0.0722,  0.5899],\n",
       "           [ 0.2939, -0.5616]],\n",
       "\n",
       "          [[-0.9256, -0.9527],\n",
       "           [-0.1738,  2.1624],\n",
       "           [ 0.0913,  1.3176],\n",
       "           [-0.4555, -0.8872]],\n",
       "\n",
       "          [[ 0.9848,  1.8037],\n",
       "           [ 0.5587,  2.6535],\n",
       "           [ 0.2654, -1.3075],\n",
       "           [ 0.2538,  4.0591]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cp = vlstm_chunkwise_parallel(qs, ks, vs, igate_preacts, fgate_preacts, chunk_size=4)\n",
    "y_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_cp\n",
    "# tensor([[[[[-0.0192, -0.0328,  0.0145],\n",
    "#            [-0.0261,  0.8259, -0.9299],\n",
    "#            [ 0.1474, -0.2691, -0.9078],\n",
    "#            [-0.9536, -0.7056, -0.2249]],\n",
    "\n",
    "#           [[-0.1601,  0.1721,  0.6033],\n",
    "#            [-0.4301,  0.2871, -0.6484],\n",
    "#            [-0.5925, -0.2081,  0.4734],\n",
    "#            [ 0.0110,  0.5813, -0.0628]],\n",
    "\n",
    "#           [[ 3.6917,  0.4356,  1.7668],\n",
    "#            [-5.2968, -1.1374, -2.3225],\n",
    "#            [ 1.3773, -0.6453,  0.6941],\n",
    "#            [-2.3798, -2.3140, -3.1298]]]]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-0.1036, -0.1770],\n",
       "           [ 0.3631, -0.0846],\n",
       "           [ 0.0722,  0.5899],\n",
       "           [ 0.2939, -0.5616]],\n",
       "\n",
       "          [[-0.9256, -0.9527],\n",
       "           [-0.1738,  2.1624],\n",
       "           [ 0.0913,  1.3176],\n",
       "           [-0.4555, -0.8872]],\n",
       "\n",
       "          [[ 0.9848,  1.8037],\n",
       "           [ 0.5587,  2.6535],\n",
       "           [ 0.2654, -1.3075],\n",
       "           [ 0.2538,  4.0591]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(y_p, \"b nh (nc l) dh -> b nh nc l dh\", l=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0.0000e+00,  0.0000e+00],\n",
       "           [ 2.9802e-08, -2.2352e-08],\n",
       "           [-2.2352e-08,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "          [[ 5.9605e-08,  1.1921e-07],\n",
       "           [-4.4703e-08, -4.7684e-07],\n",
       "           [ 1.4901e-08, -1.1921e-07],\n",
       "           [-5.9605e-08, -1.7881e-07]],\n",
       "\n",
       "          [[ 1.1921e-07, -2.3842e-07],\n",
       "           [-1.7881e-07,  0.0000e+00],\n",
       "           [ 0.0000e+00,  2.3842e-07],\n",
       "           [-1.4901e-07,  4.7684e-07]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(y_p, \"b nh (nc l) dh -> b nh nc l dh\", l=4) - y_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# v1:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# tensor([[[[[-5.5879e-09, -7.4506e-09,  3.7253e-09],\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#            [-2.4214e-08,  5.9605e-08, -1.1921e-07],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#            [-4.5993e-03,  1.3285e-03, -3.2961e-03]]]]], device='cuda:0')\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# v2: \u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtensor\u001b[49m([[[[[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5.5879e-09\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7.4506e-09\u001b[39m,  \u001b[38;5;241m3.7253e-09\u001b[39m],\n\u001b[1;32m     18\u001b[0m            [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.4214e-08\u001b[39m,  \u001b[38;5;241m5.9605e-08\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.1921e-07\u001b[39m],\n\u001b[1;32m     19\u001b[0m            [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.4901e-08\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.9802e-08\u001b[39m,  \u001b[38;5;241m0.0000e+00\u001b[39m],\n\u001b[1;32m     20\u001b[0m            [ \u001b[38;5;241m1.1921e-07\u001b[39m,  \u001b[38;5;241m1.7881e-07\u001b[39m,  \u001b[38;5;241m7.4506e-08\u001b[39m]],\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m           [[ \u001b[38;5;241m3.5303e-04\u001b[39m,  \u001b[38;5;241m2.3117e-03\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.8356e-03\u001b[39m],\n\u001b[1;32m     23\u001b[0m            [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8.3545e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.8289e-03\u001b[39m,  \u001b[38;5;241m1.4748e-03\u001b[39m],\n\u001b[1;32m     24\u001b[0m            [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3.3039e-04\u001b[39m,  \u001b[38;5;241m5.4850e-04\u001b[39m,  \u001b[38;5;241m2.7516e-04\u001b[39m],\n\u001b[1;32m     25\u001b[0m            [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6.4742e-05\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.2787e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.7010e-05\u001b[39m]],\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m           [[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.3964e-04\u001b[39m,  \u001b[38;5;241m6.8247e-06\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.9681e-04\u001b[39m],\n\u001b[1;32m     28\u001b[0m            [ \u001b[38;5;241m1.7977e-04\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.2650e-06\u001b[39m,  \u001b[38;5;241m8.1778e-05\u001b[39m],\n\u001b[1;32m     29\u001b[0m            [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.6689e-05\u001b[39m,  \u001b[38;5;241m2.7418e-06\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.1723e-06\u001b[39m],\n\u001b[1;32m     30\u001b[0m            [ \u001b[38;5;241m8.3447e-06\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2.3842e-06\u001b[39m,  \u001b[38;5;241m5.7220e-06\u001b[39m]]]]], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tensor' is not defined"
     ]
    }
   ],
   "source": [
    "# v1:\n",
    "# tensor([[[[[-5.5879e-09, -7.4506e-09,  3.7253e-09],\n",
    "#            [-2.4214e-08,  5.9605e-08, -1.1921e-07],\n",
    "#            [-1.4901e-08, -2.9802e-08,  0.0000e+00],\n",
    "#            [ 1.1921e-07,  1.7881e-07,  7.4506e-08]],\n",
    "\n",
    "#           [[ 2.7397e-04,  1.7940e-03, -2.2005e-03],\n",
    "#            [-3.2905e-04, -1.9018e-03,  5.8073e-04],\n",
    "#            [ 2.1350e-04, -3.5465e-04, -1.7783e-04],\n",
    "#            [ 2.2422e-04,  7.9042e-04,  5.8800e-05]],\n",
    "\n",
    "#           [[ 1.2011e-02, -1.8224e-04,  5.3725e-03],\n",
    "#            [-1.3653e-02,  1.6749e-04, -6.2060e-03],\n",
    "#            [ 3.4611e-03, -5.6410e-04,  8.6242e-04],\n",
    "#            [-4.5993e-03,  1.3285e-03, -3.2961e-03]]]]], device='cuda:0')\n",
    "# v2: \n",
    "# tensor([[[[[-5.5879e-09, -7.4506e-09,  3.7253e-09],\n",
    "#            [-2.4214e-08,  5.9605e-08, -1.1921e-07],\n",
    "#            [-1.4901e-08, -2.9802e-08,  0.0000e+00],\n",
    "#            [ 1.1921e-07,  1.7881e-07,  7.4506e-08]],\n",
    "\n",
    "#           [[ 3.5303e-04,  2.3117e-03, -2.8356e-03],\n",
    "#            [-8.3545e-04, -4.8289e-03,  1.4748e-03],\n",
    "#            [-3.3039e-04,  5.4850e-04,  2.7516e-04],\n",
    "#            [-6.4742e-05, -2.2787e-04, -1.7010e-05]],\n",
    "\n",
    "#           [[-4.3964e-04,  6.8247e-06, -1.9681e-04],\n",
    "#            [ 1.7977e-04, -2.2650e-06,  8.1778e-05],\n",
    "#            [-1.6689e-05,  2.7418e-06, -4.1723e-06],\n",
    "#            [ 8.3447e-06, -2.3842e-06,  5.7220e-06]]]]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = qs\n",
    "keys = ks\n",
    "values = vs\n",
    "igate_preact = igate_preacts\n",
    "fgate_preact = fgate_preacts\n",
    "chunk_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, NH, S, DH = queries.shape\n",
    "_dtype, _device = queries.dtype, queries.device\n",
    "qs = rearrange(queries, \"b nh (nc l) dh -> b nh nc l dh\", l=chunk_size) * (DH**-0.5)\n",
    "ks = rearrange(keys, \"b nh (nc l) dh -> b nh nc l dh\", l=chunk_size)\n",
    "vs = rearrange(values, \"b nh (nc l) dh -> b nh nc l dh\", l=chunk_size)\n",
    "_, _, NC, L, _ = qs.shape\n",
    "igs = rearrange(igate_preact, \"b nh (nc l) 1 -> b nh nc l\", l=chunk_size)\n",
    "fgs = rearrange(fgate_preact, \"b nh (nc l) 1 -> b nh nc l\", l=chunk_size)\n",
    "\n",
    "# compute the gates, the g and the p and q vectors\n",
    "log_fgates = F.logsigmoid(fgs)\n",
    "\n",
    "p_vec_f = torch.cat(\n",
    "    [\n",
    "        torch.zeros((B, NH, NC, 1), dtype=_dtype, device=_device),\n",
    "        log_fgates[:, :, :, :-1].cumsum(-1),\n",
    "    ],\n",
    "    dim=-1,\n",
    ")\n",
    "\n",
    "q_vec_f_raw = torch.cat(\n",
    "    [\n",
    "        torch.zeros((B, NH, NC, 1), dtype=_dtype, device=_device),\n",
    "        log_fgates[:, :, :, 1:].cumsum(-1),\n",
    "    ],\n",
    "    dim=-1,\n",
    ")\n",
    "q_vec_f = log_fgates[:, :, :, 1:].sum(-1, keepdim=True) - q_vec_f_raw\n",
    "\n",
    "p_vec = p_vec_f + igs\n",
    "q_vec = q_vec_f + igs\n",
    "g_vec = log_fgates.sum(-1)\n",
    "\n",
    "# get the maximum values per chunk for p and q\n",
    "p_vec_max = p_vec.max(-1).values\n",
    "q_vec_max = q_vec.max(-1).values\n",
    "\n",
    "\n",
    "# loop 1: materialize the  C_k, n_k, m_k\n",
    "C_states = torch.zeros((B, NH, NC, DH, DH), dtype=_dtype, device=_device)\n",
    "n_states = torch.zeros((B, NH, NC, DH), dtype=_dtype, device=_device)\n",
    "m_states = torch.zeros((B, NH, NC, 1), dtype=_dtype, device=_device)\n",
    "\n",
    "m_k = torch.zeros((B, NH, 1), dtype=_dtype, device=_device)\n",
    "m_prev_k = torch.zeros((B, NH, 1), dtype=_dtype, device=_device)\n",
    "C_k = torch.zeros((B, NH, DH, DH), dtype=_dtype, device=_device)\n",
    "C_prev_k = torch.zeros((B, NH, DH, DH), dtype=_dtype, device=_device)\n",
    "n_k = torch.zeros((B, NH, DH), dtype=_dtype, device=_device)\n",
    "n_prev_k = torch.zeros((B, NH, DH), dtype=_dtype, device=_device)\n",
    "for k in range(1, NC):\n",
    "    i = k - 1\n",
    "    # m_k\n",
    "    m_q_k = q_vec_max[:, :, i]\n",
    "    g_k = g_vec[:, :, i]\n",
    "    m_k = torch.max(g_k + m_prev_k, m_q_k)\n",
    "    m_states[:, :, k] = m_k\n",
    "\n",
    "    # C_k\n",
    "    k_chunk = ks[:, :, i, :, :].clone()\n",
    "    v_chunk = vs[:, :, i, :, :].clone()\n",
    "    q_k = q_vec[:, :, i, :].clone()\n",
    "    k_chunk_gated = k_chunk * torch.exp(q_k - m_k).unsqueeze(-1)\n",
    "\n",
    "    C_k = (\n",
    "        torch.exp(g_k + m_prev_k - m_k) * C_prev_k\n",
    "        + k_chunk_gated.transpose(-2, -1) @ v_chunk\n",
    "    )\n",
    "    C_states[:, :, k] = C_k\n",
    "\n",
    "    # n_k\n",
    "    n_k = torch.exp(g_k + m_prev_k - m_k) * n_prev_k + k_chunk_gated.transpose(\n",
    "        -2, -1\n",
    "    ).sum(-1)\n",
    "    n_states[:, :, k] = n_k\n",
    "\n",
    "    # move to the next iteration\n",
    "    m_prev_k = m_k\n",
    "    C_prev_k = C_k\n",
    "    n_prev_k = n_k\n",
    "\n",
    "# loop 2: compute the H_states\n",
    "H_states = torch.zeros((B, NH, NC, L, DH), dtype=_dtype, device=_device)\n",
    "for k in range(1, NC + 1):\n",
    "    i = k - 1\n",
    "\n",
    "    # load C_k, n_k, m_k\n",
    "    C_k = C_states[:, :, i]\n",
    "    n_k_inter = n_states[:, :, i]\n",
    "    m_k = m_states[:, :, i]\n",
    "    # load q, k, v chunks\n",
    "    q_chunk = qs[:, :, i, :, :].clone()\n",
    "    k_chunk = ks[:, :, i, :, :].clone()\n",
    "    v_chunk = vs[:, :, i, :, :].clone()\n",
    "\n",
    "    # ? Compute inter chunk contribution: H_inter\n",
    "    p_k = p_vec[:, :, i, :].clone()\n",
    "\n",
    "    m_p_k = p_vec_max[:, :, i]\n",
    "    m_H = torch.max(m_p_k, m_k)\n",
    "    q_chunk_gated = q_chunk * torch.exp(p_k - m_H).unsqueeze(-1)\n",
    "\n",
    "    denom_k_inter = torch.max(\n",
    "        torch.abs(q_chunk_gated @ n_k_inter.unsqueeze(-1)), torch.exp(-m_k - m_H)\n",
    "    )\n",
    "\n",
    "    H_inter = q_chunk_gated @ C_k / denom_k_inter\n",
    "\n",
    "    # ? Compute intra chunk contribution: H_intra\n",
    "    # this is similar to the parallel version, but only for the current chunk\n",
    "    log_fg_k = log_fgates[:, :, i].unsqueeze(-1)  # (B, NH, L, 1)\n",
    "    log_ig_k = igs[:, :, i].unsqueeze(-1)  # (B, NH, L, 1)\n",
    "    ltr = torch.tril(\n",
    "        torch.ones(\n",
    "            (L, L),\n",
    "            dtype=torch.bool,\n",
    "            device=_device,\n",
    "        )\n",
    "    )\n",
    "    log_fg_k_cumsum = torch.cat(\n",
    "        [\n",
    "            torch.zeros((B, NH, 1, 1), dtype=_dtype, device=_device),\n",
    "            torch.cumsum(log_fg_k, dim=-2),\n",
    "        ],\n",
    "        dim=-2,\n",
    "    )  # (B, NH, L+1, 1)\n",
    "    # for each batch/head this is a matrix of shape (L+1, L+1) containing the cumsum of the log forget gate values\n",
    "    # in the second dimension (colum dimension). Each row has the same is a copy of the first row.\n",
    "    # First entry of each row is zero.\n",
    "    rep_log_fg_k_cumsum = log_fg_k_cumsum.repeat(1, 1, 1, L + 1)  # (B, NH, L+1, L+1)\n",
    "    # Now in each row cut off / subtract the forgetgate values of the later timesteps\n",
    "    # where col j > row i\n",
    "    _log_fg_k_matrix = rep_log_fg_k_cumsum - rep_log_fg_k_cumsum.transpose(\n",
    "        -2, -1\n",
    "    )  # (B, NH, L+1, L+1)\n",
    "    # Causal masking & selection of the correct submatrix, such that forgetgate at timestep t is not applied\n",
    "    # to the input at timestep t\n",
    "    log_fg_k_matrix = torch.where(\n",
    "        ltr, _log_fg_k_matrix[:, :, 1:, 1:], -float(\"inf\")\n",
    "    )  # (B, NH, L, L)\n",
    "\n",
    "    log_D_k = log_fg_k_matrix + log_ig_k.transpose(-2, -1)  # (B, NH, L, L)\n",
    "\n",
    "    # compute the max state (for now isolated for intra chunk contribution)\n",
    "    m_log_D_k = torch.max(log_D_k, dim=-1, keepdim=True).values\n",
    "\n",
    "    log_D_k_stabilized = log_D_k - m_log_D_k\n",
    "    D_k = torch.exp(log_D_k_stabilized)\n",
    "    qk_k_matrix = q_chunk @ k_chunk.transpose(-2, -1)\n",
    "    C_k_matrix = qk_k_matrix * D_k\n",
    "\n",
    "    denom_k_intra = torch.maximum(\n",
    "        C_k_matrix.sum(dim=-1, keepdim=True).abs(), torch.exp(-m_log_D_k)\n",
    "    )\n",
    "    C_k_matrix_normalized = C_k_matrix / denom_k_intra  # TODO add eps\n",
    "\n",
    "    H_intra = C_k_matrix_normalized @ v_chunk  # (B, NH, L, DH)\n",
    "    H_states[:, :, i, :, :] = (denom_k_inter / denom_k_intra) * H_inter + H_intra\n",
    "\n",
    "# H_y = rearrange(H_states, \"b nh nc l dh -> b nh (nc l) dh\")\n",
    "\n",
    "# we do not need the first forget gate as this is applied to the first element\n",
    "# log_fgates_cumsum = log_fgates[:, :, 1:].cumsum(-1)\n",
    "# d_vec = torch.cat(\n",
    "#     [torch.zeros((B, NH, 1, 1), dtype=_dtype, device=_device), log_fgates_cumsum],\n",
    "#     dim=-2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-0.9131, -0.6950,  0.3553],\n",
       "           [-0.9939,  0.3550,  1.3450],\n",
       "           [-1.2052,  0.5400,  1.5244],\n",
       "           [ 0.5647, -0.1064, -0.7442]],\n",
       "\n",
       "          [[ 3.4731, -0.7237, -2.6495],\n",
       "           [ 0.2019,  0.2291,  0.4814],\n",
       "           [ 0.6854,  0.2205, -0.3705],\n",
       "           [ 0.8782,  0.2471, -2.1387]],\n",
       "\n",
       "          [[-0.2243, -0.0334,  0.2088],\n",
       "           [ 0.6945,  0.0576, -0.6253],\n",
       "           [-0.6054, -0.6223,  0.4894],\n",
       "           [-0.6631,  3.1439, -1.1159]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-1.0596, -1.0655, -1.0648, -1.6584],\n",
       "           [-0.4953, -1.0422, -1.2319, -1.2757],\n",
       "           [-0.6950, -0.9492, -0.5191, -0.2592]]]], device='cuda:0'),\n",
       " tensor([[[[-0.2963,  2.6764, -0.1408, -0.8441],\n",
       "           [ 0.2905, -0.2838, -1.4535,  2.3737],\n",
       "           [-0.0177, -2.7884, -0.3788,  0.7046]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_fgates, igs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "          [[ 0.7340, -0.6587, -1.6607],\n",
       "           [ 0.0045,  0.4336,  0.6466],\n",
       "           [-0.9611,  0.2796,  1.4387]],\n",
       "\n",
       "          [[ 0.5968,  1.9466, -1.5605],\n",
       "           [ 0.1144,  0.3455, -0.2782],\n",
       "           [ 0.2439,  0.8581, -0.6792]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-0.9131, -0.6950,  0.3553],\n",
       "           [-0.9939,  0.3550,  1.3450],\n",
       "           [-1.2052,  0.5400,  1.5244],\n",
       "           [ 0.5647, -0.1064, -0.7442]],\n",
       "\n",
       "          [[ 3.4731, -0.7237, -2.6495],\n",
       "           [ 0.2019,  0.2291,  0.4814],\n",
       "           [ 0.6854,  0.2205, -0.3705],\n",
       "           [ 0.8782,  0.2471, -2.1387]],\n",
       "\n",
       "          [[-0.2243, -0.0334,  0.2088],\n",
       "           [ 0.6945,  0.0576, -0.6253],\n",
       "           [-0.6054, -0.6223,  0.4894],\n",
       "           [-0.6631,  3.1439, -1.1159]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 3, 1]), torch.Size([1, 1, 4, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_states[:, :, -1].unsqueeze(-1).shape, q_chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 4, 1]), torch.Size([1, 1, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q_chunk @ n_states[:, :, -1].unsqueeze(-1)).shape, m_k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.abs(q_chunk @ n_states[:, :, -1].unsqueeze(-1)), m_k).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 3]), torch.Size([1, 1, 3, 4, 3]), torch.Size([1, 1, 4, 3]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_vec.shape, ks.shape, ks[:, :, 1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kv_gated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mkv_gated\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kv_gated' is not defined"
     ]
    }
   ],
   "source": [
    "kv_gated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 5])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ks[:, :, 1, :, :] * d_vec[:, :, 1, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec[:, :, 1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[[ 0.7589],\n",
       "            [-0.7418],\n",
       "            [-2.5793],\n",
       "            [-1.5436]],\n",
       " \n",
       "           [[-1.1483],\n",
       "            [-1.1596],\n",
       "            [-4.4460],\n",
       "            [-3.5700]],\n",
       " \n",
       "           [[ 0.5241],\n",
       "            [-1.4934],\n",
       "            [-2.0288],\n",
       "            [-1.9730]]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 3, 4, 1]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec, d_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.7589],\n",
       "          [-1.1483],\n",
       "          [ 0.5241]]]], device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec.max(dim=-2).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 3, 1]), torch.Size([1, 1, 1]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals, idxs = d_vec.max(dim=-2)\n",
    "vals.shape, vals[:, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 5, 5])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ks.transpose(-1, -2) @ vs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 3, 4, 5]), torch.Size([1, 1, 3, 4, 1]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks.shape, d_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 4, 5])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(d_vec * ks).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_fgates[:, :, :, 1:].cumsum(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 4, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt220cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
