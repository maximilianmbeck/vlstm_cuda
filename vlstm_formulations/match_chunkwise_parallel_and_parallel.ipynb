{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch \n",
    "\n",
    "from vlstm_parallel import vlstm_fw_torch\n",
    "from vlstm_recurrent import vlstm_recurrent_sequence_stabilized\n",
    "from vlstm_chunkwise_parallel import vlstm_chunkwise_parallel_3\n",
    "from einops import rearrange\n",
    "from torch.nn import functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match vLSTM chunkwise parallel to parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "S = 12\n",
    "NH = 1\n",
    "DH = 3\n",
    "EPS = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "igate_preacts = torch.randn((B, NH, S, 1), dtype=DTYPE, device=DEVICE)\n",
    "fgate_preacts = torch.randn((B, NH, S, 1), dtype=DTYPE, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# igate_preacts = 5 * torch.arange(B * NH * S, dtype=DTYPE, device=DEVICE).reshape(B, NH, S, 1) / 10000\n",
    "# fgate_preacts = torch.arange(B * NH * S, dtype=DTYPE, device=DEVICE).reshape(B, NH, S, 1) +1 # / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# igate_preacts = 5 * torch.arange(B * NH * S, dtype=DTYPE, device=DEVICE).reshape(B, NH, S, 1) / 10000\n",
    "# fgate_preacts = torch.arange(B * NH * S, dtype=DTYPE, device=DEVICE).reshape(B, NH, S, 1) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgate_preacts, igate_preacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 12, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = torch.randn((B, NH, S, DH), dtype=DTYPE, device=DEVICE)\n",
    "ks = torch.randn((B, NH, S, DH), dtype=DTYPE, device=DEVICE)\n",
    "vs = torch.randn((B, NH, S, DH), dtype=DTYPE, device=DEVICE)\n",
    "vs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = vlstm_fw_torch(qs, ks, vs, igate_preacts, fgate_preacts, eps=EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_r = vlstm_recurrent_sequence_stabilized(qs, ks, vs, igate_preacts, fgate_preacts, normalization_mode=\"max_abs_sum_C_1\", eps=EPS)\n",
    "# y_r, torch.allclose(y_p, y_r, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4766, -0.5826, -0.9475],\n",
       "          [ 0.3189, -0.5805, -0.3735],\n",
       "          [ 0.0083,  1.1414,  1.1899],\n",
       "          [-0.4672, -0.2603, -0.0403],\n",
       "          [-0.1332,  0.4042,  0.0817],\n",
       "          [ 0.6912, -0.1775, -0.1799],\n",
       "          [-1.6277, -1.1145,  0.6377],\n",
       "          [-0.4791, -0.3256,  0.1318],\n",
       "          [-0.6228,  0.2321,  0.4485],\n",
       "          [-0.1759,  0.1434,  0.1479],\n",
       "          [ 0.1849, -0.0911, -0.0084],\n",
       "          [-0.7768, -0.2171,  0.1132]]]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_fgates: torch.Size([1, 1, 3, 4])\n",
      "tensor([[[[-0.5762, -1.3072, -0.1690, -0.9215],\n",
      "          [-0.9936, -0.2652, -0.8875, -0.7972],\n",
      "          [-0.5570, -0.9301, -0.8282, -1.4776]]]], device='cuda:0')\n",
      "p_vec_f: torch.Size([1, 1, 3, 4])\n",
      "tensor([[[[-0.5762, -1.8834, -2.0525, -2.9740],\n",
      "          [-0.9936, -1.2587, -2.1462, -2.9435],\n",
      "          [-0.5570, -1.4871, -2.3153, -3.7928]]]], device='cuda:0')\n",
      "q_vec_f: torch.Size([1, 1, 3, 4])\n",
      "tensor([[[[-2.9740, -2.3977, -1.0905, -0.9215],\n",
      "          [-2.9435, -1.9499, -1.6847, -0.7972],\n",
      "          [-3.7928, -3.2359, -2.3057, -1.4776]]]], device='cuda:0')\n",
      "g_vec: torch.Size([1, 1, 3])\n",
      "tensor([[[-2.9740, -2.9435, -3.7928]]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-0.4766, -0.5826, -0.9475],\n",
       "           [ 0.3189, -0.5805, -0.3735],\n",
       "           [ 0.0083,  1.1414,  1.1899],\n",
       "           [-0.4672, -0.2603, -0.0403]],\n",
       "\n",
       "          [[-0.1608,  0.6145,  0.2053],\n",
       "           [ 0.7484, -0.2315, -0.2424],\n",
       "           [-1.6329, -1.1134,  0.6515],\n",
       "           [-0.4936, -0.3449,  0.1181]],\n",
       "\n",
       "          [[-0.6963,  0.2131,  0.4381],\n",
       "           [-0.2021,  0.1161,  0.1755],\n",
       "           [ 0.2011, -0.0778, -0.0165],\n",
       "           [-0.7652, -0.2093,  0.1081]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cp = vlstm_chunkwise_parallel_3(qs, ks, vs, igate_preacts, fgate_preacts, chunk_size=4)\n",
    "y_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = qs\n",
    "keys = ks\n",
    "values = vs\n",
    "igate_preact = igate_preacts\n",
    "fgate_preact = fgate_preacts\n",
    "chunk_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'queries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m B, NH, S, DH \u001b[38;5;241m=\u001b[39m \u001b[43mqueries\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      2\u001b[0m _dtype, _device \u001b[38;5;241m=\u001b[39m queries\u001b[38;5;241m.\u001b[39mdtype, queries\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m      3\u001b[0m qs \u001b[38;5;241m=\u001b[39m rearrange(queries, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb nh (nc l) dh -> b nh nc l dh\u001b[39m\u001b[38;5;124m\"\u001b[39m, l\u001b[38;5;241m=\u001b[39mchunk_size) \u001b[38;5;241m*\u001b[39m (DH\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'queries' is not defined"
     ]
    }
   ],
   "source": [
    "B, NH, S, DH = queries.shape\n",
    "_dtype, _device = queries.dtype, queries.device\n",
    "qs = rearrange(queries, \"b nh (nc l) dh -> b nh nc l dh\", l=chunk_size) * (DH**-0.5)\n",
    "ks = rearrange(keys, \"b nh (nc l) dh -> b nh nc l dh\", l=chunk_size)\n",
    "vs = rearrange(values, \"b nh (nc l) dh -> b nh nc l dh\", l=chunk_size)\n",
    "_, _, NC, L, _ = qs.shape\n",
    "igs = rearrange(igate_preact, \"b nh (nc l) 1 -> b nh nc l\", l=chunk_size)\n",
    "fgs = rearrange(fgate_preact, \"b nh (nc l) 1 -> b nh nc l\", l=chunk_size)\n",
    "\n",
    "# compute the gates, the g and the p and q vectors\n",
    "log_fgates = F.logsigmoid(fgs)\n",
    "\n",
    "p_vec_f = torch.cat(\n",
    "    [\n",
    "        torch.zeros((B, NH, NC, 1), dtype=_dtype, device=_device),\n",
    "        log_fgates[:, :, :, :-1].cumsum(-1),\n",
    "    ],\n",
    "    dim=-1,\n",
    ")\n",
    "\n",
    "q_vec_f_raw = torch.cat(\n",
    "    [\n",
    "        torch.zeros((B, NH, NC, 1), dtype=_dtype, device=_device),\n",
    "        log_fgates[:, :, :, 1:].cumsum(-1),\n",
    "    ],\n",
    "    dim=-1,\n",
    ")\n",
    "q_vec_f = log_fgates[:, :, :, 1:].sum(-1, keepdim=True) - q_vec_f_raw\n",
    "\n",
    "p_vec = p_vec_f + igs\n",
    "q_vec = q_vec_f + igs\n",
    "g_vec = log_fgates.sum(-1)\n",
    "\n",
    "# get the maximum values per chunk for p and q\n",
    "p_vec_max = p_vec.max(-1).values\n",
    "q_vec_max = q_vec.max(-1).values\n",
    "\n",
    "\n",
    "# loop 1: materialize the  C_k, n_k, m_k\n",
    "C_states = torch.zeros((B, NH, NC, DH, DH), dtype=_dtype, device=_device)\n",
    "n_states = torch.zeros((B, NH, NC, DH), dtype=_dtype, device=_device)\n",
    "m_states = torch.zeros((B, NH, NC, 1), dtype=_dtype, device=_device)\n",
    "\n",
    "m_k = torch.zeros((B, NH, 1), dtype=_dtype, device=_device)\n",
    "m_prev_k = torch.zeros((B, NH, 1), dtype=_dtype, device=_device)\n",
    "C_k = torch.zeros((B, NH, DH, DH), dtype=_dtype, device=_device)\n",
    "C_prev_k = torch.zeros((B, NH, DH, DH), dtype=_dtype, device=_device)\n",
    "n_k = torch.zeros((B, NH, DH), dtype=_dtype, device=_device)\n",
    "n_prev_k = torch.zeros((B, NH, DH), dtype=_dtype, device=_device)\n",
    "for k in range(1, NC):\n",
    "    i = k - 1\n",
    "    # m_k\n",
    "    m_q_k = q_vec_max[:, :, i]\n",
    "    g_k = g_vec[:, :, i]\n",
    "    m_k = torch.max(g_k + m_prev_k, m_q_k)\n",
    "    m_states[:, :, k] = m_k\n",
    "\n",
    "    # C_k\n",
    "    k_chunk = ks[:, :, i, :, :].clone()\n",
    "    v_chunk = vs[:, :, i, :, :].clone()\n",
    "    q_k = q_vec[:, :, i, :].clone()\n",
    "    k_chunk_gated = k_chunk * torch.exp(q_k - m_k).unsqueeze(-1)\n",
    "\n",
    "    C_k = (\n",
    "        torch.exp(g_k + m_prev_k - m_k) * C_prev_k\n",
    "        + k_chunk_gated.transpose(-2, -1) @ v_chunk\n",
    "    )\n",
    "    C_states[:, :, k] = C_k\n",
    "\n",
    "    # n_k\n",
    "    n_k = torch.exp(g_k + m_prev_k - m_k) * n_prev_k + k_chunk_gated.transpose(\n",
    "        -2, -1\n",
    "    ).sum(-1)\n",
    "    n_states[:, :, k] = n_k\n",
    "\n",
    "    # move to the next iteration\n",
    "    m_prev_k = m_k\n",
    "    C_prev_k = C_k\n",
    "    n_prev_k = n_k\n",
    "\n",
    "# loop 2: compute the H_states\n",
    "H_states = torch.zeros((B, NH, NC, L, DH), dtype=_dtype, device=_device)\n",
    "for k in range(1, NC + 1):\n",
    "    i = k - 1\n",
    "\n",
    "    # load C_k, n_k, m_k\n",
    "    C_k = C_states[:, :, i]\n",
    "    n_k_inter = n_states[:, :, i]\n",
    "    m_k = m_states[:, :, i]\n",
    "    # load q, k, v chunks\n",
    "    q_chunk = qs[:, :, i, :, :].clone()\n",
    "    k_chunk = ks[:, :, i, :, :].clone()\n",
    "    v_chunk = vs[:, :, i, :, :].clone()\n",
    "\n",
    "    # ? Compute inter chunk contribution: H_inter\n",
    "    p_k = p_vec[:, :, i, :].clone()\n",
    "\n",
    "    m_p_k = p_vec_max[:, :, i]\n",
    "    m_H = torch.max(m_p_k, m_k)\n",
    "    q_chunk_gated = q_chunk * torch.exp(p_k - m_H).unsqueeze(-1)\n",
    "\n",
    "    denom_k_inter = torch.max(\n",
    "        torch.abs(q_chunk_gated @ n_k_inter.unsqueeze(-1)), torch.exp(-m_k - m_H)\n",
    "    )\n",
    "\n",
    "    H_inter = q_chunk_gated @ C_k / denom_k_inter\n",
    "\n",
    "    # ? Compute intra chunk contribution: H_intra\n",
    "    # this is similar to the parallel version, but only for the current chunk\n",
    "    log_fg_k = log_fgates[:, :, i].unsqueeze(-1)  # (B, NH, L, 1)\n",
    "    log_ig_k = igs[:, :, i].unsqueeze(-1)  # (B, NH, L, 1)\n",
    "    ltr = torch.tril(\n",
    "        torch.ones(\n",
    "            (L, L),\n",
    "            dtype=torch.bool,\n",
    "            device=_device,\n",
    "        )\n",
    "    )\n",
    "    log_fg_k_cumsum = torch.cat(\n",
    "        [\n",
    "            torch.zeros((B, NH, 1, 1), dtype=_dtype, device=_device),\n",
    "            torch.cumsum(log_fg_k, dim=-2),\n",
    "        ],\n",
    "        dim=-2,\n",
    "    )  # (B, NH, L+1, 1)\n",
    "    # for each batch/head this is a matrix of shape (L+1, L+1) containing the cumsum of the log forget gate values\n",
    "    # in the second dimension (colum dimension). Each row has the same is a copy of the first row.\n",
    "    # First entry of each row is zero.\n",
    "    rep_log_fg_k_cumsum = log_fg_k_cumsum.repeat(1, 1, 1, L + 1)  # (B, NH, L+1, L+1)\n",
    "    # Now in each row cut off / subtract the forgetgate values of the later timesteps\n",
    "    # where col j > row i\n",
    "    _log_fg_k_matrix = rep_log_fg_k_cumsum - rep_log_fg_k_cumsum.transpose(\n",
    "        -2, -1\n",
    "    )  # (B, NH, L+1, L+1)\n",
    "    # Causal masking & selection of the correct submatrix, such that forgetgate at timestep t is not applied\n",
    "    # to the input at timestep t\n",
    "    log_fg_k_matrix = torch.where(\n",
    "        ltr, _log_fg_k_matrix[:, :, 1:, 1:], -float(\"inf\")\n",
    "    )  # (B, NH, L, L)\n",
    "\n",
    "    log_D_k = log_fg_k_matrix + log_ig_k.transpose(-2, -1)  # (B, NH, L, L)\n",
    "\n",
    "    # compute the max state (for now isolated for intra chunk contribution)\n",
    "    m_log_D_k = torch.max(log_D_k, dim=-1, keepdim=True).values\n",
    "\n",
    "    log_D_k_stabilized = log_D_k - m_log_D_k\n",
    "    D_k = torch.exp(log_D_k_stabilized)\n",
    "    qk_k_matrix = q_chunk @ k_chunk.transpose(-2, -1)\n",
    "    C_k_matrix = qk_k_matrix * D_k\n",
    "\n",
    "    denom_k_intra = torch.maximum(\n",
    "        C_k_matrix.sum(dim=-1, keepdim=True).abs(), torch.exp(-m_log_D_k)\n",
    "    )\n",
    "    C_k_matrix_normalized = C_k_matrix / denom_k_intra  # TODO add eps\n",
    "\n",
    "    H_intra = C_k_matrix_normalized @ v_chunk  # (B, NH, L, DH)\n",
    "    H_states[:, :, i, :, :] = (denom_k_inter / denom_k_intra) * H_inter + H_intra\n",
    "\n",
    "# H_y = rearrange(H_states, \"b nh nc l dh -> b nh (nc l) dh\")\n",
    "\n",
    "# we do not need the first forget gate as this is applied to the first element\n",
    "# log_fgates_cumsum = log_fgates[:, :, 1:].cumsum(-1)\n",
    "# d_vec = torch.cat(\n",
    "#     [torch.zeros((B, NH, 1, 1), dtype=_dtype, device=_device), log_fgates_cumsum],\n",
    "#     dim=-2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0.1950, -0.2674, -0.1591, -0.0408,  0.0139],\n",
       "           [-0.0457, -0.7729,  0.3219,  0.6750,  0.3412],\n",
       "           [-0.0534, -1.1351,  0.4686,  0.9789,  0.5149],\n",
       "           [-0.1144,  0.1129, -0.0369,  0.0488, -0.1858]],\n",
       "\n",
       "          [[-0.2556,  1.1231, -0.4512, -0.4634, -1.2010],\n",
       "           [-0.6378,  1.5420,  0.0900, -1.2322,  3.0609],\n",
       "           [ 0.9447, -0.5071,  0.8299,  1.8393, -1.2458],\n",
       "           [ 0.1122,  0.4685, -0.7218, -0.7698,  0.0353]],\n",
       "\n",
       "          [[-2.5104,  1.3194, -2.5216, -2.7714,  3.5603],\n",
       "           [ 0.7144, -0.3377, -0.2862, -0.4849, -1.0592],\n",
       "           [-1.4214,  0.7989, -0.4866, -0.0828,  1.6035],\n",
       "           [ 1.3098, -0.7683,  0.2306, -0.1338, -1.5235]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2472, -0.3480, -1.2512, -0.3286],\n",
       "           [-1.0188, -1.0823, -0.8327, -0.8236],\n",
       "           [-1.1829, -0.3297, -1.0177, -0.5052]]]], device='cuda:0'),\n",
       " tensor([[[[-0.3091, -0.5703,  1.8633, -0.4843],\n",
       "           [ 0.4213, -0.3814,  0.3600,  0.0021],\n",
       "           [-1.1131, -1.2531,  0.0982, -0.8470]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_fgates, igs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "          [[-2.7854e-02, -5.3366e-04, -4.8855e-02,  2.1908e-02,  1.1594e-01],\n",
       "           [ 7.2663e-01,  5.8536e-01,  1.6246e+00, -8.4919e-01,  9.5934e-01],\n",
       "           [-1.5995e-01, -7.0658e-02, -3.0576e-01,  1.0001e-01, -1.4419e-01],\n",
       "           [-8.1330e-01, -6.3639e-01, -1.7333e+00,  9.3910e-01, -9.0490e-01],\n",
       "           [-3.8330e-01, -2.8181e-01, -7.6245e-01,  4.2472e-01, -3.2418e-01]],\n",
       "\n",
       "          [[-2.4721e-01,  1.1252e+00,  1.0871e+00,  2.5634e+00,  9.1802e-02],\n",
       "           [-2.1048e-01, -4.7870e-01,  3.1842e-01, -1.0948e+00,  4.0503e-02],\n",
       "           [ 2.7336e-01, -9.8781e-02, -2.2610e-01, -8.4500e-01,  7.1335e-02],\n",
       "           [ 7.6424e-02,  5.7718e-01,  4.3890e-01,  8.7344e-01, -3.1371e-02],\n",
       "           [ 6.3420e-01,  5.0946e-02,  5.0141e-01, -2.0211e+00,  9.2150e-02]]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "          [[-0.6741, -0.5397, -1.4885,  0.7784, -0.9014],\n",
       "           [ 0.2604,  0.1975,  0.5540, -0.2985,  0.2428],\n",
       "           [ 0.0798,  0.0606,  0.1691, -0.0888,  0.0913],\n",
       "           [-0.0019, -0.0016, -0.0038,  0.0015, -0.0075]],\n",
       "\n",
       "          [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "           [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 5, 1]), torch.Size([1, 1, 4, 5]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_states[:, :, -1].unsqueeze(-1).shape, q_chunk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 4, 1]), torch.Size([1, 1, 1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q_chunk @ n_states[:, :, -1].unsqueeze(-1)).shape, m_k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.abs(q_chunk @ n_states[:, :, -1].unsqueeze(-1)), m_k).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 2 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m g_vec\u001b[38;5;241m.\u001b[39mshape, ks\u001b[38;5;241m.\u001b[39mshape, \u001b[43mks\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 2 with size 1"
     ]
    }
   ],
   "source": [
    "g_vec.shape, ks.shape, ks[:, :, 1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 5, 5])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_gated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 5])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ks[:, :, 1, :, :] * d_vec[:, :, 1, :]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec[:, :, 1, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[[ 0.7589],\n",
       "            [-0.7418],\n",
       "            [-2.5793],\n",
       "            [-1.5436]],\n",
       " \n",
       "           [[-1.1483],\n",
       "            [-1.1596],\n",
       "            [-4.4460],\n",
       "            [-3.5700]],\n",
       " \n",
       "           [[ 0.5241],\n",
       "            [-1.4934],\n",
       "            [-2.0288],\n",
       "            [-1.9730]]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 3, 4, 1]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec, d_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.7589],\n",
       "          [-1.1483],\n",
       "          [ 0.5241]]]], device='cuda:0')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec.max(dim=-2).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 3, 1]), torch.Size([1, 1, 1]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals, idxs = d_vec.max(dim=-2)\n",
    "vals.shape, vals[:, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 5, 5])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ks.transpose(-1, -2) @ vs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 3, 4, 5]), torch.Size([1, 1, 3, 4, 1]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks.shape, d_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 4, 5])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(d_vec * ks).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_fgates[:, :, :, 1:].cumsum(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 4, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vec.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt220cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
