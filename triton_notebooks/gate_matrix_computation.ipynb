{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forget Gate Matrix Computation Variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs = torch.arange(0, 10)\n",
    "igs = torch.arange(0, 10) / 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, -1, -2, -3, -4, -5, -6, -7, -8, -9],\n",
       "        [ 1,  0, -1, -2, -3, -4, -5, -6, -7, -8],\n",
       "        [ 2,  1,  0, -1, -2, -3, -4, -5, -6, -7],\n",
       "        [ 3,  2,  1,  0, -1, -2, -3, -4, -5, -6],\n",
       "        [ 4,  3,  2,  1,  0, -1, -2, -3, -4, -5],\n",
       "        [ 5,  4,  3,  2,  1,  0, -1, -2, -3, -4],\n",
       "        [ 6,  5,  4,  3,  2,  1,  0, -1, -2, -3],\n",
       "        [ 7,  6,  5,  4,  3,  2,  1,  0, -1, -2],\n",
       "        [ 8,  7,  6,  5,  4,  3,  2,  1,  0, -1],\n",
       "        [ 9,  8,  7,  6,  5,  4,  3,  2,  1,  0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs[:,None] - fgs[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_log_gate_matrix_paper(fgs: torch.Tensor, igs: torch.Tensor) -> torch.Tensor:\n",
    "    _device = fgs.device\n",
    "    _dtype = fgs.dtype\n",
    "    B, NH, S, _ = fgs.shape\n",
    "    ltr = torch.tril(\n",
    "        torch.ones(\n",
    "            (S, S),\n",
    "            dtype=torch.bool,\n",
    "            device=_device,\n",
    "        )\n",
    "    )\n",
    "    log_fgates_cumsum = torch.cat(\n",
    "        [\n",
    "            torch.zeros((B, NH, 1, 1), dtype=_dtype, device=_device),\n",
    "            torch.cumsum(fgs, dim=-2),\n",
    "        ],\n",
    "        dim=-2,\n",
    "    )  # (B, NH, S+1, 1)\n",
    "    # for each batch/head this is a matrix of shape (S+1, S+1) containing the cumsum of the log forget gate values\n",
    "    # in the second dimension (colum dimension). Each row has the same is a copy of the first row.\n",
    "    # First entry of each row is zero.\n",
    "    rep_log_fgates_cumsum = log_fgates_cumsum.repeat(\n",
    "        1, 1, 1, S + 1\n",
    "    )  # (B, NH, S+1, S+1)\n",
    "    # Now in each row cut off / subtract the forgetgate values of the later timesteps\n",
    "    # where col j > row i\n",
    "    _log_fg_matrix = rep_log_fgates_cumsum - rep_log_fgates_cumsum.transpose(\n",
    "        -2, -1\n",
    "    )  # (B, NH, S+1, S+1)\n",
    "    # Causal masking & selection of the correct submatrix, such that forgetgate at timestep t is not applied\n",
    "    # to the input at timestep t\n",
    "    log_fg_matrix = torch.where(\n",
    "        ltr, _log_fg_matrix[:, :, 1:, 1:], -float(\"inf\")\n",
    "    )  # (B, NH, S, S)\n",
    "\n",
    "    # gate decay matrix D (combination of forget gate and input gate)\n",
    "    log_D_matrix = log_fg_matrix + igs.transpose(-2, -1)  # (B, NH, S, S)\n",
    "    return log_D_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "NH = 1\n",
    "S = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs = torch.ones(B, NH, S, 1)\n",
    "igs = torch.zeros(B, NH, S, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matD_paper = construct_log_gate_matrix_paper(fgs, igs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "          [1., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "          [2., 1., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "          [3., 2., 1., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "          [4., 3., 2., 1., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "          [5., 4., 3., 2., 1., 0., -inf, -inf, -inf, -inf],\n",
       "          [6., 5., 4., 3., 2., 1., 0., -inf, -inf, -inf],\n",
       "          [7., 6., 5., 4., 3., 2., 1., 0., -inf, -inf],\n",
       "          [8., 7., 6., 5., 4., 3., 2., 1., 0., -inf],\n",
       "          [9., 8., 7., 6., 5., 4., 3., 2., 1., 0.]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matD_paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs.squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_cumsum = torch.cumsum(fgs.squeeze(-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0., -1., -2., -3., -4., -5., -6., -7., -8., -9.],\n",
       "          [ 1.,  0., -1., -2., -3., -4., -5., -6., -7., -8.],\n",
       "          [ 2.,  1.,  0., -1., -2., -3., -4., -5., -6., -7.],\n",
       "          [ 3.,  2.,  1.,  0., -1., -2., -3., -4., -5., -6.],\n",
       "          [ 4.,  3.,  2.,  1.,  0., -1., -2., -3., -4., -5.],\n",
       "          [ 5.,  4.,  3.,  2.,  1.,  0., -1., -2., -3., -4.],\n",
       "          [ 6.,  5.,  4.,  3.,  2.,  1.,  0., -1., -2., -3.],\n",
       "          [ 7.,  6.,  5.,  4.,  3.,  2.,  1.,  0., -1., -2.],\n",
       "          [ 8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.,  0., -1.],\n",
       "          [ 9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.,  0.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the gate matrix via subtraction\n",
    "fg_cumsum[:, :, :, None] - fg_cumsum[:, :, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False],\n",
       "        [ True, False, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True, False, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True, False, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True, False, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True, False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(S, S, dtype=torch.bool), -1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [2., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [3., 2., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [4., 3., 2., 1., 0., 0., 0., 0., 0., 0.],\n",
       "           [5., 4., 3., 2., 1., 0., 0., 0., 0., 0.],\n",
       "           [6., 5., 4., 3., 2., 1., 0., 0., 0., 0.],\n",
       "           [7., 6., 5., 4., 3., 2., 1., 0., 0., 0.],\n",
       "           [8., 7., 6., 5., 4., 3., 2., 1., 0., 0.],\n",
       "           [9., 8., 7., 6., 5., 4., 3., 2., 1., 0.]]]]),\n",
       " tensor([[[[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           [1.]]]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the matrix via repeating, masking and then cumsum\n",
    "(fgs * mask).cumsum(dim=-2), fgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiled Forget Gate matrix computation\n",
    "\n",
    "Compute a tile of the forgetgate matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "NH = 1\n",
    "S = 32\n",
    "\n",
    "BQ = 8\n",
    "BKV = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs = torch.ones(B*NH*S).reshape(B, NH, S)\n",
    "fgs_cs = torch.cumsum(fgs, dim=-1)\n",
    "fgs_rev_cs = torch.cumsum(fgs.flip(-1), dim=-1).flip(-1)\n",
    "fgs_cs, fgs_rev_cs\n",
    "igs = torch.arange(B*NH*S).reshape(B, NH, S) / 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_BQ = 2\n",
    "idx_BKV = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_chunk = fgs[:, :, idx_BKV * BKV : (idx_BKV + 1) * idx_BKV]\n",
    "fgs_cs_chunk_Q = fgs_cs[:, :, idx_BQ * BQ : (idx_BQ + 1) * BQ]\n",
    "fgs_cs_chunk_KV = fgs_cs[:, :, idx_BKV * BKV : (idx_BKV + 1) * BKV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-4., -5., -6., -7.],\n",
       "          [-3., -4., -5., -6.],\n",
       "          [-2., -3., -4., -5.],\n",
       "          [-1., -2., -3., -4.],\n",
       "          [ 0., -1., -2., -3.],\n",
       "          [ 1.,  0., -1., -2.],\n",
       "          [ 2.,  1.,  0., -1.],\n",
       "          [ 3.,  2.,  1.,  0.]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs_cs_chunk_Q[:, :, :, None] - fgs_cs_chunk_KV[:, :, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [-inf, -inf, -inf, -inf],\n",
       "          [0., -inf, -inf, -inf],\n",
       "          [1., 0., -inf, -inf],\n",
       "          [2., 1., 0., -inf],\n",
       "          [3., 2., 1., 0.]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_fgs_mat = construct_log_gate_matrix_paper(fgs.unsqueeze(-1), torch.zeros_like(fgs))\n",
    "full_fgs_mat[:, :, idx_BQ * BQ : (idx_BQ + 1) * BQ, idx_BKV * BKV : (idx_BKV + 1) * BKV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constuct_log_gate_matrix_tiled(fgs: torch.Tensor, igs: torch.Tensor, BQ: int, BKV: int, idx_BQ: int, idx_BKV, fgs_cs: torch.Tensor = None) -> torch.Tensor:\n",
    "    B, NH, S = fgs.shape\n",
    "    if fgs_cs is None:\n",
    "        fgs_cs = torch.cumsum(fgs, dim=-1)\n",
    "    fgs_cs_chunk_Q = fgs_cs[:, :, idx_BQ * BQ : (idx_BQ + 1) * BQ]\n",
    "    fgs_cs_chunk_KV = fgs_cs[:, :, idx_BKV * BKV : (idx_BKV + 1) * BKV]\n",
    "    \n",
    "    fgate_tile = fgs_cs_chunk_Q[:, :, :, None] - fgs_cs_chunk_KV[:, :, None, :]\n",
    "    \n",
    "    igs_chunk = igs[:, :, idx_BKV * BKV : (idx_BKV + 1) * BKV]\n",
    "    log_D_matrix = fgate_tile + igs_chunk\n",
    "\n",
    "    # causal masking\n",
    "    if idx_BKV * BKV >= idx_BQ * BQ:\n",
    "        bq_idxes = torch.arange(idx_BQ * BQ, (idx_BQ + 1) * BQ)\n",
    "        kv_idxes = torch.arange(idx_BKV * BKV, (idx_BKV + 1) * BKV)\n",
    "        idx_mask = bq_idxes[:, None] - kv_idxes[None, :] # or bq_idxes[:, None] >= kv_idxes[None, :]\n",
    "        log_D_matrix = torch.where(idx_mask < 0, -float(\"inf\"), log_D_matrix)\n",
    "    return log_D_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  -inf,   -inf,   -inf,   -inf],\n",
       "          [  -inf,   -inf,   -inf,   -inf],\n",
       "          [  -inf,   -inf,   -inf,   -inf],\n",
       "          [  -inf,   -inf,   -inf,   -inf],\n",
       "          [0.2000,   -inf,   -inf,   -inf],\n",
       "          [1.2000, 0.2100,   -inf,   -inf],\n",
       "          [2.2000, 1.2100, 0.2200,   -inf],\n",
       "          [3.2000, 2.2100, 1.2200, 0.2300]]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_fgs_mat = construct_log_gate_matrix_paper(fgs.unsqueeze(-1), igs.unsqueeze(-1))\n",
    "full_fgs_mat[:, :, idx_BQ * BQ : (idx_BQ + 1) * BQ, idx_BKV * BKV : (idx_BKV + 1) * BKV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  -inf,   -inf,   -inf,   -inf],\n",
       "          [  -inf,   -inf,   -inf,   -inf],\n",
       "          [  -inf,   -inf,   -inf,   -inf],\n",
       "          [  -inf,   -inf,   -inf,   -inf],\n",
       "          [0.2000,   -inf,   -inf,   -inf],\n",
       "          [1.2000, 0.2100,   -inf,   -inf],\n",
       "          [2.2000, 1.2100, 0.2200,   -inf],\n",
       "          [3.2000, 2.2100, 1.2200, 0.2300]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiled_fgs_mat = constuct_log_gate_matrix_tiled(fgs, igs, BQ, BKV, idx_BQ, idx_BKV)\n",
    "tiled_fgs_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2000, 0.2100, 0.2200, 0.2300]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "igs_chunk = igs[:, :, idx_BKV * BKV : (idx_BKV + 1) * BKV]\n",
    "igs_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16, 17, 18, 19, 20, 21, 22, 23])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_idxes = torch.arange(idx_BQ * BQ, (idx_BQ + 1) * BQ)\n",
    "bq_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 21, 22, 23])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_idxes = torch.arange(idx_BKV * BKV, (idx_BKV + 1) * BKV)\n",
    "kv_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [ True, False, False, False],\n",
       "        [ True,  True, False, False],\n",
       "        [ True,  True,  True, False],\n",
       "        [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_idxes[:, None] >= kv_idxes[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt240cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
