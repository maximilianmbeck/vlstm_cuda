{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/max/myrepos/vlstm_cuda/')\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_triton.fused_attention.triton_tutorial import attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 128 #32 #32 #16 #8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 64 # dim per head\n",
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(1) #TODO from here: with seed=0 even the pytorch version alone breaks for float16 and bfloat16\n",
    "# fixed:\n",
    "# qs = torch.arange((B*NH*S*DH), device=DEVICE, dtype=DTYPE).reshape((B, NH, S, DH)) / 10.\n",
    "# qs = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) / 100.\n",
    "# ks = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) / 100.\n",
    "# # vs = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) / 100.\n",
    "# vs = torch.arange((B*NH*S*DH), device=DEVICE, dtype=DTYPE).reshape((B, NH, S, DH)) / 100.\n",
    "# # vs = torch.zeros((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "# vs[:,:,1,0] = 7.\n",
    "# qs[:,:,1,0] = 1.\n",
    "\n",
    "# vs[:,:,1,16] = 8.\n",
    "# qs[:,:,1,16] = 1.\n",
    "# random: \n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "# igs = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1) / 10.\n",
    "# igs = torch.zeros((B, NH, S, 1), device=DEVICE, dtype=DTYPE) #/ 10.\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE) #/ 10.\n",
    "# fgs = torch.ones((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "dHs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs float16\n",
    "dtype_fp16 = torch.float16\n",
    "qs_half = qs.to(dtype=dtype_fp16)\n",
    "ks_half = ks.to(dtype=dtype_fp16)\n",
    "vs_half = vs.to(dtype=dtype_fp16)\n",
    "igs_half = igs.to(dtype=dtype_fp16)\n",
    "fgs_half = fgs.to(dtype=dtype_fp16)\n",
    "dHs_half = dHs.to(dtype=dtype_fp16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs bfloat16\n",
    "dtype_bf16 = torch.bfloat16\n",
    "qs_bf16 = qs.to(dtype=dtype_bf16)\n",
    "ks_bf16 = ks.to(dtype=dtype_bf16)\n",
    "vs_bf16 = vs.to(dtype=dtype_bf16)\n",
    "igs_bf16 = igs.to(dtype=dtype_bf16)\n",
    "fgs_bf16 = fgs.to(dtype=dtype_bf16)\n",
    "dHs_bf16 = dHs.to(dtype=dtype_bf16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.5811, -1.0215,  0.8330,  ...,  1.2637,  0.4214,  0.2869],\n",
       "          [ 0.2651,  0.0389,  0.6138,  ...,  1.9795,  0.9600,  1.1768],\n",
       "          [ 0.6157,  1.3809,  0.4976,  ...,  1.0830,  1.0732, -0.0125],\n",
       "          ...,\n",
       "          [-0.1365,  0.2446, -0.0297,  ..., -0.2944,  0.6147, -0.0832],\n",
       "          [-0.0317, -0.3557, -0.5635,  ...,  0.0829,  0.2019,  1.0996],\n",
       "          [-0.2773,  0.7500, -0.0801,  ..., -0.0390, -0.3489, -1.4082]]]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(qs_half, ks_half, vs_half, True, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.5811, -1.0215,  0.8330,  ...,  1.2637,  0.4214,  0.2869],\n",
       "          [ 0.2651,  0.0389,  0.6138,  ...,  1.9795,  0.9600,  1.1768],\n",
       "          [ 0.6157,  1.3809,  0.4976,  ...,  1.0830,  1.0732, -0.0125],\n",
       "          ...,\n",
       "          [-0.1365,  0.2446, -0.0297,  ..., -0.2944,  0.6147, -0.0832],\n",
       "          [-0.0317, -0.3557, -0.5635,  ...,  0.0829,  0.2019,  1.0996],\n",
       "          [-0.2773,  0.7500, -0.0801,  ..., -0.0390, -0.3489, -1.4082]]]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.scaled_dot_product_attention(qs_half, ks_half, vs_half, is_causal=True, scale=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt240cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
