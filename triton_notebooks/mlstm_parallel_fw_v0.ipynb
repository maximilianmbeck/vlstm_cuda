{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/max/myrepos/vlstm_cuda/')\n",
    "\n",
    "import torch\n",
    "import triton\n",
    "import triton.language as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPUTarget(backend='cuda', arch=89, warp_size=32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton.runtime.driver.active.get_current_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src_triton.mlstm_parallel_fw_v0.mlstm import mlstm_fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 64 #32 #32 #16 #8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 64 # dim per head\n",
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(1) #TODO from here: with seed=0 even the pytorch version alone breaks for float16 and bfloat16\n",
    "# fixed:\n",
    "# qs = torch.arange((B*NH*S*DH), device=DEVICE, dtype=DTYPE).reshape((B, NH, S, DH)) / 10.\n",
    "# qs = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) / 100.\n",
    "# ks = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) / 100.\n",
    "# # vs = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) / 100.\n",
    "# vs = torch.arange((B*NH*S*DH), device=DEVICE, dtype=DTYPE).reshape((B, NH, S, DH)) / 100.\n",
    "# # vs = torch.zeros((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "# vs[:,:,1,0] = 7.\n",
    "# qs[:,:,1,0] = 1.\n",
    "\n",
    "# vs[:,:,1,16] = 8.\n",
    "# qs[:,:,1,16] = 1.\n",
    "# random: \n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "# igs = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1) / 10.\n",
    "# igs = torch.zeros((B, NH, S, 1), device=DEVICE, dtype=DTYPE) #/ 10.\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE) #/ 10.\n",
    "# fgs = torch.ones((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "dHs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs float16\n",
    "dtype_fp16 = torch.float16\n",
    "qs_half = qs.to(dtype=dtype_fp16)\n",
    "ks_half = ks.to(dtype=dtype_fp16)\n",
    "vs_half = vs.to(dtype=dtype_fp16)\n",
    "igs_half = igs.to(dtype=dtype_fp16)\n",
    "fgs_half = fgs.to(dtype=dtype_fp16)\n",
    "dHs_half = dHs.to(dtype=dtype_fp16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs bfloat16\n",
    "dtype_bf16 = torch.bfloat16\n",
    "qs_bf16 = qs.to(dtype=dtype_bf16)\n",
    "ks_bf16 = ks.to(dtype=dtype_bf16)\n",
    "vs_bf16 = vs.to(dtype=dtype_bf16)\n",
    "igs_bf16 = igs.to(dtype=dtype_bf16)\n",
    "fgs_bf16 = fgs.to(dtype=dtype_bf16)\n",
    "dHs_bf16 = dHs.to(dtype=dtype_bf16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triton grid: (1, 1, 1), BLOCK_Q: 64, BLOCK_KV: 32\n"
     ]
    }
   ],
   "source": [
    "hs_half, m_half, n_half = mlstm_fw(matQ=qs_half, matK=ks_half, matV=vs_half, vecI=igs_half, vecF=fgs_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.2964,  2.6758, -0.1409,  ..., -0.8525,  0.3560, -1.3682],\n",
       "           [-1.4365, -1.5195,  0.2291,  ...,  0.4343,  0.7642, -1.0527],\n",
       "           [-0.8398,  0.4783,  0.6865,  ..., -0.5474, -0.5615,  0.0093],\n",
       "           ...,\n",
       "           [ 0.2793,  1.0586, -0.6704,  ..., -0.3682,  0.5264,  0.2561],\n",
       "           [-1.5283,  0.8374,  0.0970,  ..., -0.6860,  0.3206,  0.7261],\n",
       "           [-1.3105,  1.0488, -0.1710,  ..., -0.2256,  0.2086, -0.1392]]]],\n",
       "        device='cuda:0', dtype=torch.float16),\n",
       " tensor([[[[-0.2964,  2.6758, -0.1409,  ..., -0.8525,  0.3560, -1.3682],\n",
       "           [-1.4365, -1.5195,  0.2291,  ...,  0.4343,  0.7642, -1.0527],\n",
       "           [-0.8398,  0.4783,  0.6865,  ..., -0.5474, -0.5615,  0.0093],\n",
       "           ...,\n",
       "           [ 0.2793,  1.0586, -0.6704,  ..., -0.3682,  0.5264,  0.2561],\n",
       "           [-1.5283,  0.8374,  0.0970,  ..., -0.6860,  0.3206,  0.7261],\n",
       "           [-1.3105,  1.0488, -0.1710,  ..., -0.2256,  0.2086, -0.1392]]]],\n",
       "        device='cuda:0', dtype=torch.float16))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_half, hs_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(hs_half, qs_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_half.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 4096, 64, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_half.stride(0), qs_half.stride(1), qs_half.stride(2), qs_half.stride(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(3 & 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt240cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
