{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "sys.path.append(\".\")\n",
    "# os.environ[\"MAX_JOBS\"] = \"100\"\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCLUDE: ['/home/max/miniconda3/envs/xlstm/lib/python3.11/site-packages/torch/include', '/home/max/miniconda3/envs/xlstm/lib/python3.11/site-packages/torch/include/torch/csrc/api/include', '/home/max/miniconda3/envs/xlstm/lib/python3.11/site-packages/torch/include/TH', '/home/max/miniconda3/envs/xlstm/lib/python3.11/site-packages/torch/include/THC', '/usr/local/cuda/include']\n",
      "/home/max/myrepos/vlstm_cuda/src\n",
      "/home/max/cpplibs/libtorch/lib:/usr/local/cuda-12.3/lib64:\n",
      "/usr/local/cuda/lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/max/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n"
     ]
    }
   ],
   "source": [
    "from src.mm_v0.interface import testkernel, copykernel, mmkernelv1, mmkernelv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = torch.bfloat16\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_A = torch.arange(4).reshape(2, 2).to(dtype=DTYPE, device=DEVICE)\n",
    "mat_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test kernel!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = testkernel(mat_A)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch - float16!\n",
      "rows: 2, cols: 2\n",
      "blocksxy: 1-1, threads: 32-32\n",
      "cidx: 0, ridx: 0, val: 0.000000\n",
      "cidx: 1, ridx: 0, val: 2.000000\n",
      "cidx: 0, ridx: 1, val: 1.000000\n",
      "cidx: 1, ridx: 1, val: 3.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = copykernel(mat_A.to(dtype=torch.float16))\n",
    "out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[64., 64., 64.,  ..., 64., 64., 64.],\n",
       "         [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "         [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "         ...,\n",
       "         [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "         [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "         [64., 64., 64.,  ..., 64., 64., 64.]], device='cuda:0',\n",
       "        dtype=torch.bfloat16),\n",
       " torch.Size([32, 32]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warp_size = 32\n",
    "am = torch.ones((1*1*warp_size, 1*1*warp_size), device=DEVICE, dtype=DTYPE)\n",
    "bm = 2 * torch.ones((1*1*warp_size, 1*1*warp_size), device=DEVICE, dtype=DTYPE)\n",
    "cm = am @ bm\n",
    "cm, cm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch - bfloat16!\n",
      "m: 32, n: 32, k: 32\n",
      "blocksxy: 8-8, threads: 4-4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[64., 64., 64.,  ..., 64., 64., 64.],\n",
       "        [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "        [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "        ...,\n",
       "        [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "        [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "        [64., 64., 64.,  ..., 64., 64., 64.]], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = torch.bfloat16\n",
    "am = am.to(dtype=dt)\n",
    "bm = bm.to(dtype=dt)\n",
    "mmkernelv1(mat_A=am, mat_B=bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 8 # sequence length\n",
    "DH = 3 # hidden size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 3]), torch.Size([3, 8]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matA = torch.ones((S, DH), device=DEVICE, dtype=DTYPE)\n",
    "matB = torch.ones((DH, S), device=DEVICE, dtype=DTYPE)\n",
    "matA.shape, matB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3., 3., 3., 3., 3.],\n",
       "         [3., 3., 3., 3., 3., 3., 3., 3.]], device='cuda:0',\n",
       "        dtype=torch.bfloat16),\n",
       " torch.Size([8, 8]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch\n",
    "pt_out = matA @ matB\n",
    "pt_out, pt_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matA.is_contiguous(), matB.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch - bfloat16!\n",
      "m: 8, n: 8, k: 3\n",
      "blocksxy: 2-2, threads: 4-4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.]], device='cuda:0',\n",
       "        dtype=torch.bfloat16),\n",
       " torch.Size([8, 8]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu_out = mmkernelv1(mat_A=matA, mat_B=matB)\n",
    "cu_out, cu_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch - bfloat16!\n",
      "m: 8, n: 8, k: 3\n",
      "blocksxy: 2-2, threads: 4-4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3., 67.,  3., 67.,  3., 67.,  3., 67.],\n",
       "         [ 3.,  3.,  3.,  3.,  3.,  3.,  3.,  3.]], device='cuda:0',\n",
       "        dtype=torch.bfloat16),\n",
       " torch.Size([8, 8]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu_out = mmkernelv2(mat_A=matA, mat_B=matB)\n",
    "cu_out, cu_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat @ mat.T @ mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 6 # hidden size\n",
    "S = 5 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 2 # num heads\n",
    "DH = H // NH # dim per head\n",
    "DTYPE = torch.bfloat16\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "assert H % NH == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(0)\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ds = torch.rand((B, NH, S, S), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "max_log_D, _ = torch.max(ds.view(B, NH, -1), dim=-1, keepdim=True)  # (B, NH, 1)\n",
    "log_D_matrix_stabilized = ds - max_log_D.unsqueeze(-1)  # (B, NH, S, S) = (B, NH, S, S) - (B, NH, 1, 1)\n",
    "D_matrix = torch.exp(log_D_matrix_stabilized)  # (B, NH, S, S)\n",
    "mval = torch.exp(-max_log_D.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt21cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
