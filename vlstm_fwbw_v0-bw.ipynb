{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "sys.path.append(\".\")\n",
    "# os.environ[\"MAX_JOBS\"] = \"100\"\n",
    "\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=200)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCLUDE: ['/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include', '/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include/torch/csrc/api/include', '/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include/TH', '/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include/THC', '/home/max/miniconda3/envs/xlstmpt220cu121/include']\n",
      "/home/max/myrepos/vlstm_cuda/src\n",
      "/home/max/cpplibs/libtorch/lib:/usr/local/cuda-12.3/lib64:\n",
      "/home/max/miniconda3/envs/xlstmpt220cu121/lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/max/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/max/.cache/torch_extensions/py311_cu121/vlstm_fwbw_v0/build.ninja...\n",
      "Building extension module vlstm_fwbw_v0...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] /home/max/miniconda3/envs/xlstmpt220cu121/bin/nvcc --generate-dependencies-with-compile --dependency-output kernel_bw.cuda.o.d -ccbin /home/max/miniconda3/envs/xlstmpt220cu121/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=vlstm_fwbw_v0 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include -isystem /home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include/TH -isystem /home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include/THC -isystem /home/max/miniconda3/envs/xlstmpt220cu121/include -isystem /home/max/miniconda3/envs/xlstmpt220cu121/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_89,code=compute_89 -gencode=arch=compute_89,code=sm_89 --compiler-options '-fPIC' -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DTmax=13407807929942597099574024998205846127479365820592393377723561443721764030073546976801874298166903427690031858186486050853753882811946569946433649006084096 -std=c++17 -c /home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/kernel_bw.cu -o kernel_bw.cuda.o \n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh(264): remark #20200-D: #pragma message: \"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh:264 CUDART_VERSION: 12010, arch: 890\"\n",
      "  #pragma message(\"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh\" \":\" \"264\" \" CUDART_VERSION: \" \"12010\" \", arch: \" \"890\")\n",
      "                                                                                                                                                 ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh(269): remark #20200-D: #pragma message: \"INCLUDING FP16\"\n",
      "  #pragma message(\"INCLUDING FP16\")\n",
      "                                   ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_fp16.cuh(29): remark #20200-D: #pragma message: \"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_fp16.cuh:29 CUDART_VERSION with FP16: 12010, CUDA_ARCH: 890\"\n",
      "  #pragma message(\"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_fp16.cuh\" \":\" \"29\" \" CUDART_VERSION with FP16: \" \"12010\" \", CUDA_ARCH: \" \"890\")\n",
      "                                                                                                                                                                    ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2fp16.cuh(29): remark #20200-D: #pragma message: \"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2fp16.cuh:29 CUDART_VERSION with FP16: 12010, CUDA_ARCH: 890\"\n",
      "  #pragma message(\"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2fp16.cuh\" \":\" \"29\" \" CUDART_VERSION with FP16: \" \"12010\" \", CUDA_ARCH: \" \"890\")\n",
      "                                                                                                                                                                     ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh(282): remark #20200-D: #pragma message: \"INCLUDING BF16\"\n",
      "  #pragma message(\"INCLUDING BF16\")\n",
      "                                   ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_bf16.cuh(29): remark #20200-D: #pragma message: \"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_bf16.cuh:29 CUDART_VERSION with BF16: 12010, CUDA_ARCH: 890\"\n",
      "  #pragma message(\"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_bf16.cuh\" \":\" \"29\" \" CUDART_VERSION with BF16: \" \"12010\" \", CUDA_ARCH: \" \"890\")\n",
      "                                                                                                                                                                    ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2bf16.cuh(29): remark #20200-D: #pragma message: \"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2bf16.cuh:29 CUDART_VERSION with FP16: 12010, CUDA_ARCH: 890\"\n",
      "  #pragma message(\"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2bf16.cuh\" \":\" \"29\" \" CUDART_VERSION with FP16: \" \"12010\" \", CUDA_ARCH: \" \"890\")\n",
      "                                                                                                                                                                     ^\n",
      "\n",
      "ptxas info    : 150 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN5vlstm7kernels8vlstm_bwIfLi4ELi8ELi8EEEvPT_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_PfS4_iiii' for 'sm_89'\n",
      "ptxas info    : Function properties for _ZN5vlstm7kernels8vlstm_bwIfLi4ELi8ELi8EEEvPT_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_S3_PfS4_iiii\n",
      "    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 96 registers, 496 bytes cmem[0], 16 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function '_ZN5vlstm7kernels8vlstm_bwI6__halfLi4ELi8ELi8EEEvPT_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_PfS5_iiii' for 'sm_89'\n",
      "ptxas info    : Function properties for _ZN5vlstm7kernels8vlstm_bwI6__halfLi4ELi8ELi8EEEvPT_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_PfS5_iiii\n",
      "    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 96 registers, 496 bytes cmem[0], 8 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function '_ZN5vlstm7kernels8vlstm_bwI13__nv_bfloat16Li4ELi8ELi8EEEvPT_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_PfS5_iiii' for 'sm_89'\n",
      "ptxas info    : Function properties for _ZN5vlstm7kernels8vlstm_bwI13__nv_bfloat16Li4ELi8ELi8EEEvPT_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_S4_PfS5_iiii\n",
      "    24 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 108 registers, 496 bytes cmem[0], 8 bytes cmem[2]\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh(264): remark #20200-D: #pragma message: \"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh:264 CUDART_VERSION: 12010, arch: 800\"\n",
      "  #pragma message(\"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh\" \":\" \"264\" \" CUDART_VERSION: \" \"12010\" \", arch: \" \"800\")\n",
      "                                                                                                                                                 ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh(269): remark #20200-D: #pragma message: \"INCLUDING FP16\"\n",
      "  #pragma message(\"INCLUDING FP16\")\n",
      "                                   ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_fp16.cuh(29): remark #20200-D: #pragma message: \"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_fp16.cuh:29 CUDART_VERSION with FP16: 12010, CUDA_ARCH: 800\"\n",
      "  #pragma message(\"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_fp16.cuh\" \":\" \"29\" \" CUDART_VERSION with FP16: \" \"12010\" \", CUDA_ARCH: \" \"800\")\n",
      "                                                                                                                                                                    ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2fp16.cuh(29): remark #20200-D: #pragma message: \"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2fp16.cuh:29 CUDART_VERSION with FP16: 12010, CUDA_ARCH: 800\"\n",
      "  #pragma message(\"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2fp16.cuh\" \":\" \"29\" \" CUDART_VERSION with FP16: \" \"12010\" \", CUDA_ARCH: \" \"800\")\n",
      "                                                                                                                                                                     ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh(282): remark #20200-D: #pragma message: \"INCLUDING BF16\"\n",
      "  #pragma message(\"INCLUDING BF16\")\n",
      "                                   ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_bf16.cuh(29): remark #20200-D: #pragma message: \"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_bf16.cuh:29 CUDART_VERSION with BF16: 12010, CUDA_ARCH: 800\"\n",
      "  #pragma message(\"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_bf16.cuh\" \":\" \"29\" \" CUDART_VERSION with BF16: \" \"12010\" \", CUDA_ARCH: \" \"800\")\n",
      "                                                                                                                                                                    ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2bf16.cuh(29): remark #20200-D: #pragma message: \"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2bf16.cuh:29 CUDART_VERSION with FP16: 12010, CUDA_ARCH: 800\"\n",
      "  #pragma message(\"/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops_2bf16.cuh\" \":\" \"29\" \" CUDART_VERSION with FP16: \" \"12010\" \", CUDA_ARCH: \" \"800\")\n",
      "                                                                                                                                                                     ^\n",
      "\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh:264:138: note: '#pragma message: /home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh:264 CUDART_VERSION: 12010, arch: __CUDA_ARCH__'\n",
      "  264 | #pragma message(AT \" CUDART_VERSION: \" TOSTRING(                               \\\n",
      "      |                                                                                                                                          ^\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh:276:90: note: '#pragma message: SKIPPING FP16, because of CUDART_VERSION: 12010, arch: __CUDA_ARCH__'\n",
      "  276 | #pragma message(\"SKIPPING FP16, because of CUDART_VERSION: \" TOSTRING(         \\\n",
      "      |                                                                                          ^\n",
      "/home/max/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/../util/inline_ops.cuh:289:90: note: '#pragma message: SKIPPING BF16, because of CUDART_VERSION: 12010, arch: __CUDA_ARCH__'\n",
      "  289 | #pragma message(\"SKIPPING BF16, because of CUDART_VERSION: \" TOSTRING(         \\\n",
      "      |                                                                                          ^\n",
      "[2/2] /home/max/miniconda3/envs/xlstmpt220cu121/bin/x86_64-conda-linux-gnu-c++ interface.o kernel_fw.cuda.o kernel_bw.cuda.o -shared -L/home/max/miniconda3/envs/xlstmpt220cu121/lib -lcublas -L/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/home/max/miniconda3/envs/xlstmpt220cu121/lib -lcudart -o vlstm_fwbw_v0.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module vlstm_fwbw_v0...\n"
     ]
    }
   ],
   "source": [
    "from src.vlstm_fwbw_v0.interface import vlstm_fwbw_torch_obw, vlstm_fwbw_cuda\n",
    "\n",
    "from src.vlstm_fwbw_v0.interface import vlstm_fw_torch, vlstm_fw_cuda\n",
    "from src.vlstm_fwbw_v0.interface import vlstm_bw_torch_obw, vlstm_bw_cuda\n",
    "from src.vlstm_fwbw_v0.torch_impl import vlstm_fw_tiled_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA vLSTM backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "S = 64 #16 #8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 8 # dim per head\n",
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-9.2466e-01, -4.2534e-01, -2.6438e+00,  1.4518e-01, -1.2087e-01, -5.7973e-01, -6.2285e-01, -3.2839e-01],\n",
       "           [-1.0745e+00, -3.6314e-01, -1.6711e+00,  2.2655e+00,  3.1168e-01, -1.8419e-01,  1.2866e+00,  1.1820e+00],\n",
       "           [-1.2706e-01,  1.2169e+00,  1.4353e+00,  1.0605e+00, -4.9413e-01, -1.4244e+00, -7.2443e-01, -1.2973e+00],\n",
       "           [ 6.9690e-02, -7.4066e-03,  1.8969e+00,  6.8778e-01, -7.7948e-02, -8.3728e-01,  1.3506e+00, -2.8792e-01],\n",
       "           [-5.9653e-01, -3.2826e-01, -9.0860e-01, -8.0594e-01, -7.4067e-01, -5.0385e-02,  5.4348e-01,  1.5150e+00],\n",
       "           [ 1.4121e-02,  4.5320e-01,  1.6349e+00,  7.1239e-01, -1.8057e-01,  1.0252e+00, -1.4622e+00, -7.5538e-01],\n",
       "           [-1.8364e-01,  3.8239e-01,  3.9177e-01, -8.2991e-02,  8.9712e-01, -1.1123e+00,  1.1165e-01,  4.8628e-01],\n",
       "           [-5.4994e-01, -3.2309e-01, -5.4689e-01,  9.0488e-01,  2.8369e-01,  1.2103e-01,  4.7297e-01, -1.0823e+00],\n",
       "           [-3.3446e-02, -9.7344e-01,  9.5592e-01, -1.1795e+00, -1.0064e+00,  1.1599e-01,  6.8517e-01, -4.1239e-01],\n",
       "           [-6.7381e-01, -5.4044e-01,  6.8985e-01, -1.5517e+00,  3.8053e-01, -4.3581e-02,  3.5974e-01, -5.0426e-01],\n",
       "           [-3.1052e-01,  7.6436e-01, -3.1298e+00,  3.4941e-01, -2.7612e-02,  1.4448e+00, -2.7707e-03,  1.8990e-01],\n",
       "           [ 2.2415e-01, -2.3280e-01,  9.7137e-01,  1.6773e+00,  1.3447e-01,  5.2461e-01,  1.1699e+00, -9.5568e-01],\n",
       "           [-8.5698e-02, -1.4977e+00, -9.0736e-01, -4.5244e-01,  6.6173e-02, -3.8381e-02,  5.8397e-01,  8.8454e-01],\n",
       "           [-1.6148e+00,  4.4849e-01,  7.3407e-01, -8.4570e-01,  6.5872e-01, -3.5541e-01, -1.9107e+00, -1.6850e-01],\n",
       "           [ 1.8969e+00,  5.1329e-01,  1.1002e+00, -1.3909e+00, -2.6249e-01, -1.4429e+00,  1.5446e+00,  1.2185e-02],\n",
       "           [ 2.1437e+00, -9.2642e-01,  1.6909e+00, -2.5508e-01, -9.0211e-01, -2.1282e-01, -3.3148e-01, -2.0226e-01],\n",
       "           [-1.1451e+00, -5.7146e-01, -6.5101e-01,  2.0775e+00, -1.4032e+00,  1.2803e+00, -2.1226e+00, -9.0260e-01],\n",
       "           [ 2.6687e-01, -7.7345e-01, -1.9546e-01, -3.5504e-01,  3.4003e-01, -1.4072e-01,  3.5133e-01, -9.8068e-01],\n",
       "           [-3.9272e-01,  5.6149e-01,  5.0778e-02,  1.5877e+00, -4.0395e-01, -2.2449e-01, -1.7560e-01,  1.5172e-01],\n",
       "           [ 6.1342e-02, -1.3979e+00, -3.4039e-02, -2.4075e-01,  1.0469e+00,  1.2855e+00,  7.5718e-01, -8.3131e-01],\n",
       "           [ 4.0113e-01, -4.8134e-01, -9.8528e-01,  9.3812e-01,  3.6736e-01, -4.6754e-01, -1.5733e+00,  1.0383e+00],\n",
       "           [-5.7326e-01,  2.7507e-01, -2.7541e-01,  1.5937e-01, -2.2566e+00,  5.3861e-01, -1.2314e+00,  1.5438e+00],\n",
       "           [ 1.0489e-01, -4.6263e-01,  4.6437e-01,  1.5002e-01, -1.3809e+00,  1.8847e+00, -1.1002e+00,  2.7608e-01],\n",
       "           [-6.8500e-01,  6.5925e-01, -8.1778e-01, -9.3332e-02,  1.9178e-01,  2.1443e-01, -7.3694e-01, -4.5156e-01],\n",
       "           [-1.3546e-01, -1.3171e+00, -8.7381e-01, -4.0840e-01,  3.7063e-01,  2.3022e-01, -1.3475e+00, -5.0064e-01],\n",
       "           [-4.1215e-01, -1.5055e+00, -1.1229e+00, -2.4949e-01, -6.9668e-01, -2.1947e+00, -4.4546e-01,  5.7513e-02],\n",
       "           [ 2.7088e-01,  1.2292e+00, -1.4770e-02,  3.9272e-01, -1.2490e+00,  1.6065e+00,  5.3124e-01, -1.3232e+00],\n",
       "           [-1.7174e+00,  9.5140e-01, -2.2542e-01, -5.6928e-01,  2.9864e-01, -4.6660e-01,  2.3300e+00,  5.5654e-01],\n",
       "           [ 9.0903e-01,  2.9210e-01, -2.2849e+00,  4.2133e-01,  1.1173e+00,  5.9529e-01,  3.0829e-01,  1.2683e+00],\n",
       "           [ 1.0294e-01, -1.9810e+00,  5.8922e-01,  1.5494e-01,  8.0646e-01,  2.4884e-01, -6.8482e-01, -1.1831e-02],\n",
       "           [-2.3765e+00,  3.3196e-01,  3.3498e-01, -7.6068e-02,  2.2586e-01, -2.4527e+00,  7.3919e-02, -1.9685e+00],\n",
       "           [ 1.1612e+00, -5.3360e-01,  1.3228e+00, -1.7094e+00, -1.1085e+00,  1.3417e+00,  3.3156e+00, -8.4666e-01],\n",
       "           [ 2.3737e-01,  1.0884e+00, -2.4973e-01, -4.9736e-01, -1.1520e+00,  1.4054e+00,  9.1116e-01, -6.0021e-02],\n",
       "           [ 4.0261e-01, -4.6268e-01,  9.3103e-02,  1.0969e+00,  6.7773e-01, -1.9075e-01, -4.7532e-01, -1.7916e+00],\n",
       "           [ 7.3020e-02, -9.7017e-01, -1.5168e-01,  6.4805e-01,  4.0209e-01, -4.5726e-01,  9.1431e-01, -8.0725e-01],\n",
       "           [-3.4651e-02, -1.3154e+00, -6.0735e-01,  1.1249e+00, -7.0437e-01,  1.0772e+00, -6.9448e-01, -1.3563e-01],\n",
       "           [ 6.6971e-01, -6.6631e-01,  1.9095e-01, -1.7596e+00, -5.8540e-01, -6.9613e-01, -1.2390e-01, -6.4585e-01],\n",
       "           [-2.0933e-01,  1.7208e+00,  5.8334e-01, -6.4887e-02,  2.0613e+00, -2.4906e-01, -1.8009e+00, -4.2197e-01],\n",
       "           [-1.1432e+00,  1.2004e+00,  3.4864e-01, -6.8779e-01, -4.3595e-01, -1.0111e+00, -9.2217e-01,  5.7839e-01],\n",
       "           [ 1.2755e+00, -1.8468e+00,  9.6650e-01, -7.2612e-01,  4.2602e-02,  1.9088e+00, -8.1902e-01, -6.7605e-01],\n",
       "           [ 1.4237e+00,  9.2431e-01,  2.1202e-01,  5.9384e-01, -1.5283e-01, -4.1272e-01,  6.0107e-01,  2.0994e+00],\n",
       "           [ 8.8653e-01, -2.3197e-01,  7.4427e-01, -2.7161e-01, -8.9864e-01,  8.8195e-01, -8.0994e-01,  8.7735e-01],\n",
       "           [-1.7651e+00,  6.5314e-01, -6.4112e-02,  6.9343e-01, -1.3255e+00, -4.1441e-01,  6.1583e-01, -3.7169e-01],\n",
       "           [-5.3075e-01,  1.1778e+00, -8.7160e-01, -5.0408e-01,  1.9058e+00,  2.5888e-01, -3.0698e-01, -5.8252e-01],\n",
       "           [-3.0520e-01,  2.3543e-02, -1.0384e+00, -4.5758e-01,  1.3978e+00, -5.1973e-01,  7.4748e-01, -5.4662e-01],\n",
       "           [-8.9798e-02,  1.1101e-02, -3.3736e-01,  3.0677e-01,  3.6878e-01, -2.0521e+00,  8.9447e-01, -4.2086e-01],\n",
       "           [-4.1074e-01,  5.1639e-01, -2.7058e-01,  4.7389e-01, -9.0341e-01,  2.9722e-01, -1.2429e+00, -4.5588e-01],\n",
       "           [-2.6139e-01, -1.1982e+00, -1.5334e+00, -2.7293e-01, -1.0230e+00,  2.4305e-01,  1.7026e-01, -2.1111e-01],\n",
       "           [-1.2461e-01,  1.3310e-01, -8.1351e-01, -7.6410e-01, -4.1469e-01, -3.7722e-01, -9.9624e-01,  7.1201e-01],\n",
       "           [-3.3039e-01,  6.1221e-01, -3.5287e-01,  2.9989e-01,  1.2806e-01,  6.1679e-01, -1.2361e+00, -3.2533e-01],\n",
       "           [ 1.1327e+00,  3.6030e-01,  3.6529e-01, -4.1258e-01,  5.2491e-01,  2.1800e-01, -2.8640e-01, -1.1629e+00],\n",
       "           [ 2.9067e-01,  7.0668e-01, -2.7574e-01,  3.4423e-02, -6.7777e-02, -4.9841e-01,  5.9371e-01, -1.1901e-01],\n",
       "           [-1.4427e-01, -6.7390e-01,  7.4368e-02,  2.2662e-01,  2.7515e-01, -6.7154e-02, -1.0753e+00,  1.8201e+00],\n",
       "           [ 9.4384e-01, -1.8705e+00, -4.3770e-01,  1.4464e-01, -2.3492e+00, -2.5396e-01,  3.3259e-01, -4.3111e-01],\n",
       "           [-6.1056e-01, -1.5461e+00,  1.0681e+00,  1.9983e+00, -3.2179e-01, -1.0682e+00, -7.2873e-01, -1.0579e+00],\n",
       "           [ 2.2124e+00,  1.3819e+00,  9.7209e-01, -9.1230e-01,  3.6113e-01, -5.2619e-01,  7.0983e-01, -3.8259e-02],\n",
       "           [ 1.6536e+00, -1.0162e+00,  7.9535e-01,  1.0513e+00,  3.4926e-01, -5.8930e-01,  1.3733e+00, -7.7249e-01],\n",
       "           [-7.2774e-02, -8.0433e-01, -1.0326e+00,  1.7001e+00,  1.0919e+00,  2.0900e-01,  6.3536e-01, -8.0362e-01],\n",
       "           [-1.3479e-01, -1.2558e+00, -1.9218e-03,  1.3597e-01,  6.8941e-01,  4.3329e-01,  6.1648e-02,  1.4794e+00],\n",
       "           [ 7.3811e-01, -1.5368e+00,  1.6518e+00, -3.2050e-01,  4.7511e-01, -1.3123e+00,  7.1520e-01,  1.0198e+00],\n",
       "           [ 2.9293e-01,  2.9328e-01, -4.7074e-01, -1.8247e+00,  6.5760e-02,  5.0131e-01, -1.3679e+00,  3.5025e-01],\n",
       "           [-9.5196e-01, -6.2318e-01,  5.9263e-01, -2.5676e-02, -1.4770e+00, -7.3015e-01,  1.0717e-01, -4.4032e-01],\n",
       "           [ 8.1423e-03, -3.9180e-01, -1.3857e+00, -7.2642e-01, -1.4890e+00,  9.5093e-03, -6.5785e-01,  7.6095e-01],\n",
       "           [ 3.4210e-01,  7.9231e-01,  1.5966e+00, -3.4822e-01,  1.6972e-01, -3.1882e-01,  1.4025e+00,  6.5594e-01]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 64, 8]),\n",
       " 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(0)\n",
    "# fixed:\n",
    "# qs = torch.arange((B*NH*S*DH), device=DEVICE, dtype=DTYPE).reshape((B, NH, S, DH)) / 10.\n",
    "# ks = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) / 100.\n",
    "# vs = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) / 100.\n",
    "# random:\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# igs = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1) / 10.\n",
    "# igs = torch.zeros((B, NH, S, 1), device=DEVICE, dtype=DTYPE) #/ 10.\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE) #/ 10.\n",
    "fgs = torch.ones((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "dHs = qs.clone()\n",
    "qs, qs.shape, len(qs.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bw kernel match direct call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_pt, n_pt, m_pt, _, matD_pt = vlstm_fw_torch(queries=qs, keys=ks, values=vs, igate_preact=igs, fgate_preact=fgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dQs_pt, dKs_pt, dVs_pt, dIgs_pt, dFgs_pt, delta_D_pt, delta_Dtilde_pt, delta_fbar_pt, mat_P_pt, mat_C_pt = vlstm_bw_torch_obw(\n",
    "    delta_Htilde=dHs,\n",
    "    queries=qs,\n",
    "    keys=ks,\n",
    "    values=vs,\n",
    "    igate_preact=igs,\n",
    "    fgate_preact=fgs,\n",
    "    var_n=n_pt,\n",
    "    var_m=m_pt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_cumsum(x, dim=-1):\n",
    "    return x.flip(dims=(dim,)).cumsum(dim).flip(dims=(dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate fgrads trick\n",
    "df = (dQs_pt * qs - dKs_pt * ks).sum(-1, keepdim=True)\n",
    "df = rev_cumsum(df, dim=-2)\n",
    "df_pt = df * torch.nn.functional.sigmoid(-fgs)\n",
    "# df_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pt - dFgs_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch - float32!\n",
      "B: 1, NH: 1, S: 64, DH: 8\n",
      "blocksxy: 1-2, threadsxy: 4-4, shared_mem in bytes: 5664\n",
      "In FW-Kernel: gdim.x: 1, gdim.y: 2, gdim.z: 1, bdim.x: 4, bdim.y: 4\n",
      "In FW-Kernel: QtileDim: 8, KVtileDim: 8, TblockDim:4\n"
     ]
    }
   ],
   "source": [
    "hs_cu, n_cu, m_cu, _ = vlstm_fw_cuda(mat_Q=qs, mat_K=ks, mat_V=vs, igate_preact=igs, fgate_preact=fgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch - float32!\n",
      "B: 1, NH: 1, S: 64, DH: 8\n",
      "blocksxy: 1-2, threadsxy: 4-4, shared_mem in bytes: 7648\n",
      "In BW-Kernel: gdim.x: 1, gdim.y: 2, gdim.z: 1, bdim.x: 4, bdim.y: 4\n",
      "In BW-Kernel: QtileDim: 8, KVtileDim: 8, TblockDim:4\n"
     ]
    }
   ],
   "source": [
    "dQs_cu, dKs_cu, dVs_cu, dIgs_cu, dFgs_cu, matC_cu, deltaDcsChunkArr_cu, deltaDcsVec_cu = vlstm_bw_cuda(\n",
    "    delta_Htilde=dHs,\n",
    "    mat_Q=qs,\n",
    "    mat_K=ks,\n",
    "    mat_V=vs,\n",
    "    igate_preact=igs,\n",
    "    fgate_preact=fgs,\n",
    "    n=n_pt,\n",
    "    m=m_pt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta Q match: True\n",
      "delta K match: True\n",
      "delta V match: True\n",
      "delta Igate match: True\n",
      "delta Fgate match: True\n"
     ]
    }
   ],
   "source": [
    "RTOL = 1e-10\n",
    "ATOL = 4e-4\n",
    "print(f\"delta Q match: {torch.allclose(dQs_cu, dQs_pt, rtol=RTOL, atol=ATOL)}\")\n",
    "print(f\"delta K match: {torch.allclose(dKs_cu, dKs_pt, rtol=RTOL, atol=ATOL)}\")\n",
    "print(f\"delta V match: {torch.allclose(dVs_cu, dVs_pt, rtol=RTOL, atol=ATOL)}\")\n",
    "print(f\"delta Igate match: {torch.allclose(dIgs_cu, dIgs_pt, rtol=RTOL, atol=ATOL)}\")\n",
    "print(f\"delta Fgate match: {torch.allclose(dFgs_cu, dFgs_pt, rtol=RTOL, atol=ATOL)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 64, 1]),\n",
       " torch.Size([1, 1, 64, 1]),\n",
       " torch.Size([1, 1, 64, 1]),\n",
       " torch.Size([1, 1, 64, 1]),\n",
       " torch.Size([1, 1, 64, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs.shape, dFgs_cu.shape, dFgs_pt.shape, dIgs_cu.shape, dIgs_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00],\n",
       "          [-1.2414e-01],\n",
       "          [ 2.6844e-03],\n",
       "          [-2.3010e-01],\n",
       "          [ 1.8230e-01],\n",
       "          [ 2.2131e-02],\n",
       "          [ 1.2863e+00],\n",
       "          [ 2.7503e-01],\n",
       "          [ 1.9151e+00],\n",
       "          [-6.6840e-02],\n",
       "          [ 6.3091e-01],\n",
       "          [ 3.9952e-01],\n",
       "          [ 8.5827e-01],\n",
       "          [ 6.9611e-01],\n",
       "          [ 2.1424e-01],\n",
       "          [ 3.7011e-02],\n",
       "          [-2.7183e-01],\n",
       "          [-5.0328e-01],\n",
       "          [ 1.7285e-01],\n",
       "          [-2.6171e-01],\n",
       "          [ 5.2955e-02],\n",
       "          [ 5.7039e-01],\n",
       "          [-9.6497e-02],\n",
       "          [-2.0098e+00],\n",
       "          [ 6.4235e-02],\n",
       "          [ 2.5044e-02],\n",
       "          [-4.9683e-01],\n",
       "          [-6.2860e-02],\n",
       "          [ 1.5297e-01],\n",
       "          [ 2.7864e+00],\n",
       "          [ 3.4535e-01],\n",
       "          [-4.0065e-01],\n",
       "          [ 3.7816e-01],\n",
       "          [ 1.0902e+00],\n",
       "          [ 2.7775e-01],\n",
       "          [-4.1950e+00],\n",
       "          [-1.2819e+00],\n",
       "          [-8.7695e-01],\n",
       "          [-3.7726e-01],\n",
       "          [ 1.8658e+00],\n",
       "          [ 1.1813e-01],\n",
       "          [ 1.7859e-01],\n",
       "          [-3.2024e-01],\n",
       "          [-7.8389e-02],\n",
       "          [ 3.8559e-02],\n",
       "          [ 9.3978e-02],\n",
       "          [ 1.1797e-01],\n",
       "          [ 7.7298e-03],\n",
       "          [-6.6006e-02],\n",
       "          [-1.2588e-01],\n",
       "          [-2.3414e-01],\n",
       "          [-6.2511e-02],\n",
       "          [ 3.3971e-01],\n",
       "          [-3.5429e+00],\n",
       "          [-3.9540e+00],\n",
       "          [ 2.5251e+00],\n",
       "          [ 7.4248e-01],\n",
       "          [ 3.8230e-01],\n",
       "          [-1.5744e-01],\n",
       "          [ 1.9187e-02],\n",
       "          [-2.7203e+00],\n",
       "          [-1.5122e+00],\n",
       "          [-3.4274e-01],\n",
       "          [-1.2959e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dFgs_cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00],\n",
       "          [-1.2414e-01],\n",
       "          [ 2.6844e-03],\n",
       "          [-2.3010e-01],\n",
       "          [ 1.8230e-01],\n",
       "          [ 2.2131e-02],\n",
       "          [ 1.2863e+00],\n",
       "          [ 2.7503e-01],\n",
       "          [ 1.9151e+00],\n",
       "          [-6.6840e-02],\n",
       "          [ 6.3091e-01],\n",
       "          [ 3.9952e-01],\n",
       "          [ 8.5826e-01],\n",
       "          [ 6.9611e-01],\n",
       "          [ 2.1424e-01],\n",
       "          [ 3.7011e-02],\n",
       "          [-2.7183e-01],\n",
       "          [-5.0328e-01],\n",
       "          [ 1.7285e-01],\n",
       "          [-2.6171e-01],\n",
       "          [ 5.2954e-02],\n",
       "          [ 5.7039e-01],\n",
       "          [-9.6497e-02],\n",
       "          [-2.0098e+00],\n",
       "          [ 6.4235e-02],\n",
       "          [ 2.5044e-02],\n",
       "          [-4.9683e-01],\n",
       "          [-6.2860e-02],\n",
       "          [ 1.5297e-01],\n",
       "          [ 2.7864e+00],\n",
       "          [ 3.4535e-01],\n",
       "          [-4.0065e-01],\n",
       "          [ 3.7816e-01],\n",
       "          [ 1.0902e+00],\n",
       "          [ 2.7775e-01],\n",
       "          [-4.1950e+00],\n",
       "          [-1.2819e+00],\n",
       "          [-8.7695e-01],\n",
       "          [-3.7726e-01],\n",
       "          [ 1.8658e+00],\n",
       "          [ 1.1813e-01],\n",
       "          [ 1.7859e-01],\n",
       "          [-3.2024e-01],\n",
       "          [-7.8390e-02],\n",
       "          [ 3.8559e-02],\n",
       "          [ 9.3977e-02],\n",
       "          [ 1.1797e-01],\n",
       "          [ 7.7298e-03],\n",
       "          [-6.6005e-02],\n",
       "          [-1.2588e-01],\n",
       "          [-2.3414e-01],\n",
       "          [-6.2511e-02],\n",
       "          [ 3.3971e-01],\n",
       "          [-3.5429e+00],\n",
       "          [-3.9540e+00],\n",
       "          [ 2.5251e+00],\n",
       "          [ 7.4248e-01],\n",
       "          [ 3.8230e-01],\n",
       "          [-1.5744e-01],\n",
       "          [ 1.9187e-02],\n",
       "          [-2.7203e+00],\n",
       "          [-1.5123e+00],\n",
       "          [-3.4274e-01],\n",
       "          [-1.2959e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dFgs_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.9758, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(matC_cu - mat_P_pt).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 7.7486e-07],\n",
       "          [-1.7881e-07],\n",
       "          [-2.9802e-07],\n",
       "          [ 7.7486e-07],\n",
       "          [-6.5565e-07],\n",
       "          [ 2.3842e-06],\n",
       "          [ 1.7881e-06],\n",
       "          [ 1.9073e-06],\n",
       "          [ 3.5763e-07],\n",
       "          [ 1.1921e-06],\n",
       "          [ 2.9802e-07],\n",
       "          [ 2.1458e-06],\n",
       "          [-2.9802e-07],\n",
       "          [-1.1921e-06],\n",
       "          [-3.8147e-06],\n",
       "          [ 2.1458e-06],\n",
       "          [-4.2915e-06],\n",
       "          [ 6.1989e-06],\n",
       "          [-8.9407e-07],\n",
       "          [ 7.7486e-07],\n",
       "          [ 4.5300e-06],\n",
       "          [ 1.1921e-06],\n",
       "          [-2.8610e-06],\n",
       "          [ 3.5763e-07],\n",
       "          [ 2.6077e-08],\n",
       "          [ 1.3113e-06],\n",
       "          [ 5.2154e-08],\n",
       "          [ 5.9605e-07],\n",
       "          [ 7.6294e-06],\n",
       "          [-4.5300e-06],\n",
       "          [ 1.4305e-06],\n",
       "          [-1.6689e-06],\n",
       "          [ 1.1623e-06],\n",
       "          [ 4.4703e-07],\n",
       "          [-3.8147e-06],\n",
       "          [ 8.9407e-08],\n",
       "          [ 2.6226e-06],\n",
       "          [ 1.1921e-07],\n",
       "          [ 6.6757e-06],\n",
       "          [-2.7940e-08],\n",
       "          [-7.7486e-07],\n",
       "          [-9.5367e-07],\n",
       "          [ 1.6112e-07],\n",
       "          [-2.9802e-08],\n",
       "          [ 1.0729e-06],\n",
       "          [ 1.1921e-06],\n",
       "          [ 0.0000e+00],\n",
       "          [-1.7881e-07],\n",
       "          [ 1.3709e-06],\n",
       "          [ 2.3842e-06],\n",
       "          [ 1.0133e-06],\n",
       "          [ 2.0266e-06],\n",
       "          [-3.1471e-05],\n",
       "          [-5.5879e-08],\n",
       "          [-7.0333e-06],\n",
       "          [-7.1526e-07],\n",
       "          [ 9.6858e-08],\n",
       "          [ 3.5763e-07],\n",
       "          [ 9.5367e-07],\n",
       "          [ 2.6703e-05],\n",
       "          [-6.2585e-07],\n",
       "          [-3.2783e-07],\n",
       "          [ 5.2154e-08],\n",
       "          [ 6.1989e-06]]]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dIgs_cu - dIgs_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00],\n",
       "          [ 1.7136e-07],\n",
       "          [ 9.2434e-08],\n",
       "          [ 2.5332e-07],\n",
       "          [-1.6391e-07],\n",
       "          [-6.8918e-08],\n",
       "          [-1.4305e-06],\n",
       "          [-1.7881e-07],\n",
       "          [-1.6689e-06],\n",
       "          [-1.9372e-07],\n",
       "          [-7.1526e-07],\n",
       "          [-9.2387e-07],\n",
       "          [-6.5565e-07],\n",
       "          [-1.7881e-07],\n",
       "          [ 5.9605e-08],\n",
       "          [ 6.7055e-08],\n",
       "          [-5.9605e-07],\n",
       "          [ 4.1723e-07],\n",
       "          [-1.2815e-06],\n",
       "          [-2.6822e-07],\n",
       "          [-1.9744e-07],\n",
       "          [-9.5367e-07],\n",
       "          [ 1.5646e-07],\n",
       "          [ 2.1458e-06],\n",
       "          [ 6.7055e-08],\n",
       "          [ 1.0617e-07],\n",
       "          [ 2.3842e-07],\n",
       "          [-1.2666e-07],\n",
       "          [-2.9802e-07],\n",
       "          [-4.5300e-06],\n",
       "          [ 1.1027e-06],\n",
       "          [-2.3842e-07],\n",
       "          [-4.1723e-07],\n",
       "          [-9.5367e-07],\n",
       "          [-6.8545e-07],\n",
       "          [ 4.7684e-06],\n",
       "          [ 2.8610e-06],\n",
       "          [ 1.9670e-06],\n",
       "          [ 9.2387e-07],\n",
       "          [-1.5497e-06],\n",
       "          [ 1.6391e-07],\n",
       "          [-1.1921e-07],\n",
       "          [ 2.9802e-08],\n",
       "          [-2.6077e-07],\n",
       "          [-1.7509e-07],\n",
       "          [-2.5332e-07],\n",
       "          [-4.9174e-07],\n",
       "          [ 1.5832e-08],\n",
       "          [ 2.3842e-07],\n",
       "          [ 8.9407e-08],\n",
       "          [ 1.4901e-08],\n",
       "          [-8.1956e-08],\n",
       "          [-7.1526e-07],\n",
       "          [ 8.3447e-06],\n",
       "          [ 1.0729e-05],\n",
       "          [-7.1526e-07],\n",
       "          [ 1.0133e-06],\n",
       "          [ 5.3644e-07],\n",
       "          [-2.0862e-07],\n",
       "          [-8.3819e-08],\n",
       "          [-1.7643e-05],\n",
       "          [-8.1062e-06],\n",
       "          [-2.2650e-06],\n",
       "          [-8.4639e-06]]]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dFgs_pt - dFgs_cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 3.5763e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.1095e-07, -3.5763e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.9802e-06, -3.0994e-06, -3.0994e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.8626e-09,  2.3842e-07,  2.6822e-07,  2.5332e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.6880e-09, -5.1223e-09, -1.6298e-09, -1.1176e-08,  2.7940e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.7940e-08,  2.4214e-08,  2.9802e-08,  3.5390e-08,  5.0291e-08,  1.1921e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.7008e-08,  2.6077e-08,  2.7940e-08,  3.0734e-08,  3.1665e-08,  7.8678e-06,  7.9870e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-1.1642e-08, -1.1176e-08, -1.2107e-08, -1.4435e-08, -2.3647e-09,  5.4836e-06,  5.7220e-06,  5.8413e-06,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.5611e-08, -2.5611e-08, -2.6077e-08, -2.5611e-08, -4.1327e-09,  1.6689e-05,  1.6928e-05,  1.6928e-05,  1.6928e-05,  0.0000e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(matC_cu - delta_Dtilde_pt.cumsum(-1).tril(-1))[:, :, :, -10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-6.7055e-08,  2.0862e-07, -3.2783e-07,  2.9802e-07, -5.9605e-07, -3.2783e-07, -4.4703e-08,  3.5763e-07],\n",
       "           [ 8.3819e-09, -7.4506e-08,  1.1921e-07, -8.9407e-08,  1.4901e-07,  8.9407e-08,  2.2352e-08, -1.0431e-07],\n",
       "           [ 7.4506e-09,  2.9802e-08, -1.7881e-07,  7.4506e-08, -3.5763e-07, -2.0862e-07, -8.9407e-08,  2.3842e-07],\n",
       "           [ 4.4703e-08, -2.3842e-07,  1.6391e-07, -2.3842e-07,  7.4506e-08,  1.3411e-07,  1.1921e-07,  1.2107e-08],\n",
       "           [-2.2352e-08, -7.0781e-08, -4.7684e-07, -8.9407e-08,  2.6822e-07,  1.4901e-07,  0.0000e+00, -3.5763e-07],\n",
       "           [-7.1526e-07, -7.0781e-08,  1.6391e-07, -2.3842e-07,  2.7418e-06, -2.2701e-08, -5.9605e-08,  7.4506e-07],\n",
       "           [-3.3528e-07,  2.2352e-08, -5.3644e-07, -5.6624e-07,  4.5300e-06, -7.7486e-07, -1.7881e-07,  1.3113e-06],\n",
       "           [ 2.1458e-06,  8.9407e-07, -3.0994e-06,  2.8312e-07,  2.2650e-06, -2.5034e-06, -1.6689e-06,  5.4948e-08],\n",
       "           [-1.9073e-06,  8.3447e-07,  5.9605e-07,  2.0862e-07, -1.0729e-06,  9.5367e-07,  1.3113e-06, -7.7486e-07],\n",
       "           [-9.5367e-07,  1.7881e-07,  5.9605e-07,  1.7881e-07, -4.7684e-07,  8.3447e-07,  5.3644e-07, -9.6858e-08],\n",
       "           [ 1.1921e-06, -1.1921e-07, -9.5367e-07, -3.5763e-07,  2.3842e-07, -1.1921e-06, -7.1526e-07,  2.0862e-07],\n",
       "           [-6.8545e-07,  9.5367e-07,  3.5763e-07,  5.9605e-08,  8.3447e-07,  9.5367e-07,  1.7285e-06, -3.8743e-07],\n",
       "           [-7.0781e-08,  1.4901e-08, -5.2154e-08, -1.4901e-08,  3.7253e-08, -2.6077e-08,  1.4901e-08, -5.9605e-08],\n",
       "           [ 4.4703e-08, -3.1665e-08, -8.9407e-08,  3.3528e-08,  8.9407e-08,  8.9407e-08,  1.4901e-07,  5.9605e-08],\n",
       "           [-8.9407e-07,  1.3113e-06,  2.3842e-06,  1.4156e-07, -3.5763e-06, -2.1458e-06, -5.0068e-06, -2.6226e-06],\n",
       "           [-4.4703e-08, -2.9802e-08,  1.7881e-07,  1.7509e-07, -3.5763e-07, -1.1921e-07, -5.3644e-07, -1.4901e-07],\n",
       "           [-1.1921e-07,  0.0000e+00,  4.4703e-08, -2.3842e-07,  1.1921e-07, -4.4703e-08, -7.4506e-08,  5.9605e-08],\n",
       "           [-1.5497e-06, -7.4506e-07,  7.7486e-07, -1.1921e-06,  4.4703e-07, -1.7881e-06, -4.2915e-06, -2.1458e-06],\n",
       "           [ 2.9802e-07,  2.0862e-07, -2.6822e-07,  5.3644e-07, -2.2352e-07,  2.9802e-07,  5.9605e-07,  1.1921e-07],\n",
       "           [-2.8610e-06, -1.6689e-06,  7.4506e-07, -8.9407e-07,  1.1623e-06, -2.5034e-06, -5.0068e-06, -3.3379e-06],\n",
       "           [-4.2915e-06, -3.2187e-06, -5.9605e-08, -2.6226e-06,  2.6226e-06, -3.6955e-06, -5.9605e-06, -2.9802e-06],\n",
       "           [-5.9605e-07,  4.9174e-07, -5.9605e-08,  1.1921e-07, -3.1292e-07, -4.4703e-07,  8.3447e-07,  1.6689e-06],\n",
       "           [-5.2452e-06,  1.1623e-06, -2.3842e-07, -1.4007e-06, -4.1723e-07, -1.0431e-06, -2.2650e-06,  2.5034e-06],\n",
       "           [ 3.0994e-06, -6.5565e-07, -4.4703e-08,  1.1325e-06,  2.3842e-07,  5.9605e-07,  1.4305e-06, -1.4305e-06],\n",
       "           [ 3.4273e-07, -5.9605e-08, -1.7881e-07,  2.6822e-07,  5.2154e-08,  5.5879e-08,  4.4703e-08,  2.9802e-08],\n",
       "           [-3.5763e-07, -9.5367e-07,  1.7881e-07, -6.5565e-07, -2.6822e-07, -5.2154e-08,  5.9605e-07,  4.7684e-07],\n",
       "           [-3.1292e-07, -3.5763e-07,  1.1921e-07, -3.2783e-07, -1.0431e-07, -7.4506e-09,  2.6822e-07,  2.3842e-07],\n",
       "           [-2.3842e-07,  2.2352e-07, -2.6822e-07,  3.8743e-07,  1.9372e-07,  2.3842e-07, -5.9605e-08, -1.8626e-07],\n",
       "           [ 9.5367e-07, -3.8743e-07,  1.0729e-06,  1.6671e-07, -1.7881e-07,  1.5497e-06, -2.3842e-06, -2.1458e-06],\n",
       "           [ 3.0994e-06, -2.7418e-06,  3.4571e-06, -4.5300e-06, -6.9141e-06,  8.1062e-06, -6.6757e-06, -6.9141e-06],\n",
       "           [-2.0862e-07, -4.9174e-07,  4.4703e-08, -7.1526e-07, -1.0729e-06,  1.1921e-06, -2.9802e-07, -5.9605e-07],\n",
       "           [-7.1526e-07, -9.6858e-08,  8.9407e-08, -7.7486e-07, -5.9605e-07,  1.2293e-07, -9.5367e-07,  1.4901e-07],\n",
       "           [-3.2187e-06,  6.2585e-07,  4.0233e-07, -3.0398e-06, -2.6226e-06,  1.7881e-07, -3.5763e-06,  5.3644e-07],\n",
       "           [ 1.7881e-07,  8.9407e-08, -4.1723e-07,  1.0729e-06,  7.1526e-07,  2.6822e-07,  5.9605e-07,  3.2783e-07],\n",
       "           [-2.5034e-06, -5.4836e-06,  1.1444e-05,  4.5300e-06, -2.5630e-06,  1.2398e-05, -7.4506e-08, -7.3910e-06],\n",
       "           [ 4.1723e-07,  8.3447e-07, -1.9073e-06, -7.1526e-07,  3.5763e-07, -2.1458e-06,  7.4506e-08,  1.1921e-06],\n",
       "           [-7.4506e-07, -2.8610e-06,  5.2452e-06,  1.2815e-06, -2.3842e-06,  5.9605e-06, -8.9407e-07, -3.5763e-06],\n",
       "           [ 1.0431e-07,  7.4506e-08, -8.9407e-08, -5.4017e-08, -1.9558e-08, -9.6858e-08, -1.3970e-08,  8.2888e-08],\n",
       "           [-3.5763e-07,  1.7881e-07, -5.9605e-08,  5.9605e-08, -1.7881e-07,  3.7253e-09, -3.5763e-07, -3.7253e-08],\n",
       "           [ 4.0531e-06, -1.5497e-06, -1.4901e-08, -1.4305e-06,  1.7881e-06, -5.3644e-07,  3.8147e-06,  5.9605e-08],\n",
       "           [-1.0729e-06,  1.4901e-08,  1.4901e-07,  1.0431e-07,  1.7881e-07,  4.4703e-08, -4.6194e-07,  3.5763e-07],\n",
       "           [-7.4506e-08, -2.0862e-07,  2.0862e-07, -2.2352e-07,  5.9605e-07, -2.2352e-08,  3.7253e-07,  1.4901e-07],\n",
       "           [-3.2969e-07,  8.9407e-08,  3.5763e-07, -2.3842e-07,  7.1526e-07,  1.1921e-07, -5.9837e-08, -3.5763e-07],\n",
       "           [ 2.2352e-08, -6.3330e-08,  7.4506e-09, -2.7940e-08,  2.9802e-08, -2.2352e-08,  7.0781e-08, -7.4506e-08],\n",
       "           [ 1.6764e-08, -2.9802e-08,  2.2352e-08, -4.4703e-08, -2.7940e-08, -1.4901e-08,  4.4703e-08, -1.0431e-07],\n",
       "           [-7.1526e-07,  1.3113e-06, -1.7881e-07,  2.0862e-07, -7.1526e-07, -3.5763e-07,  1.0133e-06, -1.1921e-06],\n",
       "           [ 0.0000e+00,  5.0664e-07, -2.6077e-07, -1.1921e-07, -8.9407e-08,  3.5763e-07, -1.4901e-07, -1.9372e-07],\n",
       "           [ 2.1607e-07, -2.9802e-07,  2.3842e-07,  2.7567e-07, -3.5763e-07, -2.3842e-07,  1.0431e-07,  5.9605e-08],\n",
       "           [-1.1921e-06,  1.0431e-07,  2.4959e-07, -2.0862e-07, -3.7253e-07, -3.2783e-07, -1.3113e-06, -1.3411e-07],\n",
       "           [ 1.1921e-07,  1.5497e-06, -1.5497e-06,  5.9605e-07,  1.4156e-07, -8.9407e-07, -7.1526e-07,  3.5763e-07],\n",
       "           [-2.6226e-06,  6.1989e-06,  6.5565e-07, -6.8545e-07,  1.6093e-06, -2.3842e-06, -4.4107e-06,  2.6077e-07],\n",
       "           [ 5.9605e-08,  7.1526e-07,  6.7055e-08,  0.0000e+00,  1.9372e-07, -8.6427e-07, -3.5763e-07, -1.0431e-07],\n",
       "           [-1.9744e-07,  2.9802e-08, -5.5134e-07,  1.7881e-07, -2.0862e-07,  2.0489e-07, -2.2352e-07,  8.9407e-08],\n",
       "           [-1.7285e-06, -1.4305e-06, -1.7881e-06, -2.7418e-06,  4.7684e-06,  4.2915e-06, -7.1526e-06,  7.8678e-06],\n",
       "           [ 1.0729e-06, -3.0994e-06, -3.2187e-06, -5.0068e-06,  6.4373e-06,  6.4373e-06, -7.8678e-06,  8.5831e-06],\n",
       "           [ 3.8743e-07,  4.6194e-07,  7.7486e-07,  1.6391e-07, -8.9407e-07, -1.3113e-06,  1.5497e-06, -1.9073e-06],\n",
       "           [ 2.6822e-07, -1.0803e-07, -1.4901e-07, -7.1526e-07,  1.1921e-07, -1.7881e-07,  8.9407e-08,  4.1723e-07],\n",
       "           [ 1.4901e-06, -6.5938e-07,  7.7486e-07, -2.5034e-06,  5.9605e-07,  4.7684e-07,  5.2154e-08, -1.3709e-06],\n",
       "           [ 2.9802e-07, -2.3842e-07,  2.0862e-07,  0.0000e+00, -8.9407e-08,  2.0862e-07,  2.3842e-07,  3.8743e-07],\n",
       "           [ 1.7881e-07, -1.3113e-06, -3.5763e-06, -5.6624e-07, -1.3411e-07,  1.9073e-06,  2.0266e-06, -4.4703e-08],\n",
       "           [ 5.3644e-07, -5.2452e-06, -1.2398e-05, -1.7881e-06,  5.3644e-07,  7.1526e-06,  7.6294e-06, -1.4901e-07],\n",
       "           [-6.5565e-07,  4.7684e-06,  1.1444e-05,  1.8179e-06,  5.2154e-07, -6.5565e-06, -6.5565e-06,  3.2224e-07],\n",
       "           [ 2.1607e-07, -1.7174e-06, -4.1723e-06, -7.0781e-07, -3.2783e-07,  2.3246e-06,  2.4140e-06, -1.7881e-07],\n",
       "           [-9.2387e-07,  1.4305e-05,  1.1683e-05,  8.5831e-06,  4.5300e-06, -1.5974e-05, -7.0333e-06,  1.6689e-06]]]], device='cuda:0'),\n",
       " tensor(1.5974e-05, device='cuda:0'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dQs_cu - dQs_pt, torch.abs(dQs_cu - dQs_pt).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 2.9802e-07, -2.9802e-07,  3.5763e-07, -2.0862e-07,  1.4901e-07,  3.5763e-07,  7.1526e-07,  7.1526e-07],\n",
       "           [ 1.4901e-08,  7.4506e-08,  1.4901e-07,  5.9605e-08, -2.2352e-08, -8.9407e-08, -3.7253e-09, -1.4901e-07],\n",
       "           [-2.9686e-09, -1.1921e-07, -3.5763e-07, -1.4901e-07,  5.2154e-08,  1.4901e-07, -6.7055e-08,  2.0862e-07],\n",
       "           [-2.9802e-08, -7.4506e-08,  4.6566e-08, -4.4703e-07, -7.4506e-08, -4.1723e-07,  3.2783e-07,  6.5565e-07],\n",
       "           [ 8.9407e-08,  1.3411e-07,  3.2783e-07,  3.5763e-07,  1.7881e-07,  1.0431e-07, -2.3842e-07, -3.5763e-07],\n",
       "           [-3.7253e-07,  1.3113e-06,  2.7418e-06,  1.3709e-06,  1.5497e-06, -4.1723e-07, -1.6689e-06, -4.6194e-07],\n",
       "           [ 2.8312e-07, -1.6391e-07,  2.2352e-07, -4.4703e-07, -5.9605e-07,  3.8743e-07, -9.6858e-08,  1.3411e-07],\n",
       "           [ 9.5367e-07,  2.0862e-07,  1.9073e-06, -2.1458e-06, -7.1526e-07, -3.5763e-07, -5.6624e-07,  1.7881e-06],\n",
       "           [ 2.9802e-08,  1.1921e-06, -3.3379e-06,  9.5367e-07,  8.3447e-07,  7.1526e-07, -9.5367e-07,  8.3447e-07],\n",
       "           [-5.9605e-08,  5.9605e-07, -1.9073e-06,  5.9605e-08, -1.4901e-07,  3.5763e-07, -4.7684e-07,  4.7684e-07],\n",
       "           [ 1.2666e-07, -1.2666e-07,  5.0664e-07,  8.6427e-07,  7.0781e-08,  2.3842e-07,  5.6624e-07, -4.7684e-07],\n",
       "           [ 1.1921e-07, -4.4703e-08,  5.9605e-07,  1.2815e-06,  1.5646e-07,  3.2783e-07,  1.1921e-06, -8.6427e-07],\n",
       "           [ 3.7625e-07, -4.4703e-08,  2.2352e-07, -3.8743e-07, -8.9407e-08, -2.6822e-07,  3.5763e-07,  4.4703e-08],\n",
       "           [ 8.1062e-06,  1.1129e-06,  3.8147e-06, -5.2452e-06, -1.0729e-06, -5.0068e-06,  6.1989e-06, -4.1723e-07],\n",
       "           [-1.9073e-06, -3.5763e-07, -1.1325e-06,  1.3709e-06,  2.8312e-07,  1.3709e-06, -1.4901e-06,  5.2154e-08],\n",
       "           [ 1.7881e-07, -8.3447e-07,  4.1723e-07, -6.2585e-07,  1.0729e-06,  6.2585e-07,  1.3709e-06, -1.1921e-06],\n",
       "           [ 2.3842e-07, -1.4305e-06,  4.1723e-07, -1.0133e-06,  1.9073e-06,  1.0133e-06,  2.3842e-06, -2.5034e-06],\n",
       "           [-1.9073e-06,  6.6757e-06,  3.2187e-06, -1.3709e-06, -5.2452e-06, -1.1921e-06,  1.7583e-06,  1.0729e-06],\n",
       "           [ 1.9372e-07, -1.5646e-07, -5.6624e-07,  4.7684e-07,  1.2666e-07, -3.7253e-07, -9.5367e-07,  5.9605e-07],\n",
       "           [-1.4715e-07, -5.9605e-07,  6.8545e-07, -8.0466e-07,  7.7486e-07,  1.0729e-06,  1.6689e-06, -1.4305e-06],\n",
       "           [ 3.3155e-07, -7.1526e-07, -1.6689e-06,  1.6689e-06, -8.3447e-07, -1.1921e-07, -3.5763e-06,  2.6226e-06],\n",
       "           [ 4.1723e-07, -1.3784e-07,  1.3411e-07, -1.1921e-07,  1.6689e-06, -5.6624e-07,  9.5367e-07, -1.2517e-06],\n",
       "           [-1.0133e-06,  1.3113e-06, -2.0266e-06, -4.4703e-07,  2.6226e-06, -3.2187e-06,  9.6112e-07, -9.5367e-07],\n",
       "           [-1.7881e-07, -3.5763e-07, -4.1723e-07, -1.7881e-07,  1.0431e-07, -2.3842e-07, -8.3447e-07, -2.3842e-07],\n",
       "           [ 2.7940e-09,  7.4506e-08,  3.7253e-08,  9.3132e-09,  7.4506e-09,  6.7055e-08,  4.4703e-08, -1.0245e-08],\n",
       "           [-2.5705e-07,  1.7881e-06,  1.4901e-07, -1.2200e-07,  6.5565e-07,  9.5367e-07,  1.1921e-06,  5.3644e-07],\n",
       "           [ 1.3504e-08,  1.8626e-08, -3.9116e-08, -2.7940e-09,  1.4901e-08, -1.4901e-08, -7.4506e-09,  5.9605e-08],\n",
       "           [ 2.3842e-07, -2.7418e-06,  2.1458e-06,  1.0431e-07,  1.1921e-07,  1.7881e-07, -1.9073e-06, -9.5367e-07],\n",
       "           [ 9.5367e-07, -1.0490e-05,  2.3842e-07,  1.5497e-06,  7.1526e-06,  4.7684e-07, -3.2187e-06,  1.1921e-06],\n",
       "           [-1.0729e-06, -5.2452e-06,  2.0862e-06,  4.1723e-07,  2.5034e-06, -8.3447e-07, -1.7881e-06, -1.0729e-06],\n",
       "           [ 2.3842e-07,  3.5763e-07, -8.9407e-08, -1.7881e-07, -4.1723e-07,  5.3644e-07,  3.2037e-07,  1.1921e-07],\n",
       "           [ 1.1921e-06,  3.0994e-06,  2.3842e-07, -3.3379e-06, -4.7684e-06,  5.0068e-06,  5.2452e-06,  2.3842e-07],\n",
       "           [ 8.9407e-08, -7.1526e-07,  2.0862e-07,  3.1292e-07,  7.1526e-07, -8.6427e-07, -8.3447e-07, -5.3644e-07],\n",
       "           [-1.0431e-07,  5.9605e-08, -3.7253e-08, -3.8743e-07, -2.0862e-07,  7.4506e-09,  1.7881e-07,  3.5763e-07],\n",
       "           [-2.1458e-06,  7.0333e-06,  2.3842e-07,  3.3379e-06, -1.4305e-06,  7.6294e-06, -7.1526e-06,  7.3910e-06],\n",
       "           [-1.0431e-07,  8.2888e-08, -5.7742e-08,  2.7567e-07,  1.7695e-08,  6.1467e-08,  8.1956e-08,  1.2293e-07],\n",
       "           [-4.1723e-07,  2.3097e-07, -1.3411e-07,  1.0729e-06,  3.2783e-07,  5.6624e-07,  1.6391e-07,  3.1292e-07],\n",
       "           [-8.1956e-08,  7.4506e-08, -2.6077e-08,  6.5193e-09,  7.4506e-09, -8.9407e-08,  0.0000e+00,  6.5193e-09],\n",
       "           [-1.9073e-06,  2.8610e-06, -1.1921e-06,  1.1921e-06, -2.0862e-07, -3.0994e-06,  1.2517e-06,  1.1921e-06],\n",
       "           [ 5.9605e-08, -2.0862e-07,  8.9407e-08, -8.1956e-08, -1.4901e-08,  1.7881e-07, -4.4703e-08, -1.4901e-07],\n",
       "           [ 8.3447e-07,  2.0862e-07,  1.6391e-07,  8.1956e-08, -7.4506e-08, -3.7253e-09,  5.5879e-08,  9.5367e-07],\n",
       "           [-9.5367e-07,  3.5763e-07,  5.9605e-08,  5.9605e-07, -7.1526e-07, -7.7486e-07,  5.3644e-07, -1.9372e-07],\n",
       "           [-1.9372e-07,  1.0431e-07, -9.6858e-08,  4.0513e-08,  6.7055e-08, -1.5274e-07,  1.4901e-07, -1.2666e-07],\n",
       "           [-6.3330e-08, -1.2480e-07, -1.7881e-07, -4.8429e-08,  7.4506e-09, -3.3528e-08,  9.3132e-08,  3.7253e-09],\n",
       "           [-4.0978e-08, -2.4587e-07, -3.6135e-07, -1.1269e-07, -8.9407e-08, -4.2468e-07,  2.4028e-07,  5.2154e-08],\n",
       "           [ 1.2293e-07, -1.4901e-07,  2.0862e-07, -3.8743e-07, -2.9802e-07,  2.0266e-06, -6.5565e-07,  5.0664e-07],\n",
       "           [ 5.2154e-08,  1.7881e-07,  2.5332e-07,  2.2352e-08,  2.1607e-07, -1.4901e-08,  0.0000e+00,  4.4703e-08],\n",
       "           [-3.5390e-08, -2.9802e-08, -4.4703e-08,  1.1176e-08, -5.9605e-08, -3.7253e-08, -4.8429e-08,  2.9802e-08],\n",
       "           [-2.3842e-07,  7.7486e-07, -1.3709e-06, -1.1921e-06, -4.4703e-07, -6.5565e-07, -7.5996e-07,  1.3113e-06],\n",
       "           [ 4.4107e-06,  4.1723e-06,  8.2701e-07, -1.5497e-06,  3.0994e-06,  1.6689e-06, -2.7418e-06, -5.0068e-06],\n",
       "           [ 3.2187e-06,  2.2650e-06, -8.9407e-08, -2.8610e-06,  1.1325e-06,  1.4901e-06,  0.0000e+00, -1.7285e-06],\n",
       "           [ 2.1607e-07, -4.0978e-07,  2.7940e-07,  7.7486e-07, -4.5449e-07, -6.2585e-07,  3.5763e-07, -9.8348e-07],\n",
       "           [ 1.4305e-06,  1.5736e-05, -2.5034e-06, -1.0490e-05,  1.0490e-05,  5.4836e-06,  2.7418e-06,  6.1989e-06],\n",
       "           [-8.3819e-09, -7.4506e-09,  1.0245e-08,  1.6764e-08,  6.5193e-09, -9.3132e-09, -7.4506e-09, -8.3819e-09],\n",
       "           [-4.4703e-07, -3.2485e-06,  5.9605e-07,  5.1707e-06,  9.5367e-07, -1.3113e-06,  1.1921e-07, -2.4438e-06],\n",
       "           [-8.3447e-07,  2.9802e-07, -3.9861e-07, -2.3842e-07, -2.9802e-07,  2.1607e-07, -6.2585e-07,  5.9605e-08],\n",
       "           [ 1.7881e-07, -1.7881e-07,  5.9605e-08,  2.3842e-07,  2.9802e-08, -2.9802e-08,  2.3842e-07, -5.9605e-08],\n",
       "           [ 1.4901e-08,  1.4901e-07,  1.7881e-07, -1.7881e-07, -1.7881e-07, -3.7253e-08, -7.4506e-08,  1.4901e-07],\n",
       "           [ 2.6077e-08,  2.9802e-07, -4.3714e-08, -4.4703e-08, -2.0862e-07, -8.9407e-08, -4.0978e-08, -4.1723e-07],\n",
       "           [ 6.0797e-06, -3.6359e-06, -1.6689e-05, -9.5367e-06,  5.3942e-06,  6.9141e-06, -1.8358e-05,  3.5763e-06],\n",
       "           [-1.4156e-07, -1.8359e-07,  4.4703e-08,  7.0035e-07, -1.3900e-07, -1.8626e-07,  4.4703e-07, -1.4529e-07],\n",
       "           [-1.6857e-07, -8.9407e-08,  2.3842e-07,  2.9802e-08, -1.4901e-07, -1.3411e-07,  5.9605e-08, -1.0803e-07],\n",
       "           [-1.3039e-08, -3.7253e-08, -8.9407e-08,  1.8626e-09, -3.3528e-08,  1.1176e-08, -6.7055e-08, -9.3132e-09],\n",
       "           [ 1.3709e-06,  3.0994e-06,  6.4373e-06, -1.4305e-06,  6.8545e-07, -1.3113e-06,  5.7220e-06,  2.6226e-06]]]], device='cuda:0'),\n",
       " tensor(1.8358e-05, device='cuda:0'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dKs_cu - dKs_pt, torch.abs(dKs_cu - dKs_pt).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.4305e-06,  5.3644e-07,  3.8147e-06, -9.5367e-07,  2.0489e-08,  8.3447e-07, -8.9407e-08, -4.1723e-07],\n",
       "           [ 4.4703e-08, -7.4506e-09, -4.4703e-08, -8.9407e-08,  3.7253e-09,  7.4506e-08, -7.4506e-08, -9.3132e-09],\n",
       "           [-3.7253e-09,  2.3842e-07,  2.9802e-07,  2.3842e-07, -5.9605e-08, -2.9802e-07, -1.1921e-07, -3.5763e-07],\n",
       "           [-8.1956e-08, -2.2352e-07,  9.5367e-07,  1.4901e-07, -8.9407e-08, -8.3447e-07,  1.3113e-06,  1.9372e-07],\n",
       "           [-4.4703e-08, -3.7253e-08,  1.4901e-07, -2.0862e-07, -1.1921e-07, -4.4703e-08,  2.9802e-08,  2.3842e-07],\n",
       "           [-4.4703e-07,  5.9605e-08, -1.5497e-06, -7.7486e-07,  1.6689e-06, -2.5034e-06,  1.6093e-06,  1.3709e-06],\n",
       "           [-1.1921e-07, -1.4305e-06,  2.0862e-07,  1.1921e-07, -1.3113e-06,  1.5497e-06,  7.7486e-07, -1.7881e-06],\n",
       "           [ 1.1921e-07, -5.9605e-07,  1.3113e-06, -1.0729e-06, -3.5763e-07, -1.4901e-07,  2.6822e-07,  1.3411e-07],\n",
       "           [ 8.9407e-08,  1.8440e-07, -2.3842e-07, -1.3411e-07, -2.2352e-08, -2.3842e-07, -3.5763e-07,  3.8743e-07],\n",
       "           [-1.1921e-07,  8.9407e-08, -3.5763e-07, -6.2585e-07, -4.3306e-08, -1.1921e-07, -4.3213e-07,  3.4273e-07],\n",
       "           [-2.2352e-08, -1.4901e-08,  0.0000e+00,  9.6858e-08,  8.3819e-09,  7.4506e-08,  4.6348e-08, -4.6100e-08],\n",
       "           [ 5.9605e-07, -4.6194e-07,  2.0266e-06,  3.2187e-06,  2.2352e-07,  1.0133e-06,  2.3842e-06, -1.9073e-06],\n",
       "           [-2.3842e-07, -4.4703e-08, -8.9407e-08,  1.6391e-07,  2.9802e-08,  1.9372e-07, -2.0862e-07, -4.8429e-08],\n",
       "           [-9.5367e-07,  4.1723e-07,  5.9605e-07, -2.9802e-07,  5.9605e-08, -3.5763e-07, -2.1458e-06,  1.6391e-07],\n",
       "           [ 2.0266e-06,  5.0664e-07,  1.1921e-06, -1.5497e-06, -2.6077e-07, -1.4901e-06,  1.6689e-06, -2.2352e-08],\n",
       "           [ 1.4305e-06, -1.0729e-06,  9.5367e-07, -8.9407e-08, -2.9802e-08,  4.4703e-07,  2.7940e-07, -7.1526e-07],\n",
       "           [-8.3447e-07,  1.3709e-06, -3.5763e-07,  2.3842e-06, -2.1458e-06, -7.1526e-07, -1.9073e-06,  9.8348e-07],\n",
       "           [-8.3447e-07,  1.1921e-06,  1.1921e-06,  2.3842e-07, -1.0133e-06,  1.0133e-06,  1.1325e-06,  1.1921e-07],\n",
       "           [ 1.4901e-08, -1.0133e-06,  1.4901e-07, -4.4703e-07,  7.1526e-07,  1.0729e-06,  9.5367e-07, -7.7486e-07],\n",
       "           [ 6.7055e-08, -3.5763e-07, -1.0803e-07,  4.2841e-08,  2.9802e-07,  2.3842e-07,  2.2352e-08, -1.0431e-07],\n",
       "           [ 1.0729e-06, -1.4305e-06, -3.0994e-06,  2.7418e-06,  5.8860e-07, -1.1921e-06, -5.0068e-06,  3.4571e-06],\n",
       "           [ 7.1526e-07, -3.8743e-07,  4.1723e-07, -1.6391e-07,  2.8610e-06, -4.4703e-07,  1.3113e-06, -1.7881e-06],\n",
       "           [ 7.7486e-07,  5.6624e-07,  5.9605e-07,  1.7881e-07,  1.1623e-06, -1.4305e-06,  2.1458e-06, -2.9802e-08],\n",
       "           [-1.0431e-07, -5.9605e-08, -2.0862e-07, -3.7253e-08,  8.1956e-08, -7.4506e-08, -2.0862e-07, -3.7253e-08],\n",
       "           [ 1.3970e-09,  7.4506e-09,  2.2352e-08,  5.5879e-09,  1.8626e-09,  4.4238e-09,  1.1176e-08,  7.4506e-09],\n",
       "           [ 7.7486e-07,  2.1458e-06,  7.7486e-07,  4.7684e-07, -3.7253e-07,  2.6226e-06,  4.1723e-07, -7.7486e-07],\n",
       "           [ 1.8626e-08,  2.7940e-08, -3.4925e-09, -1.8626e-09, -1.9558e-08, -3.3528e-08, -3.7253e-08, -6.9849e-10],\n",
       "           [ 8.3447e-07,  2.9802e-07,  5.9605e-08,  2.3842e-07, -5.6624e-07,  5.9605e-08, -1.0729e-06, -3.5763e-07],\n",
       "           [-7.0781e-07, -5.4836e-06,  3.3379e-06, -5.2154e-08,  1.3113e-06, -1.4901e-07, -1.9073e-06, -8.9407e-07],\n",
       "           [-8.9407e-07,  2.6226e-06, -8.3447e-07,  1.7881e-07, -9.5367e-07, -7.1526e-07,  3.5763e-07, -4.4703e-07],\n",
       "           [ 4.7684e-07,  4.3213e-07, -1.9372e-07, -1.7881e-07, -5.6624e-07,  1.0729e-06,  4.4703e-07,  3.5763e-07],\n",
       "           [-1.4305e-06,  5.3644e-07, -1.1921e-06,  1.0729e-06,  1.1921e-06, -1.7881e-06, -3.8147e-06,  2.1458e-06],\n",
       "           [-1.1027e-06, -4.5300e-06,  1.0729e-06,  1.9073e-06,  4.7684e-06, -6.0797e-06, -4.1723e-06,  7.7486e-07],\n",
       "           [ 1.5553e-07, -1.3039e-07,  6.1467e-08, -8.3447e-07, -3.8743e-07, -1.8626e-07,  1.4901e-08,  2.0862e-07],\n",
       "           [ 8.9407e-08,  3.5763e-06,  7.1526e-07, -4.2915e-06, -8.6427e-07, -1.5497e-06, -1.3784e-06,  1.4901e-06],\n",
       "           [-9.6858e-08,  0.0000e+00, -4.0978e-08,  2.6822e-07,  4.3772e-08,  1.5646e-07, -2.2352e-08,  3.5390e-08],\n",
       "           [-1.7881e-06,  1.7881e-06, -5.0664e-07,  4.2915e-06,  1.6689e-06,  1.3113e-06,  2.4214e-07,  1.6689e-06],\n",
       "           [-9.6858e-08,  2.0862e-07, -1.1269e-07,  9.3132e-08,  2.9802e-08, -2.0862e-07,  1.1921e-07,  9.8255e-08],\n",
       "           [-1.6689e-06,  1.4305e-06, -5.9605e-07,  2.3842e-07, -2.3842e-07, -1.6689e-06,  1.7881e-07,  1.1921e-07],\n",
       "           [-4.4703e-08,  1.1921e-07, -7.4506e-08,  5.9605e-08,  1.4901e-08, -2.0862e-07,  8.9407e-08,  4.4703e-08],\n",
       "           [-5.9605e-07, -1.6391e-07, -1.4901e-07, -2.9802e-08,  1.9372e-07, -1.0431e-07,  9.6858e-08, -7.1526e-07],\n",
       "           [-3.8743e-07, -1.4901e-08, -7.1526e-07,  5.9605e-08,  2.3842e-06, -9.5367e-07,  9.8348e-07, -8.3447e-07],\n",
       "           [ 6.5565e-07, -2.6822e-07, -8.9407e-08, -2.6822e-07,  6.5565e-07, -2.8173e-07,  1.2666e-07,  3.3528e-08],\n",
       "           [-3.3528e-08,  1.4901e-08, -1.0431e-07,  1.3411e-07,  7.4506e-08, -6.7055e-07,  2.5332e-07, -1.6531e-07],\n",
       "           [-5.4948e-08, -1.5646e-07, -2.9244e-07,  3.2783e-07,  4.4145e-07, -2.2650e-06,  1.1921e-06, -3.6508e-07],\n",
       "           [ 2.5332e-07, -2.7567e-07,  2.9802e-07, -3.5763e-07,  3.5763e-07,  5.9605e-07,  2.9802e-07,  4.1723e-07],\n",
       "           [ 2.9802e-08,  1.4901e-08,  1.1176e-08, -2.2352e-08,  5.9605e-08,  1.4901e-08,  0.0000e+00,  7.4506e-09],\n",
       "           [ 2.2352e-08,  4.4703e-08,  5.9605e-08, -3.7253e-08,  4.4703e-08,  0.0000e+00,  3.3528e-08,  7.4506e-09],\n",
       "           [-5.3644e-07, -2.9802e-08, -1.4305e-06, -1.1921e-06, -8.0466e-07, -7.3388e-07, -1.7881e-06,  1.3709e-06],\n",
       "           [-3.2783e-07,  1.1921e-06, -5.9605e-07,  1.4901e-08,  2.0117e-07,  2.8312e-07, -3.5763e-07,  2.1793e-07],\n",
       "           [ 2.6822e-07,  7.7486e-07,  1.1027e-06, -4.7684e-07,  2.0266e-06,  7.4506e-07, -1.2517e-06, -1.0133e-06],\n",
       "           [ 1.7881e-06,  1.9670e-06,  7.1526e-07,  5.0664e-07,  3.6135e-07, -2.0862e-06,  1.6093e-06, -1.1027e-06],\n",
       "           [ 1.4305e-06, -1.1444e-05,  4.5300e-06,  8.5831e-06, -8.1062e-06, -5.9605e-06, -1.9073e-06, -6.6757e-06],\n",
       "           [ 6.5193e-09,  1.4901e-08, -1.3039e-08, -1.1176e-08,  1.7695e-08,  1.3039e-08,  1.2107e-08,  7.4506e-09],\n",
       "           [ 2.3842e-06,  4.2915e-06, -2.5034e-06, -3.8147e-06,  1.5199e-06,  2.2650e-06,  2.2650e-06,  2.0266e-06],\n",
       "           [-8.3447e-07,  1.1325e-06,  5.0664e-07, -2.0266e-06, -1.1921e-06,  1.7881e-07, -1.3113e-06,  1.2517e-06],\n",
       "           [-3.1432e-09, -9.3132e-08, -4.8429e-08,  1.0803e-07,  8.5682e-08,  1.6764e-08,  4.0047e-08,  7.4506e-09],\n",
       "           [ 4.6566e-09,  7.4506e-09,  2.9802e-08, -8.9407e-08, -7.4506e-08,  3.7253e-09, -4.4703e-08,  7.4506e-08],\n",
       "           [ 8.1956e-08,  7.1526e-07,  1.1176e-08, -2.2352e-07, -3.2783e-07, -8.9407e-08, -9.6858e-08, -7.7486e-07],\n",
       "           [-3.8743e-07,  9.5069e-06,  2.2411e-05, -3.5763e-07,  4.1127e-06, -3.8147e-06,  1.5736e-05,  2.3842e-07],\n",
       "           [ 8.8289e-07,  1.1623e-06, -5.3644e-07, -5.3644e-06,  5.3644e-07,  1.3560e-06, -3.4571e-06,  9.8348e-07],\n",
       "           [ 5.6624e-07,  3.8743e-07, -3.1292e-07,  4.8429e-08,  9.5367e-07,  4.4703e-07, -4.4703e-08,  2.5332e-07],\n",
       "           [-1.1176e-08, -1.8626e-08, -2.2352e-08,  2.2352e-08,  1.7695e-08,  1.1176e-08, -2.9802e-08, -2.9802e-08],\n",
       "           [ 5.0664e-07,  1.0729e-06,  2.1458e-06, -5.0664e-07,  2.3842e-07, -4.4703e-07,  1.9073e-06,  9.5367e-07]]]], device='cuda:0'),\n",
       " tensor(2.2411e-05, device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dVs_cu - dVs_pt, torch.abs(dVs_cu - dVs_pt).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.5259e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-4.1206e-02, -6.7959e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 3.6761e-01,  1.1981e+00,  2.0817e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 6.6527e-02,  1.5095e-01,  6.5791e-01,  1.2679e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 1.0706e-01,  9.9456e-02,  7.6346e-01, -1.8267e+00,  9.2109e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-3.7631e-02,  2.6237e-02,  2.5274e-02,  2.6193e-01,  6.9473e-01,  8.5752e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-6.9545e-03,  2.2639e-04, -4.6380e-04,  7.1091e-02,  6.8082e-02,  7.1082e-02,  4.4476e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.0818e-03,  2.1464e-03,  1.5185e-03,  4.4968e-03,  9.1953e-03, -1.1226e-02, -5.3618e-02, -8.5615e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-3.2134e-03, -6.1670e-03, -8.5102e-03, -6.8080e-02, -1.3815e-01, -1.6094e-01,  1.1842e+00,  9.3345e-01,  6.7412e-01,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 4.9562e-03,  5.1495e-03,  8.7485e-03, -7.4578e-02, -3.0167e-02, -5.4939e-02, -3.2615e-01,  4.6407e-01,  2.2671e+00,  2.2043e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 2.4480e-03,  2.2305e-03,  1.4380e-03,  5.1469e-04, -8.7778e-03, -7.0091e-03,  7.6295e-02,  9.6603e-02, -6.9406e-01, -9.8559e-01, -1.0611e+00,  0.0000e+00],\n",
       "          [-3.9223e-05, -3.3643e-04, -4.1669e-04,  4.8056e-04,  4.9404e-04, -3.0190e-04,  2.0396e-02,  1.7450e-02, -9.8597e-02, -1.0066e-01, -9.8053e-04, -8.3205e-01],\n",
       "          [-5.0982e-05, -4.5764e-05, -1.5275e-04, -6.9271e-04, -7.8974e-04, -2.9556e-04,  1.1848e-02,  1.2858e-02, -1.1198e-01, -1.8328e-01, -4.2884e-02,  4.7678e-01],\n",
       "          [ 1.5523e-04, -4.2031e-04,  3.9668e-04,  3.5344e-04,  7.2288e-05,  5.1532e-04,  1.9724e-02,  1.9002e-02, -7.8862e-01, -7.7636e-01,  1.0149e-01, -1.3926e+00],\n",
       "          [-5.7733e-04,  1.9710e-03,  2.4545e-03,  9.0916e-03,  1.0204e-02,  9.8307e-03,  3.8382e-02,  5.7907e-02,  4.2192e-02,  1.5242e-02,  8.1734e-02, -8.7869e-02],\n",
       "          [ 7.4111e-04,  8.6371e-04,  5.5511e-04,  5.2926e-04,  5.8355e-04,  6.0281e-04,  1.5004e-02,  1.8857e-02, -6.2187e-02, -5.2266e-02,  2.8368e-01, -1.0027e+00],\n",
       "          [ 6.9976e-05,  1.6680e-04,  2.3864e-04,  1.7841e-04,  1.7835e-04,  1.7740e-04,  6.4510e-05,  2.1279e-03,  1.1892e-04,  2.8467e-03,  9.8421e-03, -7.5737e-02],\n",
       "          [ 1.5683e-06,  1.9490e-06,  1.0112e-05, -1.1822e-05,  2.3193e-05,  1.4880e-05,  6.5439e-05,  4.1562e-04, -2.9170e-04, -5.3612e-04,  3.4581e-03,  3.6039e-03],\n",
       "          [-4.2561e-06, -1.6542e-06, -2.6306e-06,  4.0439e-05,  4.2793e-05,  4.2559e-05, -1.2064e-04, -1.2781e-04,  7.0446e-04,  7.3822e-04,  2.8438e-03,  5.0830e-03],\n",
       "          [ 1.5250e-06,  6.5356e-06,  1.2094e-05,  2.9482e-05,  2.7315e-05,  2.8892e-05, -2.5271e-05, -5.4680e-05,  4.2131e-04,  3.3416e-04,  7.9309e-04,  2.5915e-03],\n",
       "          [ 2.8188e-07,  3.9263e-06,  3.3753e-06,  5.1886e-06,  2.7404e-06,  1.2426e-06, -3.1818e-05, -2.7678e-05,  5.5152e-05, -4.0689e-05, -2.1258e-04,  1.7550e-03],\n",
       "          [ 1.2174e-07,  1.6234e-07, -7.2968e-08, -1.0463e-06, -1.3939e-06, -1.6003e-06, -2.0237e-05,  6.0408e-06,  3.6869e-05,  3.3282e-05,  2.4320e-05,  5.1594e-05],\n",
       "          [-2.0705e-08,  1.1531e-07, -5.9470e-08,  4.0370e-07,  9.5831e-07,  9.3755e-07, -2.1208e-06, -1.7123e-06, -1.1413e-05, -1.3526e-05, -1.8449e-05, -3.2511e-05],\n",
       "          [-4.4888e-08, -1.0602e-07, -7.0259e-08, -2.4163e-07, -1.3553e-08,  1.6688e-08, -1.1255e-05, -2.2584e-06,  2.4254e-06,  3.7276e-07,  4.7609e-05,  6.2481e-06],\n",
       "          [ 1.6800e-08,  1.1041e-09,  2.4359e-08, -4.1898e-07, -3.5885e-07, -3.7265e-07, -2.3952e-09, -5.2312e-06, -2.8764e-05, -1.8569e-05, -3.0276e-05, -1.2218e-04],\n",
       "          [-4.4324e-09,  4.8706e-08,  1.0592e-07,  1.7414e-07,  2.8250e-07,  2.1459e-07,  1.5172e-06,  1.3891e-06, -6.7720e-06, -7.2930e-06, -3.5985e-06, -4.0116e-06],\n",
       "          [ 7.3286e-09,  7.9518e-08,  9.0072e-08,  1.5551e-07,  1.4454e-07,  1.2426e-07, -1.0549e-06, -1.1728e-06,  1.6647e-06,  3.2026e-06,  6.1094e-06, -3.5555e-05],\n",
       "          [-4.8849e-10, -4.1563e-09,  3.8352e-09,  1.1283e-08,  1.4055e-08,  1.6564e-08, -3.5997e-09, -1.7332e-07, -4.8454e-07, -1.3173e-06,  4.0039e-06,  1.1480e-05],\n",
       "          [ 1.4206e-11, -4.2828e-10, -9.9128e-11, -3.3446e-10, -8.8468e-10, -1.5502e-09,  1.4242e-08, -1.4499e-08, -1.1003e-07, -1.1623e-07,  1.2452e-06,  6.7238e-07],\n",
       "          [ 5.3790e-10,  3.7066e-10,  3.5015e-10,  1.5768e-09,  4.2873e-10,  6.4938e-10,  5.6299e-09,  2.6137e-08,  3.3959e-08,  1.8667e-08, -3.4012e-08, -3.8696e-07],\n",
       "          [ 5.3082e-10,  5.3719e-10,  4.8118e-10, -8.4468e-10, -1.4598e-09, -1.2108e-09,  7.9312e-09,  5.6280e-09,  4.3385e-07,  3.0964e-07,  7.8216e-07,  1.4675e-06],\n",
       "          [ 3.9325e-10,  4.7475e-10,  4.0071e-10,  4.0066e-10,  1.2416e-09,  6.2454e-10,  1.0493e-09,  2.9166e-09, -3.0022e-08, -2.0810e-08, -5.0957e-08, -2.2554e-07],\n",
       "          [ 3.2724e-13, -1.1359e-11, -3.4909e-11,  7.0158e-12,  2.2472e-11, -2.0190e-11,  2.6679e-10,  5.4986e-10, -1.3846e-08, -1.3913e-08,  2.1845e-08,  4.5754e-08],\n",
       "          [ 7.9054e-12,  1.9040e-11,  1.2123e-10, -2.4594e-10, -1.1529e-10, -1.6831e-10, -2.9012e-09, -6.7083e-11,  7.1245e-10,  3.0913e-09,  3.0894e-09,  8.7615e-09],\n",
       "          [-4.1050e-13, -1.4563e-11, -1.8442e-11, -6.7779e-11, -7.1054e-11, -7.1464e-11, -1.3295e-10, -5.7206e-10,  4.2134e-10,  4.8317e-10,  5.4305e-10, -5.9347e-09],\n",
       "          [ 3.8941e-12,  6.2524e-12,  1.5405e-11, -2.2939e-11, -2.1198e-12, -3.8112e-12, -1.3917e-10,  6.2239e-11,  4.5029e-10,  6.1953e-10,  1.5104e-09, -9.1738e-10],\n",
       "          [ 4.2353e-13,  5.1998e-12, -1.4954e-11, -4.6640e-11, -4.6402e-11, -4.6482e-11, -8.6156e-11, -2.0092e-10, -1.7835e-09, -1.7905e-09, -1.7934e-09, -4.3988e-09],\n",
       "          [ 3.5879e-12,  4.3178e-12,  4.0021e-12,  6.0435e-13,  1.7263e-11,  1.2578e-11, -4.3915e-11,  1.5022e-10,  2.1731e-10,  2.2868e-10,  1.2609e-10, -8.1539e-10],\n",
       "          [ 7.6671e-13,  1.5656e-12,  1.8954e-12,  1.2283e-13,  4.1594e-12,  3.8987e-12, -1.0516e-11,  5.5570e-11, -8.5429e-11, -7.5815e-11, -8.3013e-11, -9.0541e-10],\n",
       "          [ 5.5640e-14,  1.0620e-12,  2.5460e-12,  2.0863e-12,  4.0521e-13,  4.4165e-13,  6.1905e-12, -9.7488e-13, -8.7237e-13,  2.6916e-11,  1.8344e-10, -2.6742e-10],\n",
       "          [ 1.6362e-13,  1.8458e-13,  1.9358e-13,  1.4763e-13, -1.5323e-13, -1.4704e-13,  3.9476e-12,  4.1119e-12, -7.7883e-11, -8.7680e-11, -1.9110e-11, -1.4344e-10],\n",
       "          [ 2.6655e-13,  2.3906e-13,  2.7473e-13,  5.9085e-13,  5.5405e-13,  4.3079e-13,  8.4062e-13,  1.2845e-12, -1.3154e-11, -5.1884e-12,  1.4579e-11, -1.2518e-10],\n",
       "          [ 8.8262e-15,  2.3833e-14,  4.0291e-14,  1.2611e-13,  1.9229e-13,  2.1805e-13,  7.6305e-13,  4.7569e-13,  4.2899e-12,  3.3972e-12,  7.9878e-11,  9.0488e-11],\n",
       "          [ 1.6009e-15,  1.5958e-15,  7.0944e-15,  4.1205e-15, -7.4605e-15, -2.0086e-14,  4.9996e-13,  5.3757e-13, -3.5568e-12, -4.9379e-12,  9.1118e-13,  2.1711e-12],\n",
       "          [ 1.0836e-15,  1.0998e-15, -2.3663e-14, -7.0485e-14, -6.2787e-14, -7.9522e-14,  3.8981e-13,  3.2325e-13,  1.1692e-12,  1.0075e-12,  1.1075e-12, -6.0763e-13],\n",
       "          [-1.7287e-15, -2.1372e-15,  4.4539e-15, -4.6684e-16, -2.4441e-16, -1.7860e-15, -2.1150e-13, -2.7260e-14,  4.3126e-13,  4.0564e-13,  3.0538e-13,  5.5210e-12],\n",
       "          [-1.9839e-16,  7.5803e-19,  7.7993e-17, -7.1279e-16, -5.2682e-16, -1.4004e-15, -2.3343e-16,  1.7247e-14,  2.8421e-14,  1.8214e-14,  4.6650e-14,  9.4069e-13],\n",
       "          [ 6.7083e-15,  6.3120e-15,  5.8630e-15,  9.7093e-15,  1.5726e-14,  6.0095e-15, -3.0092e-14,  5.3550e-14,  1.5337e-13,  2.5609e-13, -2.6421e-13, -1.7391e-12],\n",
       "          [ 3.8190e-16, -2.7898e-15, -4.0938e-15, -2.9718e-15,  2.4016e-15,  3.8361e-15, -1.5820e-13, -7.6016e-14, -8.9572e-13, -8.9811e-13,  2.0629e-12,  1.5972e-12],\n",
       "          [-4.0312e-17, -3.8166e-16, -1.2018e-15, -4.8310e-15, -6.1251e-15, -6.7025e-15,  2.3295e-14, -3.1207e-15, -2.3227e-14, -3.4323e-14, -3.1918e-14, -1.8017e-13],\n",
       "          [ 3.4235e-17, -2.8818e-17, -1.4374e-16, -6.4425e-16, -2.4814e-16, -1.4699e-15,  1.3253e-14,  2.8367e-14, -2.4567e-14, -2.7541e-14,  7.8359e-13,  7.1188e-13],\n",
       "          [ 6.8977e-17,  1.0406e-16,  5.9939e-16, -1.8171e-16,  4.7135e-16,  1.4011e-15, -3.6663e-15, -1.5918e-14,  1.2169e-13,  3.0159e-14,  8.2746e-13,  1.6473e-12],\n",
       "          [-7.2436e-18,  7.3451e-18,  1.2329e-16,  9.9322e-17,  2.3003e-16,  1.4453e-16, -2.4664e-16,  1.4199e-15, -3.1669e-14, -3.4624e-14, -2.1996e-14,  1.6281e-13],\n",
       "          [ 8.6681e-19,  1.2144e-18,  2.7165e-18, -6.4027e-18, -4.0662e-18, -4.1477e-18, -2.6147e-17,  6.9798e-17,  1.0980e-16, -1.1213e-16,  6.7969e-16,  9.8526e-16],\n",
       "          [-1.1181e-18, -2.0747e-18, -5.8547e-18, -1.3227e-17, -7.9016e-18, -4.0561e-18, -1.9675e-17, -1.4345e-16,  1.1243e-15,  8.8771e-16,  1.3333e-14,  2.0120e-14],\n",
       "          [ 1.6559e-18,  2.1136e-18, -2.2066e-18, -2.3905e-18,  1.5007e-18,  9.1183e-19, -2.3130e-17, -3.8239e-17, -1.7341e-16, -2.0839e-16, -1.9276e-16, -1.0750e-16],\n",
       "          [ 2.5854e-18,  2.5570e-18,  2.7539e-18,  6.1565e-18,  5.9851e-18,  6.5489e-18,  2.1850e-17,  7.5026e-18,  5.7521e-17,  1.0524e-16,  1.7543e-15, -4.4924e-16],\n",
       "          [ 6.5789e-19,  1.2512e-18,  4.7812e-18,  1.6365e-17,  1.8187e-17,  1.8246e-17,  6.4325e-17,  5.9028e-17,  3.7341e-17, -5.3734e-17,  6.1300e-16,  2.9627e-17]]]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_Dtilde_pt.cumsum(-1).tril(-1)[:, :, :, 5:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [ 0.0000e+00],\n",
       "           [-1.0611e+00],\n",
       "           [-9.8048e-04],\n",
       "           [-4.2884e-02],\n",
       "           [ 1.0149e-01],\n",
       "           [ 8.1734e-02],\n",
       "           [ 2.8368e-01],\n",
       "           [ 9.8421e-03],\n",
       "           [ 3.4581e-03],\n",
       "           [ 2.8438e-03],\n",
       "           [ 7.9309e-04],\n",
       "           [-2.1258e-04],\n",
       "           [ 2.4320e-05],\n",
       "           [-1.8449e-05],\n",
       "           [ 4.7609e-05],\n",
       "           [-3.0276e-05],\n",
       "           [-3.5985e-06],\n",
       "           [-9.1691e-01],\n",
       "           [ 1.8829e+00],\n",
       "           [ 1.7943e-01],\n",
       "           [-8.6747e-03],\n",
       "           [ 1.1568e-01],\n",
       "           [-7.9905e-03],\n",
       "           [-1.6362e-03],\n",
       "           [ 8.8857e-03],\n",
       "           [-2.3146e-03],\n",
       "           [ 8.4135e-04],\n",
       "           [-3.0571e-04],\n",
       "           [ 4.6045e-05],\n",
       "           [-1.2175e-05],\n",
       "           [ 7.9879e-05],\n",
       "           [-3.8685e-05],\n",
       "           [ 6.9976e-06],\n",
       "           [-7.8360e-02],\n",
       "           [ 8.6552e-02],\n",
       "           [-3.4454e-02],\n",
       "           [-1.8165e-02],\n",
       "           [-4.3711e-03],\n",
       "           [-2.8606e-03],\n",
       "           [-9.2952e-02],\n",
       "           [ 1.3821e-03],\n",
       "           [-1.2880e-03],\n",
       "           [-4.5256e-03],\n",
       "           [-4.0202e-04],\n",
       "           [-1.9368e-05],\n",
       "           [-3.2550e-05],\n",
       "           [-3.9069e-05],\n",
       "           [-9.8716e-07],\n",
       "           [-3.3347e-06]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 64]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltaDcsVec_cu.unsqueeze(-1), deltaDcsVec_cu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  3.5662e-01, -7.4386e-03,  ...,  6.1209e+00,  3.5817e+00,  2.6195e+00],\n",
       "          [-1.2414e-01,  2.3247e-01, -1.3158e-01,  ...,  5.9967e+00,  3.4575e+00,  2.4953e+00],\n",
       "          [ 2.6844e-03,  3.5930e-01, -4.7542e-03,  ...,  6.1235e+00,  3.5843e+00,  2.6222e+00],\n",
       "          ...,\n",
       "          [-1.5122e+00, -1.1556e+00, -1.5197e+00,  ...,  4.6086e+00,  2.0694e+00,  1.1072e+00],\n",
       "          [-3.4274e-01,  1.3879e-02, -3.5018e-01,  ...,  5.7781e+00,  3.2389e+00,  2.2767e+00],\n",
       "          [-1.2959e+00, -9.3932e-01, -1.3034e+00,  ...,  4.8249e+00,  2.2857e+00,  1.3235e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dFgs_cu - delta_fbar_pt.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           ...,\n",
       "           [-1.0750e-16, -2.5254e-15, -2.7651e-15,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "           [-4.4924e-16, -3.4490e-16, -5.8351e-17,  ..., -8.4831e-01,  0.0000e+00,  0.0000e+00],\n",
       "           [ 2.9628e-17,  7.3723e-15,  8.4683e-15,  ..., -2.7333e+00, -2.6195e+00,  0.0000e+00]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 64, 64]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matC_cu[:, :, :, 16:], matC_cu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.9371,  2.0249, -0.2835, -0.0029,  0.0127, -0.0083,  0.0024,  0.0053],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]], device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltaDcsChunkArr_cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00, -1.0611e+00, -9.8048e-04, -4.2884e-02,  1.0149e-01,  8.1734e-02,  2.8368e-01,  9.8421e-03,  3.4581e-03,  2.8438e-03,  7.9309e-04, -2.1258e-04,  2.4320e-05,\n",
       "           -1.8449e-05,  4.7609e-05, -3.0276e-05, -3.5985e-06, -9.1691e-01,  1.8829e+00,  1.7943e-01, -8.6747e-03,  1.1568e-01, -7.9905e-03, -1.6362e-03,  8.8857e-03, -2.3146e-03,  8.4135e-04,\n",
       "           -3.0571e-04,  4.6045e-05, -1.2175e-05,  7.9879e-05, -3.8685e-05,  6.9976e-06, -7.8360e-02,  8.6552e-02, -3.4454e-02, -1.8165e-02, -4.3711e-03, -2.8606e-03, -9.2952e-02,  1.3821e-03,\n",
       "           -1.2880e-03, -4.5256e-03, -4.0202e-04, -1.9368e-05, -3.2550e-05, -3.9069e-05, -9.8716e-07, -3.3347e-06]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 64]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltaDcsVec_cu, deltaDcsVec_cu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.9323e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 5.8015e-01,  4.0774e-01,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 1.6501e-20,  6.3674e-21,  1.9126e-20,  ..., -1.8856e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.2495e-21, -9.8056e-21, -1.3970e-20,  ..., -1.2343e+00, -8.4832e-01,  0.0000e+00],\n",
       "          [ 6.6858e-21, -5.2894e-22,  1.7310e-21,  ..., -3.0010e+00, -2.7333e+00, -2.6195e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_Dtilde_pt.cumsum(-1).tril(-1)[:, :, :, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matC_cu - mat_P_pt\n",
    "# matC_cu - mat_C_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.9323e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 5.8015e-01,  4.0774e-01,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 1.6501e-20,  6.3674e-21,  1.9126e-20,  ..., -1.8856e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.2495e-21, -9.8056e-21, -1.3970e-20,  ..., -1.2343e+00, -8.4831e-01,  0.0000e+00],\n",
       "          [ 6.6858e-21, -5.2894e-22,  1.7310e-21,  ..., -3.0010e+00, -2.7333e+00, -2.6195e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matC_cu[:, :, :, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.9323e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 5.8015e-01,  4.0774e-01,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 1.6501e-20,  6.3674e-21,  1.9126e-20,  ..., -1.8856e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-7.2495e-21, -9.8056e-21, -1.3970e-20,  ..., -1.2343e+00, -8.4832e-01,  0.0000e+00],\n",
       "          [ 6.6858e-21, -5.2894e-22,  1.7310e-21,  ..., -3.0010e+00, -2.7333e+00, -2.6195e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_Dtilde_pt.cumsum(-1).tril(-1)[:, :, :, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [ 4.1723e-07,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          [-2.3842e-07, -2.0862e-07,  0.0000e+00,  ...,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [-6.4623e-27, -5.6546e-27,  2.4234e-26,  ..., -7.8678e-06, -7.9870e-06,  0.0000e+00],\n",
       "          [-1.6156e-27, -3.2312e-27, -1.6156e-26,  ..., -5.4836e-06, -5.7220e-06, -5.8413e-06],\n",
       "          [-5.6546e-27, -4.0390e-27,  1.0097e-27,  ..., -1.6689e-05, -1.6928e-05, -1.6928e-05]]]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(delta_Dtilde_pt.cumsum(-1).tril(-1) - matC_cu)[:,:,:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000e+00],\n",
       "           [-1.2414e-01],\n",
       "           [ 2.6844e-03],\n",
       "           [-2.3010e-01],\n",
       "           [ 1.8230e-01],\n",
       "           [ 2.2131e-02],\n",
       "           [ 1.2863e+00],\n",
       "           [ 2.7503e-01],\n",
       "           [ 1.9151e+00],\n",
       "           [-6.6840e-02],\n",
       "           [ 6.3091e-01],\n",
       "           [ 3.9952e-01],\n",
       "           [ 8.5827e-01],\n",
       "           [ 6.9611e-01],\n",
       "           [ 2.1424e-01],\n",
       "           [ 3.7011e-02],\n",
       "           [-2.7183e-01],\n",
       "           [-5.0328e-01],\n",
       "           [ 1.7285e-01],\n",
       "           [-2.6171e-01],\n",
       "           [ 5.2955e-02],\n",
       "           [ 5.7039e-01],\n",
       "           [-9.6497e-02],\n",
       "           [-2.0098e+00],\n",
       "           [ 6.4235e-02],\n",
       "           [ 2.5044e-02],\n",
       "           [-4.9683e-01],\n",
       "           [-6.2860e-02],\n",
       "           [ 1.5297e-01],\n",
       "           [ 2.7864e+00],\n",
       "           [ 3.4535e-01],\n",
       "           [-4.0065e-01],\n",
       "           [ 3.7816e-01],\n",
       "           [ 1.0902e+00],\n",
       "           [ 2.7775e-01],\n",
       "           [-4.1950e+00],\n",
       "           [-1.2819e+00],\n",
       "           [-8.7695e-01],\n",
       "           [-3.7726e-01],\n",
       "           [ 1.8658e+00],\n",
       "           [ 1.1813e-01],\n",
       "           [ 1.7859e-01],\n",
       "           [-3.2024e-01],\n",
       "           [-7.8389e-02],\n",
       "           [ 3.8559e-02],\n",
       "           [ 9.3978e-02],\n",
       "           [ 1.1797e-01],\n",
       "           [ 7.7298e-03],\n",
       "           [-6.6006e-02],\n",
       "           [-1.2588e-01],\n",
       "           [-2.3414e-01],\n",
       "           [-6.2511e-02],\n",
       "           [ 3.3971e-01],\n",
       "           [-3.5429e+00],\n",
       "           [-3.9540e+00],\n",
       "           [ 2.5251e+00],\n",
       "           [ 7.4248e-01],\n",
       "           [ 3.8230e-01],\n",
       "           [-1.5744e-01],\n",
       "           [ 1.9187e-02],\n",
       "           [-2.7203e+00],\n",
       "           [-1.5122e+00],\n",
       "           [-3.4274e-01],\n",
       "           [-1.2959e+00]]]], device='cuda:0'),\n",
       " tensor([[[ 0.0000e+00, -3.5662e-01,  7.4386e-03, -4.0306e-01,  3.7160e-01,  3.0031e-02,  2.9879e+00,  8.0092e-01,  3.5341e+00, -3.5341e-01,  1.5268e+00,  7.0510e-01,  1.0305e+00,  1.5369e+00,\n",
       "            1.2290e+00,  1.2475e-01, -6.2127e-01, -2.9013e+00,  3.8280e-01, -9.9038e-01,  9.1242e-01,  6.7548e-01, -1.1773e-01, -2.8086e+00,  1.8586e-01,  4.5974e-02, -7.1191e-01, -1.6379e-01,\n",
       "            2.8151e-01,  6.7014e+00,  7.5774e-01, -7.4752e-01,  1.2500e+00,  2.0083e+00,  4.1303e-01, -8.5006e+00, -2.1282e+00, -9.9844e-01, -8.6081e-01,  5.0939e+00,  1.7864e-01,  4.3088e-01,\n",
       "           -1.6037e+00, -1.0091e-01,  8.4502e-02,  5.5671e-01,  1.7203e-01,  3.8448e-02, -1.4954e-01, -6.1533e-01, -4.1395e-01, -1.6502e-01,  6.4159e-01, -1.3505e+01, -5.7907e+00,  4.5628e+00,\n",
       "            2.6813e+00,  1.7995e+00, -2.1082e-01,  2.4250e-02, -4.8698e+00, -6.1209e+00, -3.5817e+00, -2.6195e+00]]], device='cuda:0'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dFgs_cu, delta_fbar_pt.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00,  3.5662e-01, -7.4386e-03,  ...,  6.1209e+00,  3.5817e+00,  2.6195e+00],\n",
       "          [-1.2414e-01,  2.3247e-01, -1.3158e-01,  ...,  5.9967e+00,  3.4575e+00,  2.4953e+00],\n",
       "          [ 2.6844e-03,  3.5930e-01, -4.7542e-03,  ...,  6.1235e+00,  3.5843e+00,  2.6222e+00],\n",
       "          ...,\n",
       "          [-1.5122e+00, -1.1556e+00, -1.5197e+00,  ...,  4.6086e+00,  2.0694e+00,  1.1072e+00],\n",
       "          [-3.4274e-01,  1.3879e-02, -3.5018e-01,  ...,  5.7781e+00,  3.2389e+00,  2.2767e+00],\n",
       "          [-1.2959e+00, -9.3932e-01, -1.3034e+00,  ...,  4.8249e+00,  2.2857e+00,  1.3235e+00]]]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dFgs_cu - delta_fbar_pt.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0817e+00,  6.5791e-01,  7.6346e-01,  2.5274e-02, -4.6380e-04,  1.5185e-03,\n",
       "           -8.5102e-03,  8.7485e-03]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 16]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltaDcsVec_cu, deltaDcsVec_cu.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bw kernel match through autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_pt = fgs.clone().detach().requires_grad_(True)\n",
    "igs_pt = igs.clone().detach().requires_grad_(True)\n",
    "qs_pt = qs.clone().detach().requires_grad_(True)\n",
    "ks_pt = ks.clone().detach().requires_grad_(True)\n",
    "vs_pt = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch version QKV product (To test if this is still correct after changes to the code.)\n",
    "# at some point we have to compare to the vlstm_fw_torch version.\n",
    "# rs = qs @ ks.transpose(-1, -2) @ vs\n",
    "# rs, rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rs_torch = (qs @ ks.transpose(-1, -2) * torch.tril(torch.ones((B, NH, S, S))).to(device=DEVICE, dtype=DTYPE)) @ vs\n",
    "# rs_torch, rs_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-2.5441e+00,  7.1635e-01,  4.9337e-01, -1.2671e-01, -1.0136e-01,  4.0353e-01, -9.0226e-01, -8.0993e-01],\n",
       "           [-2.2862e+00,  6.4824e-01,  3.7120e-01, -1.2398e-01, -6.3333e-02,  3.7858e-01, -9.9495e-01, -6.0037e-01],\n",
       "           [-6.0024e-01,  2.7681e-01, -4.9371e-01,  3.6669e-01,  4.5201e-01,  1.0728e-01, -1.0555e+00,  5.2373e-01],\n",
       "           [ 1.4676e+00, -1.2904e+00,  8.6194e-01, -6.4320e-01,  9.3298e-01, -6.3869e-01, -7.2218e-01,  2.2001e+00],\n",
       "           [ 3.8925e-01, -2.7335e-01,  2.3252e-01,  4.0492e-01,  1.2218e-01, -2.6341e-01, -3.4160e-01,  2.5086e-01],\n",
       "           [ 1.0809e-01, -5.8648e-01, -7.0732e-01, -1.0621e-01, -1.0207e+00,  1.7768e-01, -3.6291e-01, -1.5303e-01],\n",
       "           [ 2.2973e-01, -2.3181e-01, -1.1165e-01,  9.3125e-01,  2.7548e+00, -1.9033e+00, -6.4628e-02, -6.6721e-01],\n",
       "           [-5.9358e-01,  7.6381e-01,  1.4412e-01,  5.0315e-02, -7.0168e-01,  1.3539e-01,  2.9504e-01, -6.2543e-02],\n",
       "           [ 8.9242e-01, -1.6984e-01,  1.1698e+00, -9.5256e-01, -4.9875e-02,  1.7573e+00,  1.6311e-01,  1.0772e+00],\n",
       "           [ 6.2490e-01,  5.1296e-01,  1.6355e+00, -5.4996e-01,  4.9355e-01,  9.6133e-01,  1.1876e-01,  6.4997e-01],\n",
       "           [-5.7895e-02,  5.3535e-01, -1.6311e-01,  3.3315e-01, -1.7205e-01, -5.4128e-02, -4.4241e-01, -6.2242e-01],\n",
       "           [ 1.6569e+00, -2.2323e+00,  3.3821e+00, -1.4501e+00, -3.7289e-01, -9.1828e-01, -7.5015e-02, -5.7753e-01],\n",
       "           [-9.5030e-02,  1.6974e-02, -1.1076e-01,  1.3503e-01,  1.6891e-03, -2.7531e-03, -1.7557e-02,  1.1330e-02],\n",
       "           [ 8.4997e-01, -1.3765e+00, -2.0189e-01, -1.8741e+00,  5.3763e-01, -4.6095e-02,  3.0899e-01,  2.4410e-01],\n",
       "           [-9.8274e-02, -2.9715e-02,  5.4466e-01,  1.1465e+00,  3.1974e-01, -4.5854e-01, -4.1936e-01, -7.6065e-01],\n",
       "           [ 1.3229e-01, -1.5120e+00,  1.2388e+00,  3.3655e-01,  1.3584e+00, -2.9858e-01,  8.9211e-01, -1.4352e-01]]]], device='cuda:0', grad_fn=<vLSTMParallelFwBwWithGroupNormBackward>),\n",
       " torch.Size([1, 1, 16, 8]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch version\n",
    "hs_pt, n_pt, m_pt = vlstm_fwbw_torch_obw(\n",
    "    queries=qs_pt,\n",
    "    keys=ks_pt,\n",
    "    values=vs_pt,\n",
    "    igate_preact=igs_pt,\n",
    "    fgate_preact=fgs_pt,\n",
    ")\n",
    "hs_pt, hs_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_cu = fgs.clone().detach().requires_grad_(True)\n",
    "igs_cu = igs.clone().detach().requires_grad_(True)\n",
    "qs_cu = qs.clone().detach().requires_grad_(True)\n",
    "ks_cu = ks.clone().detach().requires_grad_(True)\n",
    "vs_cu = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch - float32!\n",
      "B: 1, NH: 1, S: 16, DH: 8\n",
      "blocksxy: 1-2, threadsxy: 4-4, shared_mem in bytes: 5664\n",
      "In FW-Kernel: gdim.x: 1, gdim.y: 2, gdim.z: 1, bdim.x: 4, bdim.y: 4\n",
      "In FW-Kernel: QtileDim: 8, KVtileDim: 8, TblockDim:4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-2.5441e+00,  7.1635e-01,  4.9337e-01, -1.2671e-01, -1.0136e-01,  4.0353e-01, -9.0226e-01, -8.0993e-01],\n",
       "           [-2.2862e+00,  6.4824e-01,  3.7120e-01, -1.2398e-01, -6.3333e-02,  3.7858e-01, -9.9495e-01, -6.0037e-01],\n",
       "           [-6.0024e-01,  2.7681e-01, -4.9371e-01,  3.6669e-01,  4.5201e-01,  1.0728e-01, -1.0555e+00,  5.2373e-01],\n",
       "           [ 1.4676e+00, -1.2904e+00,  8.6194e-01, -6.4320e-01,  9.3298e-01, -6.3869e-01, -7.2218e-01,  2.2001e+00],\n",
       "           [ 3.8925e-01, -2.7335e-01,  2.3252e-01,  4.0492e-01,  1.2218e-01, -2.6341e-01, -3.4160e-01,  2.5086e-01],\n",
       "           [ 1.0809e-01, -5.8648e-01, -7.0732e-01, -1.0621e-01, -1.0207e+00,  1.7768e-01, -3.6291e-01, -1.5304e-01],\n",
       "           [ 2.2973e-01, -2.3181e-01, -1.1165e-01,  9.3125e-01,  2.7548e+00, -1.9033e+00, -6.4628e-02, -6.6721e-01],\n",
       "           [-5.9358e-01,  7.6381e-01,  1.4412e-01,  5.0315e-02, -7.0168e-01,  1.3540e-01,  2.9504e-01, -6.2543e-02],\n",
       "           [ 8.9242e-01, -1.6984e-01,  1.1698e+00, -9.5256e-01, -4.9875e-02,  1.7573e+00,  1.6311e-01,  1.0772e+00],\n",
       "           [ 6.2490e-01,  5.1296e-01,  1.6355e+00, -5.4996e-01,  4.9355e-01,  9.6133e-01,  1.1876e-01,  6.4997e-01],\n",
       "           [-5.7895e-02,  5.3535e-01, -1.6311e-01,  3.3315e-01, -1.7205e-01, -5.4128e-02, -4.4241e-01, -6.2242e-01],\n",
       "           [ 1.6569e+00, -2.2324e+00,  3.3821e+00, -1.4501e+00, -3.7289e-01, -9.1828e-01, -7.5016e-02, -5.7753e-01],\n",
       "           [-9.5030e-02,  1.6974e-02, -1.1076e-01,  1.3503e-01,  1.6891e-03, -2.7532e-03, -1.7557e-02,  1.1330e-02],\n",
       "           [ 8.4997e-01, -1.3765e+00, -2.0189e-01, -1.8741e+00,  5.3763e-01, -4.6095e-02,  3.0899e-01,  2.4410e-01],\n",
       "           [-9.8275e-02, -2.9714e-02,  5.4467e-01,  1.1465e+00,  3.1974e-01, -4.5854e-01, -4.1936e-01, -7.6065e-01],\n",
       "           [ 1.3229e-01, -1.5120e+00,  1.2388e+00,  3.3655e-01,  1.3584e+00, -2.9858e-01,  8.9211e-01, -1.4352e-01]]]], device='cuda:0', grad_fn=<vLSTMParallelFwBwCudaBackward>),\n",
       " torch.Size([1, 1, 16, 8]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuda kernel\n",
    "hs_cu, n_cu, m_cu, matD_cu = vlstm_fwbw_cuda(mat_Q=qs_cu, mat_K=ks_cu, mat_V=vs_cu, igate_preact=igs_cu.squeeze(-1), fgate_preact=fgs_cu.squeeze(-1))\n",
    "hs_cu, hs_cu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.3842e-06, -6.5565e-07, -4.4703e-07,  1.1921e-07,  8.9407e-08, -3.5763e-07,  8.3447e-07,  7.1526e-07],\n",
       "          [ 1.6689e-06, -4.1723e-07, -2.9802e-07,  8.9407e-08,  4.4703e-08, -2.6822e-07,  7.1526e-07,  4.7684e-07],\n",
       "          [ 4.1723e-07, -1.4901e-07,  1.1921e-07, -1.1921e-07, -1.4901e-07, -6.7055e-08,  3.5763e-07, -1.1921e-07],\n",
       "          [-1.1921e-06,  9.5367e-07, -7.1526e-07,  5.3644e-07, -7.1526e-07,  4.7684e-07,  5.3644e-07, -1.6689e-06],\n",
       "          [-1.7881e-07,  2.0862e-07, -2.2352e-07, -2.9802e-08, -1.3411e-07,  1.4901e-07,  1.7881e-07, -2.3842e-07],\n",
       "          [-2.3842e-07,  1.2517e-06,  1.4305e-06,  2.0862e-07,  2.1458e-06, -3.7253e-07,  7.7486e-07,  3.4273e-07],\n",
       "          [-2.5332e-07,  2.8312e-07,  8.9407e-08, -1.0729e-06, -3.3379e-06,  2.5034e-06,  3.7253e-08,  7.7486e-07],\n",
       "          [ 7.7486e-07, -1.0133e-06, -1.7881e-07, -7.4506e-08,  8.3447e-07, -1.1921e-07, -3.8743e-07,  9.6858e-08],\n",
       "          [-3.5763e-07,  8.9407e-08, -3.5763e-07,  4.1723e-07,  3.3900e-07, -7.1526e-07, -4.4703e-08, -4.7684e-07],\n",
       "          [-1.1921e-07, -1.7881e-07, -1.1921e-07,  1.7881e-07, -1.7881e-07, -2.3842e-07, -1.4901e-08, -1.1921e-07],\n",
       "          [-5.5879e-08,  1.1921e-07, -2.9802e-08,  2.9802e-08,  5.9605e-08,  2.6077e-08, -1.7881e-07, -5.9605e-08],\n",
       "          [-2.7418e-06,  4.0531e-06, -5.7220e-06,  2.5034e-06,  5.6624e-07,  1.8477e-06,  2.6077e-07,  1.1921e-06],\n",
       "          [ 0.0000e+00,  6.8918e-08, -4.4703e-08, -2.9802e-08,  1.5832e-08,  2.8871e-08,  2.0489e-08,  2.2352e-08],\n",
       "          [-5.3644e-07,  8.3447e-07,  1.4901e-07,  1.0729e-06, -2.9802e-07,  1.4901e-08, -1.7881e-07, -1.4901e-07],\n",
       "          [ 3.5763e-07, -2.4214e-07, -9.5367e-07, -2.3842e-06, -4.7684e-07,  7.7486e-07,  7.7486e-07,  1.3709e-06],\n",
       "          [-5.0664e-07,  1.6689e-06, -5.9605e-07,  5.9605e-07, -8.3447e-07,  2.6822e-07, -4.7684e-07,  1.4901e-08]]]], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward match\n",
    "hs_pt - hs_cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mhs_pt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/autograd/function.py:289\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/myrepos/vlstm_cuda/src/vlstm_fwbw_v0/torch_impl.py:470\u001b[0m, in \u001b[0;36mvLSTMParallelFwBwWithGroupNorm.backward\u001b[0;34m(ctx, delta_Htilde, grad_var_n_unused, grad_var_m_unused)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\n\u001b[1;32m    462\u001b[0m     ctx,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    465\u001b[0m     grad_var_m_unused: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m    466\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m    467\u001b[0m     (queries, keys, values, igate_preact, fgate_preact, var_n, var_m) \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    468\u001b[0m         ctx\u001b[38;5;241m.\u001b[39msaved_tensors\n\u001b[1;32m    469\u001b[0m     )\n\u001b[0;32m--> 470\u001b[0m     delta_Q, delta_K, delta_V, delta_i, delta_f \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    471\u001b[0m         vlstm_parallel_bw_torch_w_groupnorm(\n\u001b[1;32m    472\u001b[0m             delta_Htilde\u001b[38;5;241m=\u001b[39mdelta_Htilde,\n\u001b[1;32m    473\u001b[0m             queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[1;32m    474\u001b[0m             keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[1;32m    475\u001b[0m             values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    476\u001b[0m             igate_preact\u001b[38;5;241m=\u001b[39migate_preact,\n\u001b[1;32m    477\u001b[0m             fgate_preact\u001b[38;5;241m=\u001b[39mfgate_preact,\n\u001b[1;32m    478\u001b[0m             var_n\u001b[38;5;241m=\u001b[39mvar_n,\n\u001b[1;32m    479\u001b[0m             var_m\u001b[38;5;241m=\u001b[39mvar_m,\n\u001b[1;32m    480\u001b[0m         )\n\u001b[1;32m    481\u001b[0m     )\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delta_Q, delta_K, delta_V, delta_i, delta_f, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "hs_pt.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001],\n",
       "           [0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002],\n",
       "           [0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002],\n",
       "           [0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004],\n",
       "           [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
       "           [0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006],\n",
       "           [0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004],\n",
       "           [0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003],\n",
       "           [0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003, 0.0003],\n",
       "           [0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004],\n",
       "           [0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002],\n",
       "           [0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011, 0.0011],\n",
       "           [0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010],\n",
       "           [0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009],\n",
       "           [0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009],\n",
       "           [0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008, 0.0008]]]], device='cuda:0'),\n",
       " tensor([[[[0.0174, 0.0195, 0.0216, 0.0237, 0.0258, 0.0279, 0.0300, 0.0321],\n",
       "           [0.0785, 0.0829, 0.0873, 0.0917, 0.0961, 0.1005, 0.1049, 0.1093],\n",
       "           [0.0097, 0.0101, 0.0105, 0.0108, 0.0112, 0.0116, 0.0120, 0.0124],\n",
       "           [0.3243, 0.3337, 0.3430, 0.3524, 0.3618, 0.3711, 0.3805, 0.3898],\n",
       "           [0.2358, 0.2417, 0.2475, 0.2533, 0.2592, 0.2650, 0.2708, 0.2767],\n",
       "           [0.1397, 0.1426, 0.1456, 0.1486, 0.1516, 0.1546, 0.1576, 0.1606],\n",
       "           [0.1373, 0.1398, 0.1423, 0.1448, 0.1474, 0.1499, 0.1524, 0.1549],\n",
       "           [0.3080, 0.3129, 0.3177, 0.3225, 0.3273, 0.3321, 0.3370, 0.3418],\n",
       "           [0.1329, 0.1348, 0.1367, 0.1386, 0.1405, 0.1424, 0.1443, 0.1462],\n",
       "           [0.2046, 0.2073, 0.2101, 0.2128, 0.2155, 0.2182, 0.2209, 0.2236],\n",
       "           [0.0640, 0.0647, 0.0655, 0.0662, 0.0670, 0.0677, 0.0685, 0.0692],\n",
       "           [2.6744, 2.7021, 2.7298, 2.7575, 2.7852, 2.8129, 2.8406, 2.8683],\n",
       "           [0.3938, 0.3977, 0.4015, 0.4054, 0.4093, 0.4131, 0.4170, 0.4209],\n",
       "           [0.2212, 0.2233, 0.2253, 0.2274, 0.2295, 0.2315, 0.2336, 0.2357],\n",
       "           [0.9315, 0.9396, 0.9478, 0.9559, 0.9641, 0.9722, 0.9804, 0.9885],\n",
       "           [0.5474, 0.5520, 0.5566, 0.5611, 0.5657, 0.5702, 0.5748, 0.5794]]]], device='cuda:0'),\n",
       " tensor([[[[0.0247, 0.0247, 0.0247, 0.0247, 0.0247, 0.0247, 0.0247, 0.0247],\n",
       "           [0.0939, 0.0939, 0.0939, 0.0939, 0.0939, 0.0939, 0.0939, 0.0939],\n",
       "           [0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110],\n",
       "           [0.3571, 0.3571, 0.3571, 0.3571, 0.3571, 0.3571, 0.3571, 0.3571],\n",
       "           [0.2562, 0.2562, 0.2562, 0.2562, 0.2562, 0.2562, 0.2562, 0.2562],\n",
       "           [0.1501, 0.1501, 0.1501, 0.1501, 0.1501, 0.1501, 0.1501, 0.1501],\n",
       "           [0.1461, 0.1461, 0.1461, 0.1461, 0.1461, 0.1461, 0.1461, 0.1461],\n",
       "           [0.3249, 0.3249, 0.3249, 0.3249, 0.3249, 0.3249, 0.3249, 0.3249],\n",
       "           [0.1395, 0.1395, 0.1395, 0.1395, 0.1395, 0.1395, 0.1395, 0.1395],\n",
       "           [0.2141, 0.2141, 0.2141, 0.2141, 0.2141, 0.2141, 0.2141, 0.2141],\n",
       "           [0.0666, 0.0666, 0.0666, 0.0666, 0.0666, 0.0666, 0.0666, 0.0666],\n",
       "           [2.7713, 2.7713, 2.7713, 2.7713, 2.7713, 2.7713, 2.7713, 2.7713],\n",
       "           [0.4073, 0.4073, 0.4073, 0.4073, 0.4073, 0.4073, 0.4073, 0.4073],\n",
       "           [0.2284, 0.2284, 0.2284, 0.2284, 0.2284, 0.2284, 0.2284, 0.2284],\n",
       "           [0.9600, 0.9600, 0.9600, 0.9600, 0.9600, 0.9600, 0.9600, 0.9600],\n",
       "           [0.5634, 0.5634, 0.5634, 0.5634, 0.5634, 0.5634, 0.5634, 0.5634]]]], device='cuda:0'),\n",
       " tensor([[[[0.0020],\n",
       "           [0.0075],\n",
       "           [0.0009],\n",
       "           [0.0286],\n",
       "           [0.0205],\n",
       "           [0.0120],\n",
       "           [0.0117],\n",
       "           [0.0260],\n",
       "           [0.0112],\n",
       "           [0.0171],\n",
       "           [0.0053],\n",
       "           [0.2217],\n",
       "           [0.0326],\n",
       "           [0.0183],\n",
       "           [0.0768],\n",
       "           [0.0451]]]], device='cuda:0'),\n",
       " tensor([[[[0.0000],\n",
       "           [0.0011],\n",
       "           [0.0020],\n",
       "           [0.0035],\n",
       "           [0.0051],\n",
       "           [0.0088],\n",
       "           [0.0106],\n",
       "           [0.0115],\n",
       "           [0.0081],\n",
       "           [0.0058],\n",
       "           [0.0083],\n",
       "           [0.0033],\n",
       "           [0.0553],\n",
       "           [0.0396],\n",
       "           [0.0254],\n",
       "           [0.0186]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_pt.grad, ks_pt.grad, vs_pt.grad, igs_pt.grad, fgs_pt.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch - float32!\n",
      "B: 1, NH: 1, S: 16, DH: 8\n",
      "blocksxy: 1-2, threadsxy: 4-4, shared_mem in bytes: 7136\n",
      "In BW-Kernel: gdim.x: 1, gdim.y: 2, gdim.z: 1, bdim.x: 4, bdim.y: 4\n",
      "In BW-Kernel: QtileDim: 8, KVtileDim: 8, TblockDim:4\n"
     ]
    }
   ],
   "source": [
    "hs_cu.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "           [0., 0., 0., 0., 0., 0., 0., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]]]], device='cuda:0'),\n",
       " tensor([[[[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_cu.grad, ks_cu.grad, vs_cu.grad, igs_cu.grad, fgs_cu.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt21cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
