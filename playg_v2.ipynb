{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "sys.path.append(\".\")\n",
    "# os.environ[\"MAX_JOBS\"] = \"100\"\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCLUDE: ['/local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include', '/local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include/torch/csrc/api/include', '/local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include/TH', '/local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include/THC', '/local00/bioinf/beck/envs/xlstmdev1/include']\n",
      "/system/user/publicwork/beck/repos/xlstm/xlstm/models/vector_lstms/vkernels/cuda/src\n",
      "\n",
      "/local00/bioinf/beck/envs/xlstmdev1/lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /system/user/beck/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /system/user/beck/.cache/torch_extensions/py311_cu118/playg_v1/build.ninja...\n",
      "Building extension module playg_v1...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] /local00/bioinf/beck/envs/xlstmdev1/bin/x86_64-conda-linux-gnu-c++ -MMD -MF funcs.o.d -DTORCH_EXTENSION_NAME=playg_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include -isystem /local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include/TH -isystem /local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include/THC -isystem /local00/bioinf/beck/envs/xlstmdev1/include -isystem /local00/bioinf/beck/envs/xlstmdev1/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /system/user/publicwork/beck/repos/xlstm/xlstm/models/vector_lstms/vkernels/cuda/src/playg_v2/funcs.cc -o funcs.o \n",
      "[2/3] /local00/bioinf/beck/envs/xlstmdev1/bin/nvcc  -ccbin /local00/bioinf/beck/envs/xlstmdev1/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=playg_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include -isystem /local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include/TH -isystem /local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/include/THC -isystem /local00/bioinf/beck/envs/xlstmdev1/include -isystem /local00/bioinf/beck/envs/xlstmdev1/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=compute_80 -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -gencode arch=compute_80,code=compute_80 -res-usage --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DTmax=13407807929942597099574024998205846127479365820592393377723561443721764030073546976801874298166903427690031858186486050853753882811946569946433649006084096 -std=c++17 -c /system/user/publicwork/beck/repos/xlstm/xlstm/models/vector_lstms/vkernels/cuda/src/playg_v2/funcs.cu -o funcs.cuda.o \n",
      "ptxas info    : 3 bytes gmem\n",
      "ptxas info    : Compiling entry function '_ZN5vlstm7kernels10copykernelEP13__nv_bfloat16S2_ii' for 'sm_80'\n",
      "ptxas info    : Function properties for _ZN5vlstm7kernels10copykernelEP13__nv_bfloat16S2_ii\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 8 registers, 376 bytes cmem[0]\n",
      "[3/3] /local00/bioinf/beck/envs/xlstmdev1/bin/x86_64-conda-linux-gnu-c++ funcs.o funcs.cuda.o -shared -L/local00/bioinf/beck/envs/xlstmdev1/lib -lcublas -L/local00/bioinf/beck/envs/xlstmdev1/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/local00/bioinf/beck/envs/xlstmdev1/lib -lcudart -o playg_v1.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module playg_v1...\n"
     ]
    }
   ],
   "source": [
    "from src.playg_v2.funcs import testkernel, copykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTYPE = torch.bfloat16\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_A = torch.arange(4).reshape(2, 2).to(dtype=DTYPE, device=DEVICE)\n",
    "mat_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test kernel!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = testkernel(mat_A)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch!\n",
      "rows: 2, cols: 2\n",
      "blocksxy: 1-1, threads: 32-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = copykernel(mat_A)\n",
    "out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from template import qkv_vlstm_kernel_pytorch, qkv_vlstm_no_dmatrix_kernel_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 6 # hidden size\n",
    "S = 5 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 2 # num heads\n",
    "DH = H // NH # dim per head\n",
    "DTYPE = torch.bfloat16\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "assert H % NH == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(0)\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ds = torch.rand((B, NH, S, S), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "max_log_D, _ = torch.max(ds.view(B, NH, -1), dim=-1, keepdim=True)  # (B, NH, 1)\n",
    "log_D_matrix_stabilized = ds - max_log_D.unsqueeze(-1)  # (B, NH, S, S) = (B, NH, S, S) - (B, NH, 1, 1)\n",
    "D_matrix = torch.exp(log_D_matrix_stabilized)  # (B, NH, S, S)\n",
    "mval = torch.exp(-max_log_D.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.5625,  0.4277,  1.5859],\n",
       "          [-2.6719,  0.4082,  2.4375],\n",
       "          [-1.6562, -0.0201,  1.0469],\n",
       "          [ 2.2812,  0.1807, -1.3750],\n",
       "          [ 1.4219,  0.2266, -1.0469]],\n",
       "\n",
       "         [[-1.3672, -0.5195,  0.0229],\n",
       "          [ 0.0544,  0.8789, -0.6289],\n",
       "          [ 1.2109, -0.1963, -0.1797],\n",
       "          [-0.7578, -0.2031,  0.3984],\n",
       "          [ 0.8203,  0.1748, -0.3867]]]], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = qkv_vlstm_kernel_pytorch(queries=qs, keys=ks, values=vs, D_matrix=D_matrix, mval=mval)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.7812,  0.0952,  1.2344],\n",
       "          [-2.4062,  0.6016,  2.5000],\n",
       "          [-1.5391,  0.0986,  0.9258],\n",
       "          [ 2.6562,  0.3281, -2.0156],\n",
       "          [ 2.0312,  0.0781, -1.4219]],\n",
       "\n",
       "         [[-1.1328, -0.8398,  0.0079],\n",
       "          [ 0.0226,  0.9219, -0.5938],\n",
       "          [ 1.5781, -0.4102, -0.0610],\n",
       "          [-0.7461, -0.2178,  0.3613],\n",
       "          [ 0.6758,  0.0913, -0.4316]]]], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = qkv_vlstm_no_dmatrix_kernel_pytorch(queries=qs, keys=ks, values=vs, mval=mval, qk_decmask_normalize=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-8.3125,  0.4434,  5.7812],\n",
       "          [-1.6172,  0.4043,  1.6719],\n",
       "          [-3.1406,  0.2002,  1.8906],\n",
       "          [11.5000,  1.4219, -8.6875],\n",
       "          [ 4.9375,  0.1885, -3.4375]],\n",
       "\n",
       "         [[-1.6562, -1.2344,  0.0131],\n",
       "          [ 0.0767,  3.2656, -2.0938],\n",
       "          [ 3.8438, -1.0000, -0.1465],\n",
       "          [-5.0000, -1.4531,  2.4062],\n",
       "          [ 3.1875,  0.4297, -2.0312]]]], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = qkv_vlstm_no_dmatrix_kernel_pytorch(queries=qs, keys=ks, values=vs, mval=mval, qk_decmask_normalize=False)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.9258, -0.4258, -2.6406],\n",
       "           [ 0.1455, -0.1211, -0.5781],\n",
       "           [-0.6211, -0.3281, -1.0781],\n",
       "           [-0.3633, -1.6719,  2.2656],\n",
       "           [ 0.3125, -0.1846,  1.2891]],\n",
       " \n",
       "          [[ 1.1797, -0.1270,  1.2188],\n",
       "           [ 1.4375,  1.0625, -0.4941],\n",
       "           [-1.4219, -0.7227, -1.2969],\n",
       "           [ 0.0698, -0.0074,  1.8984],\n",
       "           [ 0.6875, -0.0781, -0.8359]]]], device='cuda:0',\n",
       "        dtype=torch.bfloat16),\n",
       " torch.Size([1, 2, 5, 3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs, qs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -8.7500,   4.1562, -41.7500],\n",
       "          [ -1.4297,   1.2188,  -8.1875],\n",
       "          [ -4.1250,   0.9453, -17.2500],\n",
       "          [  3.4844, -11.2500,  37.7500],\n",
       "          [  3.6250,  -3.4062,  20.8750]],\n",
       "\n",
       "         [[  9.3125,   2.9375,  11.8750],\n",
       "          [ 10.0000,   5.0000,  -0.4219],\n",
       "          [-12.9375,  -4.9375, -13.2500],\n",
       "          [  4.4375,   0.7461,  14.8125],\n",
       "          [  2.1406,   1.2266,  -5.0000]]]], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = qkv_vlstm_no_dmatrix_kernel_pytorch(queries=qs, keys=qs, values=qs, qk_decmask_normalize=False)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[64., 64., 64.,  ..., 64., 64., 64.],\n",
       "         [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "         [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "         ...,\n",
       "         [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "         [64., 64., 64.,  ..., 64., 64., 64.],\n",
       "         [64., 64., 64.,  ..., 64., 64., 64.]], device='cuda:0',\n",
       "        dtype=torch.bfloat16),\n",
       " torch.Size([32, 32]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warp_size = 32\n",
    "am = torch.ones((1*1*warp_size, 1*1*warp_size), device=DEVICE, dtype=DTYPE)\n",
    "bm = 2 * torch.ones((1*1*warp_size, 1*1*warp_size), device=DEVICE, dtype=DTYPE)\n",
    "cm = am @ bm\n",
    "cm, cm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt21cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
