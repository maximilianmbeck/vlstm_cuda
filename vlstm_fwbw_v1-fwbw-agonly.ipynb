{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "sys.path.append(\".\")\n",
    "# os.environ[\"MAX_JOBS\"] = \"100\"\n",
    "\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=200, threshold=100000)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCLUDE: ['/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include', '/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include/torch/csrc/api/include', '/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include/TH', '/home/max/miniconda3/envs/xlstmpt220cu121/lib/python3.11/site-packages/torch/include/THC', '/home/max/miniconda3/envs/xlstmpt220cu121/include']\n",
      "/home/max/myrepos/vlstm_cuda/src\n",
      "/home/max/cpplibs/libtorch/lib:/usr/local/cuda-12.3/lib64:\n",
      "/home/max/miniconda3/envs/xlstmpt220cu121/lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/max/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/max/.cache/torch_extensions/py311_cu121/vlstm_fwbw_v1/build.ninja...\n",
      "Building extension module vlstm_fwbw_v1...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module vlstm_fwbw_v1...\n"
     ]
    }
   ],
   "source": [
    "from src.vlstm_fwbw_v1.interface import vlstm_fwbw_torch_obw, vlstm_fwbw_cuda\n",
    "from src.vlstm_fwbw_v1.interface import vlstm_fwbw_torch_autogradbw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA vLSTM forward backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "S = 8 #32 #16 #8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 8 # dim per head\n",
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(0)\n",
    "# fixed:\n",
    "# qs = torch.arange((B*NH*S*DH), device=DEVICE, dtype=DTYPE).reshape((B, NH, S, DH)) / 10.\n",
    "# ks = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) / 100.\n",
    "# vs = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) / 100.\n",
    "\n",
    "# random: \n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "# igs = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1) / 10.\n",
    "# igs = torch.zeros((B, NH, S, 1), device=DEVICE, dtype=DTYPE) #/ 10.\n",
    "igs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE) #/ 10.\n",
    "# fgs = torch.ones((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "fgs = torch.randn((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "# dHs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### match through autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to apply the groupnorm directly afterwards\n",
    "from vlstm_formulations.ln import MultiHeadLayerNorm\n",
    "\n",
    "mh_layernorm = MultiHeadLayerNorm(ndim=NH*DH, eps=1e-6).to(device=DEVICE, dtype=DTYPE)\n",
    "mh_layernorm.weight, mh_layernorm.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 3.* torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_pt_ag = fgs.clone().detach().requires_grad_(True)\n",
    "igs_pt_ag = igs.clone().detach().requires_grad_(True)\n",
    "qs_pt_ag = qs.clone().detach().requires_grad_(True)\n",
    "ks_pt_ag = ks.clone().detach().requires_grad_(True)\n",
    "vs_pt_ag = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch obw\n",
    "hs_pt_ag, n_pt_ag, m_pt_ag = vlstm_fwbw_torch_obw( #vlstm_fwbw_torch_autogradbw( #vlstm_fwbw_torch_obw(\n",
    "    queries=qs_pt_ag,\n",
    "    keys=ks_pt_ag,\n",
    "    values=vs_pt_ag,\n",
    "    igate_preact=igs_pt_ag,\n",
    "    fgate_preact=fgs_pt_ag,\n",
    ")\n",
    "hs_pt_ag_scaled = mh_layernorm(hs_pt_ag)\n",
    "# hs_pt_ag_scaled.sum().backward()\n",
    "((hs_pt_ag_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgs_cu_ag = fgs.clone().detach().requires_grad_(True)\n",
    "igs_cu_ag = igs.clone().detach().requires_grad_(True)\n",
    "qs_cu_ag = qs.clone().detach().requires_grad_(True)\n",
    "ks_cu_ag = ks.clone().detach().requires_grad_(True)\n",
    "vs_cu_ag = vs.clone().detach().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch autograd\n",
    "# hs_cu_ag, n_cu_ag, m_cu_ag = vlstm_fwbw_torch_autogradbw(\n",
    "#     queries=qs_cu_ag,\n",
    "#     keys=ks_cu_ag,\n",
    "#     values=vs_cu_ag,\n",
    "#     igate_preact=igs_cu_ag,\n",
    "#     fgate_preact=fgs_cu_ag,\n",
    "# )\n",
    "# hs_cu_ag_scaled = mh_layernorm(hs_cu_ag)\n",
    "# hs_cu_ag_scaled.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch - float32!\n",
      "B: 1, NH: 1, S: 8, DH: 8\n",
      "blocksxy: 1-2, threadsxy: 4-4, shared_mem in bytes: 5664\n",
      "In FW-Kernel: gdim.x: 1, gdim.y: 2, gdim.z: 1, bdim.x: 4, bdim.y: 4\n",
      "In FW-Kernel: QtileDim: 8, KVtileDim: 8, TblockDim:4\n",
      "before kernel dispatch - float32!\n",
      "B: 1, NH: 1, S: 8, DH: 8\n",
      "blocksxy: 1-1, threadsxy: 4-4, shared_mem in bytes: 7648\n",
      "In BW-Kernel: gdim.x: 1, gdim.y: 1, gdim.z: 1, bdim.x: 4, bdim.y: 4\n",
      "In BW-Kernel: QtileDim: 8, KVtileDim: 8, TblockDim:4\n"
     ]
    }
   ],
   "source": [
    "# cuda kernel\n",
    "hs_cu_ag, n_cu_ag, m_cu_ag, matD_cu_ag = vlstm_fwbw_cuda(\n",
    "    mat_Q=qs_cu_ag,\n",
    "    mat_K=ks_cu_ag,\n",
    "    mat_V=vs_cu_ag,\n",
    "    vec_igp=igs_cu_ag,\n",
    "    vec_fgp=fgs_cu_ag,\n",
    ")\n",
    "hs_cu_ag_scaled = mh_layernorm(hs_cu_ag)\n",
    "# hs_cu_ag_scaled.sum().backward()\n",
    "((hs_cu_ag_scaled+offset)**2).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fw hs match: True\n",
      "fw hs scaled match: True\n",
      "fw n match: True\n",
      "fw m match: True\n",
      "delta Q match: True\n",
      "delta K match: True\n",
      "delta V match: True\n",
      "delta Igate match: True\n",
      "delta Fgate match: True\n"
     ]
    }
   ],
   "source": [
    "FW_RTOL = 1e-10\n",
    "FW_ATOL = 1e-4\n",
    "BW_RTOL = FW_ATOL\n",
    "BW_ATOL = FW_ATOL\n",
    "print(f\"fw hs match: {torch.allclose(hs_cu_ag, hs_pt_ag, rtol=FW_RTOL, atol=FW_ATOL)}\")\n",
    "print(f\"fw hs scaled match: {torch.allclose(hs_cu_ag_scaled, hs_pt_ag_scaled, rtol=FW_RTOL, atol=FW_ATOL)}\")\n",
    "print(f\"fw n match: {torch.allclose(n_cu_ag, n_pt_ag, rtol=FW_RTOL, atol=FW_ATOL)}\")\n",
    "print(f\"fw m match: {torch.allclose(m_cu_ag, m_pt_ag, rtol=FW_RTOL, atol=FW_ATOL)}\")\n",
    "# print(f\"fw D match: {torch.allclose((matD_cu_ag - matD_pt_ag).tril(), torch.zeros_like((matD_cu)), rtol=FW_RTOL, atol=FW_ATOL)}\")\n",
    "\n",
    "print(f\"delta Q match: {torch.allclose(qs_cu_ag.grad, qs_pt_ag.grad, rtol=BW_RTOL, atol=BW_ATOL)}\")\n",
    "print(f\"delta K match: {torch.allclose(ks_cu_ag.grad, ks_pt_ag.grad, rtol=BW_RTOL, atol=BW_ATOL)}\")\n",
    "print(f\"delta V match: {torch.allclose(vs_cu_ag.grad, vs_pt_ag.grad, rtol=BW_RTOL, atol=BW_ATOL)}\")\n",
    "print(f\"delta Igate match: {torch.allclose(igs_cu_ag.grad, igs_pt_ag.grad, rtol=BW_RTOL, atol=BW_ATOL)}\")\n",
    "print(f\"delta Fgate match: {torch.allclose(fgs_cu_ag.grad, fgs_pt_ag.grad, rtol=BW_RTOL, atol=BW_ATOL)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.3516],\n",
       "           [-0.0763],\n",
       "           [-0.5240],\n",
       "           [ 0.3096],\n",
       "           [-0.3649],\n",
       "           [ 0.7268],\n",
       "           [ 0.1638],\n",
       "           [ 0.4116]]]], device='cuda:0', grad_fn=<vLSTMParallelFwBwCudaBackward>),\n",
       " tensor([[[[ 0.3516],\n",
       "           [-0.0763],\n",
       "           [-0.5240],\n",
       "           [ 0.3096],\n",
       "           [-0.3649],\n",
       "           [ 0.7268],\n",
       "           [ 0.1638],\n",
       "           [ 0.4116]]]], device='cuda:0', grad_fn=<vLSTMParallelFwBwWithGroupNormBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_cu_ag, m_pt_ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-1.6069e-06,  4.9077e-06, -8.2095e-06,  6.5313e-06, -1.2263e-05, -7.7102e-06, -1.1522e-06,  8.3590e-06],\n",
       "           [-6.6263e-01, -9.3977e-01,  1.1642e+00,  1.0569e-01, -4.6530e-02, -1.1498e-01,  6.4565e-01, -1.5624e-01],\n",
       "           [-1.1775e+00, -4.2162e+00,  8.7583e+00, -2.5155e+00,  9.9588e+00,  4.9440e+00,  3.1221e+00, -7.1708e+00],\n",
       "           [ 7.5989e-01, -2.3552e+00,  1.8079e+00, -2.7433e+00,  1.4621e+00,  1.7494e+00, -2.6279e-01, -1.1134e+00],\n",
       "           [ 3.8735e-01, -9.0136e+00, -4.5716e+00, -1.0067e+01,  8.7673e+00,  7.9581e+00,  5.8301e+00, -7.4379e+00],\n",
       "           [ 3.2860e+00, -1.1445e-01, -5.6605e+00,  2.3299e-01, -1.0818e+01,  1.3968e+00, -1.6593e-01, -7.2362e+00],\n",
       "           [-3.2388e+00, -1.1100e+00,  1.5461e+00, -3.2047e-01,  3.8381e+00,  3.1948e+00,  4.6391e-01, -1.5304e+00],\n",
       "           [ 2.8446e+01,  9.4093e+00, -3.8280e+01,  2.6147e+00,  3.4739e+01, -3.0566e+01, -1.8998e+01,  1.6512e+00]]]], device='cuda:0'),\n",
       " tensor([[[[-1.8879e-06,  5.7658e-06, -9.6448e-06,  7.6733e-06, -1.4407e-05, -9.0583e-06, -1.3536e-06,  9.8205e-06],\n",
       "           [-6.6263e-01, -9.3977e-01,  1.1642e+00,  1.0569e-01, -4.6531e-02, -1.1498e-01,  6.4565e-01, -1.5624e-01],\n",
       "           [-1.1775e+00, -4.2162e+00,  8.7583e+00, -2.5155e+00,  9.9588e+00,  4.9440e+00,  3.1221e+00, -7.1708e+00],\n",
       "           [ 7.5989e-01, -2.3552e+00,  1.8079e+00, -2.7433e+00,  1.4621e+00,  1.7494e+00, -2.6280e-01, -1.1134e+00],\n",
       "           [ 3.8735e-01, -9.0136e+00, -4.5716e+00, -1.0067e+01,  8.7673e+00,  7.9582e+00,  5.8301e+00, -7.4379e+00],\n",
       "           [ 3.2860e+00, -1.1445e-01, -5.6605e+00,  2.3300e-01, -1.0818e+01,  1.3968e+00, -1.6593e-01, -7.2362e+00],\n",
       "           [-3.2388e+00, -1.1100e+00,  1.5461e+00, -3.2047e-01,  3.8381e+00,  3.1948e+00,  4.6391e-01, -1.5304e+00],\n",
       "           [ 2.8446e+01,  9.4093e+00, -3.8280e+01,  2.6147e+00,  3.4739e+01, -3.0566e+01, -1.8998e+01,  1.6512e+00]]]], device='cuda:0'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs_cu_ag.grad, qs_pt_ag.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1458e-05, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(qs_cu_ag.grad - qs_pt_ag.grad).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6212e-05, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(ks_cu_ag.grad - ks_pt_ag.grad).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6212e-05, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(ks_cu_ag.grad - ks_pt_ag.grad).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.7684e-06, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(vs_cu_ag.grad - vs_pt_ag.grad).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt21cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
