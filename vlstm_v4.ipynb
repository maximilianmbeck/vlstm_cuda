{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "sys.path.append(\".\")\n",
    "# os.environ[\"MAX_JOBS\"] = \"100\"\n",
    "\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=200)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCLUDE: ['/home/max/miniconda3/envs/xlstmpt21cu118/lib/python3.11/site-packages/torch/include', '/home/max/miniconda3/envs/xlstmpt21cu118/lib/python3.11/site-packages/torch/include/torch/csrc/api/include', '/home/max/miniconda3/envs/xlstmpt21cu118/lib/python3.11/site-packages/torch/include/TH', '/home/max/miniconda3/envs/xlstmpt21cu118/lib/python3.11/site-packages/torch/include/THC', '/home/max/miniconda3/envs/xlstmpt21cu118/include']\n",
      "/home/max/myrepos/vlstm_cuda/src\n",
      "/home/max/cpplibs/libtorch/lib:/usr/local/cuda-12.3/lib64:\n",
      "/home/max/miniconda3/envs/xlstmpt21cu118/lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/max/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/max/.cache/torch_extensions/py311_cu118/vlstm_v4/build.ninja...\n",
      "Building extension module vlstm_v4...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module vlstm_v4...\n"
     ]
    }
   ],
   "source": [
    "from src.vlstm_v4.interface import qkvkernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qkvtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "S = 16 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 8 # dim per head\n",
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.0000,  0.1000,  0.2000,  0.3000,  0.4000,  0.5000,  0.6000,  0.7000],\n",
       "           [ 0.8000,  0.9000,  1.0000,  1.1000,  1.2000,  1.3000,  1.4000,  1.5000],\n",
       "           [ 1.6000,  1.7000,  1.8000,  1.9000,  2.0000,  2.1000,  2.2000,  2.3000],\n",
       "           [ 2.4000,  2.5000,  2.6000,  2.7000,  2.8000,  2.9000,  3.0000,  3.1000],\n",
       "           [ 3.2000,  3.3000,  3.4000,  3.5000,  3.6000,  3.7000,  3.8000,  3.9000],\n",
       "           [ 4.0000,  4.1000,  4.2000,  4.3000,  4.4000,  4.5000,  4.6000,  4.7000],\n",
       "           [ 4.8000,  4.9000,  5.0000,  5.1000,  5.2000,  5.3000,  5.4000,  5.5000],\n",
       "           [ 5.6000,  5.7000,  5.8000,  5.9000,  6.0000,  6.1000,  6.2000,  6.3000],\n",
       "           [ 6.4000,  6.5000,  6.6000,  6.7000,  6.8000,  6.9000,  7.0000,  7.1000],\n",
       "           [ 7.2000,  7.3000,  7.4000,  7.5000,  7.6000,  7.7000,  7.8000,  7.9000],\n",
       "           [ 8.0000,  8.1000,  8.2000,  8.3000,  8.4000,  8.5000,  8.6000,  8.7000],\n",
       "           [ 8.8000,  8.9000,  9.0000,  9.1000,  9.2000,  9.3000,  9.4000,  9.5000],\n",
       "           [ 9.6000,  9.7000,  9.8000,  9.9000, 10.0000, 10.1000, 10.2000, 10.3000],\n",
       "           [10.4000, 10.5000, 10.6000, 10.7000, 10.8000, 10.9000, 11.0000, 11.1000],\n",
       "           [11.2000, 11.3000, 11.4000, 11.5000, 11.6000, 11.7000, 11.8000, 11.9000],\n",
       "           [12.0000, 12.1000, 12.2000, 12.3000, 12.4000, 12.5000, 12.6000, 12.7000]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 16, 8]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(0)\n",
    "qs = torch.arange((B*NH*S*DH), device=DEVICE, dtype=DTYPE).reshape((B, NH, S, DH)) / 10.\n",
    "ks = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) #/ 10.\n",
    "vs = torch.ones((B, NH, S, DH), device=DEVICE, dtype=DTYPE) #/ 10.\n",
    "qs, qs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000,  2.8000],\n",
       "           [ 9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000,  9.2000],\n",
       "           [15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000, 15.6000],\n",
       "           [22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000, 22.0000],\n",
       "           [28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000, 28.4000],\n",
       "           [34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000, 34.8000],\n",
       "           [41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000, 41.2000],\n",
       "           [47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000, 47.6000],\n",
       "           [54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000, 54.0000],\n",
       "           [60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000, 60.4000],\n",
       "           [66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000, 66.8000],\n",
       "           [73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000, 73.2000],\n",
       "           [79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000, 79.6000],\n",
       "           [86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000, 86.0000],\n",
       "           [92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000, 92.4000],\n",
       "           [98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000, 98.8000]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 16, 16]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = qs @ ks.transpose(-1, -2)\n",
    "rs, rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  44.8000,   44.8000,   44.8000,   44.8000,   44.8000,   44.8000,   44.8000,   44.8000],\n",
       "           [ 147.2000,  147.2000,  147.2000,  147.2000,  147.2000,  147.2000,  147.2000,  147.2000],\n",
       "           [ 249.6000,  249.6000,  249.6000,  249.6000,  249.6000,  249.6000,  249.6000,  249.6000],\n",
       "           [ 352.0000,  352.0000,  352.0000,  352.0000,  352.0000,  352.0000,  352.0000,  352.0000],\n",
       "           [ 454.4000,  454.4000,  454.4000,  454.4000,  454.4000,  454.4000,  454.4000,  454.4000],\n",
       "           [ 556.8000,  556.8000,  556.8000,  556.8000,  556.8000,  556.8000,  556.8000,  556.8000],\n",
       "           [ 659.2001,  659.2001,  659.2001,  659.2001,  659.2001,  659.2001,  659.2001,  659.2001],\n",
       "           [ 761.6000,  761.6000,  761.6000,  761.6000,  761.6000,  761.6000,  761.6000,  761.6000],\n",
       "           [ 864.0000,  864.0000,  864.0000,  864.0000,  864.0000,  864.0000,  864.0000,  864.0000],\n",
       "           [ 966.4000,  966.4000,  966.4000,  966.4000,  966.4000,  966.4000,  966.4000,  966.4000],\n",
       "           [1068.7999, 1068.7999, 1068.7999, 1068.7999, 1068.7999, 1068.7999, 1068.7999, 1068.7999],\n",
       "           [1171.2001, 1171.2001, 1171.2001, 1171.2001, 1171.2001, 1171.2001, 1171.2001, 1171.2001],\n",
       "           [1273.6000, 1273.6000, 1273.6000, 1273.6000, 1273.6000, 1273.6000, 1273.6000, 1273.6000],\n",
       "           [1376.0000, 1376.0000, 1376.0000, 1376.0000, 1376.0000, 1376.0000, 1376.0000, 1376.0000],\n",
       "           [1478.4000, 1478.4000, 1478.4000, 1478.4000, 1478.4000, 1478.4000, 1478.4000, 1478.4000],\n",
       "           [1580.7999, 1580.7999, 1580.7999, 1580.7999, 1580.7999, 1580.7999, 1580.7999, 1580.7999]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 16, 8]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch version\n",
    "rs = qs @ ks.transpose(-1, -2) @ vs\n",
    "rs, rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before kernel dispatch - float32!\n",
      "B: 1, NH: 1, S: 16, DH: 8\n",
      "blocksxy: 1-1, threads: 4-4\n",
      "In Kernel: gdim.x: 1, gdim.y: 1, gdim.z: 1, bdim.x: 4, bdim.y: 4\n",
      "In Kernel: QtileDim: 8, KVtileDim: 8, TblockDim:4\n",
      "qTIdx=0|kvTIdx=0: qTile[3][7] = 3.100000\n",
      "qTIdx=0|kvTIdx=0: kTile[0][7] = 1.000000\n",
      "qTIdx=0|kvTIdx=0: sTile[3][0](7) = 22.000000\n",
      "qTIdx=0|kvTIdx=0: qTile[7][7] = 6.300000\n",
      "qTIdx=0|kvTIdx=0: kTile[0][7] = 1.000000\n",
      "qTIdx=0|kvTIdx=0: sTile[7][0](7) = 47.599998\n",
      "qTIdx=1|kvTIdx=0: qTile[3][7] = 9.500000\n",
      "qTIdx=1|kvTIdx=0: kTile[0][7] = 1.000000\n",
      "qTIdx=1|kvTIdx=0: sTile[3][0](7) = 73.200005\n",
      "qTIdx=1|kvTIdx=0: qTile[7][7] = 12.700000\n",
      "qTIdx=1|kvTIdx=0: kTile[0][7] = 1.000000\n",
      "qTIdx=1|kvTIdx=0: sTile[7][0](7) = 98.799995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  44.8000,   44.8000,   44.8000,   44.8000,   44.8000,   44.8000,   44.8000,   44.8000],\n",
       "           [ 147.2000,  147.2000,  147.2000,  147.2000,  147.2000,  147.2000,  147.2000,  147.2000],\n",
       "           [ 249.6000,  249.6000,  249.6000,  249.6000,  249.6000,  249.6000,  249.6000,  249.6000],\n",
       "           [ 352.0000,  352.0000,  352.0000,  352.0000,  352.0000,  352.0000,  352.0000,  352.0000],\n",
       "           [ 454.4000,  454.4000,  454.4000,  454.4000,  454.4000,  454.4000,  454.4000,  454.4000],\n",
       "           [ 556.8000,  556.8000,  556.8000,  556.8000,  556.8000,  556.8000,  556.8000,  556.8000],\n",
       "           [ 659.2001,  659.2001,  659.2001,  659.2001,  659.2001,  659.2001,  659.2001,  659.2001],\n",
       "           [ 761.6000,  761.6000,  761.6000,  761.6000,  761.6000,  761.6000,  761.6000,  761.6000],\n",
       "           [ 864.0000,  864.0000,  864.0000,  864.0000,  864.0000,  864.0000,  864.0000,  864.0000],\n",
       "           [ 966.4000,  966.4000,  966.4000,  966.4000,  966.4000,  966.4000,  966.4000,  966.4000],\n",
       "           [1068.7999, 1068.7999, 1068.7999, 1068.7999, 1068.7999, 1068.7999, 1068.7999, 1068.7999],\n",
       "           [1171.2001, 1171.2001, 1171.2001, 1171.2001, 1171.2001, 1171.2001, 1171.2001, 1171.2001],\n",
       "           [1273.6000, 1273.6000, 1273.6000, 1273.6000, 1273.6000, 1273.6000, 1273.6000, 1273.6000],\n",
       "           [1376.0000, 1376.0000, 1376.0000, 1376.0000, 1376.0000, 1376.0000, 1376.0000, 1376.0000],\n",
       "           [1478.4001, 1478.4001, 1478.4001, 1478.4001, 1478.4001, 1478.4001, 1478.4001, 1478.4001],\n",
       "           [1580.7999, 1580.7999, 1580.7999, 1580.7999, 1580.7999, 1580.7999, 1580.7999, 1580.7999]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 16, 8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cuda kernel\n",
    "rs = qkvkernel(mat_Q=qs, mat_K=ks, mat_V=vs)\n",
    "rs, rs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matmul kernel Test from vlstm_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# from src.vlstm_v3.interface import testkernel, copykernel, mmkernelv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "DTYPE = torch.bfloat16\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "S = 8 # sequence length\n",
    "DH = 8 # hidden size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 8]),\n",
       " torch.Size([8, 8]),\n",
       " tensor([[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.],\n",
       "         [  8.,   9.,  10.,  11.,  12.,  13.,  14.,  15.],\n",
       "         [ 16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.],\n",
       "         [ 24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.],\n",
       "         [ 32.,  33.,  34.,  35.,  36.,  37.,  38.,  39.],\n",
       "         [ 40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.],\n",
       "         [ 48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.],\n",
       "         [ 56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.],\n",
       "         [ 64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.],\n",
       "         [ 72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.],\n",
       "         [ 80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.],\n",
       "         [ 88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.],\n",
       "         [ 96.,  97.,  98.,  99., 100., 101., 102., 103.],\n",
       "         [104., 105., 106., 107., 108., 109., 110., 111.],\n",
       "         [112., 113., 114., 115., 116., 117., 118., 119.],\n",
       "         [120., 121., 122., 123., 124., 125., 126., 127.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " tensor([ 28.,  92., 156., 220., 284., 348., 412., 476., 540., 604., 668., 732., 796., 860., 924., 988.], device='cuda:0', dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matA = torch.arange((2*S * DH), device=DEVICE, dtype=DTYPE).reshape((2*S, DH))\n",
    "matB = torch.ones((DH, S), device=DEVICE, dtype=DTYPE)\n",
    "matA.shape, matB.shape, matA, matA.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 28.,  28.,  28.,  28.,  28.,  28.,  28.,  28.],\n",
       "         [ 92.,  92.,  92.,  92.,  92.,  92.,  92.,  92.],\n",
       "         [156., 156., 156., 156., 156., 156., 156., 156.],\n",
       "         [220., 220., 220., 220., 220., 220., 220., 220.],\n",
       "         [284., 284., 284., 284., 284., 284., 284., 284.],\n",
       "         [348., 348., 348., 348., 348., 348., 348., 348.],\n",
       "         [412., 412., 412., 412., 412., 412., 412., 412.],\n",
       "         [476., 476., 476., 476., 476., 476., 476., 476.],\n",
       "         [540., 540., 540., 540., 540., 540., 540., 540.],\n",
       "         [604., 604., 604., 604., 604., 604., 604., 604.],\n",
       "         [668., 668., 668., 668., 668., 668., 668., 668.],\n",
       "         [732., 732., 732., 732., 732., 732., 732., 732.],\n",
       "         [796., 796., 796., 796., 796., 796., 796., 796.],\n",
       "         [860., 860., 860., 860., 860., 860., 860., 860.],\n",
       "         [924., 924., 924., 924., 924., 924., 924., 924.],\n",
       "         [988., 988., 988., 988., 988., 988., 988., 988.]], device='cuda:0', dtype=torch.bfloat16),\n",
       " torch.Size([16, 8]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch\n",
    "pt_out = matA @ matB\n",
    "pt_out, pt_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matA.is_contiguous(), matB.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mmkernelv1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/max/myrepos/vlstm_cuda/vlstm_v4.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/max/myrepos/vlstm_cuda/vlstm_v4.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cu_out \u001b[39m=\u001b[39m mmkernelv1(mat_A\u001b[39m=\u001b[39mmatA, mat_B\u001b[39m=\u001b[39mmatB)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/max/myrepos/vlstm_cuda/vlstm_v4.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cu_out, cu_out\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mmkernelv1' is not defined"
     ]
    }
   ],
   "source": [
    "cu_out = mmkernelv1(mat_A=matA, mat_B=matB)\n",
    "cu_out, cu_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matA[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matA[9].cumsum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(72,80, dtype=torch.bfloat16, device=torch.device('cuda:0')).cumsum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(72,80, dtype=torch.bfloat16, device=torch.device('cpu')).cumsum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(72,80, dtype=torch.float32, device=torch.device('cpu')).cumsum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.arange(72,80, dtype=torch.float16, device=torch.device('cuda:0')).cumsum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# cu_out = mmkernelv2(mat_A=matA, mat_B=matB)\n",
    "# cu_out, cu_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat @ mat.T @ mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 6 # hidden size\n",
    "S = 5 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 2 # num heads\n",
    "DH = H // NH # dim per head\n",
    "DTYPE = torch.bfloat16\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "assert H % NH == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(0)\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ds = torch.rand((B, NH, S, S), device=DEVICE, dtype=DTYPE)\n",
    "\n",
    "max_log_D, _ = torch.max(ds.view(B, NH, -1), dim=-1, keepdim=True)  # (B, NH, 1)\n",
    "log_D_matrix_stabilized = ds - max_log_D.unsqueeze(-1)  # (B, NH, S, S) = (B, NH, S, S) - (B, NH, 1, 1)\n",
    "D_matrix = torch.exp(log_D_matrix_stabilized)  # (B, NH, S, S)\n",
    "mval = torch.exp(-max_log_D.unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt21cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
