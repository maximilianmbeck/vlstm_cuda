{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch vLSTM forward - Tiled Computation\n",
    "\n",
    "Shows that we can compute the forward pass of the vLSTM in tiled fashion (similar to FlashAttention), \n",
    "which is necessary for the fused kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from vlstm_full import vlstm_fw_torch\n",
    "from vlstm_fw_tiled import vlstm_fw_tiled_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "S = 8 # seq len\n",
    "B = 1 # batch size\n",
    "NH = 1 # num heads\n",
    "DH = 4 # dim per head\n",
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 8, 4]), torch.Size([1, 1, 8, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create qkv, inputgates, forgetgates \n",
    "torch.manual_seed(0)\n",
    "qs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "ks = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "vs = torch.randn((B, NH, S, DH), device=DEVICE, dtype=DTYPE)\n",
    "igs = torch.rand((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "igs2 = (1. + torch.arange((B * NH * S), device=DEVICE, dtype=DTYPE)).reshape(B, NH, S, 1)\n",
    "fgs = torch.rand((B, NH, S, 1), device=DEVICE, dtype=DTYPE)\n",
    "qs.shape, fgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-2.5441,  0.7163,  0.4934, -0.1267],\n",
       "           [-0.0950,  0.1215, -0.2144, -0.2080],\n",
       "           [-1.1865,  0.5090, -0.2582, -0.4349],\n",
       "           [ 0.6274, -0.0040, -1.7983,  1.1217],\n",
       "           [-0.2278,  0.4122, -2.1547,  1.6022],\n",
       "           [ 0.8848, -0.3820,  0.6012, -0.5168],\n",
       "           [ 1.9075, -1.2873, -0.1571,  0.0968],\n",
       "           [ 1.5725, -1.0859, -0.3932,  1.7004]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = vlstm_fw_torch(\n",
    "    queries=qs,\n",
    "    keys=ks,\n",
    "    values=vs,\n",
    "    igate_preact=igs,\n",
    "    fgate_preact=fgs,\n",
    "    stabilize_rowwise=True,\n",
    ")\n",
    "rs, rs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[    inf,     nan,     nan,     nan],\n",
       "           [    nan,     nan,     nan,     nan],\n",
       "           [    inf,     nan,     nan,     nan],\n",
       "           [    nan,     nan,     nan,     nan],\n",
       "           [    nan,     nan,     nan,     nan],\n",
       "           [    nan,     nan,    -inf,     inf],\n",
       "           [   -inf,     inf,     inf,    -inf],\n",
       "           [-2.8085,  0.6834,  0.1378,  2.3397]]]], device='cuda:0'),\n",
       " torch.Size([1, 1, 8, 4]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs = vlstm_fw_tiled_torch(\n",
    "    queries=qs,\n",
    "    keys=ks,\n",
    "    values=vs,\n",
    "    igate_preact=igs,\n",
    "    fgate_preact=fgs,\n",
    "    bq_tile_size=4,\n",
    "    bkv_tile_size=4,\n",
    ")\n",
    "hs, hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 3, 4]), torch.Size([1, 1, 2, 4]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs.split(3, dim=2)[0].shape, qs.split(3, dim=2)[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt220cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
